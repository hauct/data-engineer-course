{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ“Š AGGREGATIONS WITH PYSPARK\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“‹ **DAY 3 - LESSON 2: AGGREGATIONS**\n",
    "\n",
    "### **ðŸŽ¯ OBJECTIVES:**\n",
    "\n",
    "1. **Basic Aggregations** - count, sum, avg, min, max\n",
    "2. **GroupBy Aggregations** - Single and multiple groups\n",
    "3. **Multiple Aggregations** - agg() with multiple functions\n",
    "4. **Pivot Tables** - Transform rows to columns\n",
    "5. **Rollup** - Hierarchical aggregations\n",
    "6. **Cube** - Multi-dimensional aggregations\n",
    "7. **Window Aggregations** - Running totals, moving averages\n",
    "8. **Advanced Patterns** - Custom aggregations, percentiles\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”§ **SETUP SPARK SESSION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "26/01/09 15:46:19 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Spark Session Created\n",
      "Spark Version: 3.5.1\n",
      "Master: spark://spark-master:7077\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Aggregations\") \\\n",
    "    .master(\"spark://spark-master:7077\") \\\n",
    "    .config(\"spark.executor.memory\", \"2g\") \\\n",
    "    .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.endpoint\", \"http://minio:9000\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.access.key\", \"minioadmin\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.secret.key\", \"minioadmin123\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"âœ… Spark Session Created\")\n",
    "print(f\"Spark Version: {spark.version}\")\n",
    "print(f\"Master: {spark.sparkContext.master}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸ“Š **1. CREATE SAMPLE DATASET**\n",
    "\n",
    "Táº¡o dataset sales phá»©c táº¡p Ä‘á»ƒ thá»±c hÃ nh aggregations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š SALES DATASET:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-------+-----------+----------+------+--------+-------+--------------+------------+----+-----+---+\n",
      "|order_id|order_date|country|category   |product   |price |quantity|channel|customer_name |total_amount|year|month|day|\n",
      "+--------+----------+-------+-----------+----------+------+--------+-------+--------------+------------+----+-----+---+\n",
      "|ORD001  |2024-01-15|USA    |Electronics|Laptop    |1200.0|2       |Online |John Doe      |2400.0      |2024|1    |15 |\n",
      "|ORD002  |2024-01-15|USA    |Electronics|Phone     |800.0 |3       |Store  |Jane Smith    |2400.0      |2024|1    |15 |\n",
      "|ORD003  |2024-01-16|USA    |Clothing   |Shirt     |50.0  |5       |Online |Bob Johnson   |250.0       |2024|1    |16 |\n",
      "|ORD004  |2024-01-16|USA    |Electronics|Tablet    |600.0 |1       |Online |John Doe      |600.0       |2024|1    |16 |\n",
      "|ORD005  |2024-01-17|USA    |Clothing   |Pants     |80.0  |3       |Store  |Alice Brown   |240.0       |2024|1    |17 |\n",
      "|ORD006  |2024-01-15|UK     |Electronics|Laptop    |1200.0|1       |Online |Charlie Wilson|1200.0      |2024|1    |15 |\n",
      "|ORD007  |2024-01-16|UK     |Books      |Novel     |20.0  |10      |Store  |David Lee     |200.0       |2024|1    |16 |\n",
      "|ORD008  |2024-01-16|UK     |Electronics|Phone     |800.0 |2       |Online |Eve Davis     |1600.0      |2024|1    |16 |\n",
      "|ORD009  |2024-01-17|UK     |Clothing   |Jacket    |150.0 |2       |Store  |Frank Miller  |300.0       |2024|1    |17 |\n",
      "|ORD010  |2024-01-17|UK     |Books      |Textbook  |60.0  |3       |Online |Grace Lee     |180.0       |2024|1    |17 |\n",
      "|ORD011  |2024-01-15|Canada |Electronics|Laptop    |1200.0|1       |Online |Henry Taylor  |1200.0      |2024|1    |15 |\n",
      "|ORD012  |2024-01-16|Canada |Clothing   |Shoes     |120.0 |2       |Store  |Ivy Anderson  |240.0       |2024|1    |16 |\n",
      "|ORD013  |2024-01-16|Canada |Books      |Magazine  |10.0  |5       |Online |Jack Thomas   |50.0        |2024|1    |16 |\n",
      "|ORD014  |2024-01-17|Canada |Electronics|Tablet    |600.0 |2       |Online |Karen Jackson |1200.0      |2024|1    |17 |\n",
      "|ORD015  |2024-01-17|Canada |Clothing   |Dress     |100.0 |1       |Store  |Leo White     |100.0       |2024|1    |17 |\n",
      "|ORD016  |2024-01-18|USA    |Electronics|Headphones|200.0 |4       |Online |Mia Harris    |800.0       |2024|1    |18 |\n",
      "|ORD017  |2024-01-18|USA    |Books      |Comic     |15.0  |8       |Store  |Noah Martin   |120.0       |2024|1    |18 |\n",
      "|ORD018  |2024-01-19|USA    |Clothing   |Hat       |30.0  |6       |Online |Olivia Garcia |180.0       |2024|1    |19 |\n",
      "|ORD019  |2024-01-19|USA    |Electronics|Camera    |1500.0|1       |Store  |Paul Martinez |1500.0      |2024|1    |19 |\n",
      "|ORD020  |2024-01-20|USA    |Books      |Cookbook  |35.0  |4       |Online |Quinn Robinson|140.0       |2024|1    |20 |\n",
      "|ORD021  |2024-01-18|UK     |Electronics|Mouse     |50.0  |10      |Online |Rachel Clark  |500.0       |2024|1    |18 |\n",
      "|ORD022  |2024-01-18|UK     |Clothing   |Scarf     |40.0  |5       |Store  |Sam Rodriguez |200.0       |2024|1    |18 |\n",
      "|ORD023  |2024-01-19|UK     |Books      |Biography |25.0  |6       |Online |Tina Lewis    |150.0       |2024|1    |19 |\n",
      "|ORD024  |2024-01-19|UK     |Electronics|Keyboard  |100.0 |3       |Store  |Uma Walker    |300.0       |2024|1    |19 |\n",
      "|ORD025  |2024-01-20|UK     |Clothing   |Gloves    |25.0  |8       |Online |Victor Hall   |200.0       |2024|1    |20 |\n",
      "+--------+----------+-------+-----------+----------+------+--------+-------+--------------+------------+----+-----+---+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:=============================>                             (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total rows: 25\n",
      "root\n",
      " |-- order_id: string (nullable = true)\n",
      " |-- order_date: date (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- category: string (nullable = true)\n",
      " |-- product: string (nullable = true)\n",
      " |-- price: double (nullable = true)\n",
      " |-- quantity: integer (nullable = true)\n",
      " |-- channel: string (nullable = true)\n",
      " |-- customer_name: string (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Create comprehensive sales data\n",
    "sales_data = [\n",
    "    # USA Sales\n",
    "    (\"ORD001\", \"2024-01-15\", \"USA\", \"Electronics\", \"Laptop\", 1200.0, 2, \"Online\", \"John Doe\"),\n",
    "    (\"ORD002\", \"2024-01-15\", \"USA\", \"Electronics\", \"Phone\", 800.0, 3, \"Store\", \"Jane Smith\"),\n",
    "    (\"ORD003\", \"2024-01-16\", \"USA\", \"Clothing\", \"Shirt\", 50.0, 5, \"Online\", \"Bob Johnson\"),\n",
    "    (\"ORD004\", \"2024-01-16\", \"USA\", \"Electronics\", \"Tablet\", 600.0, 1, \"Online\", \"John Doe\"),\n",
    "    (\"ORD005\", \"2024-01-17\", \"USA\", \"Clothing\", \"Pants\", 80.0, 3, \"Store\", \"Alice Brown\"),\n",
    "    \n",
    "    # UK Sales\n",
    "    (\"ORD006\", \"2024-01-15\", \"UK\", \"Electronics\", \"Laptop\", 1200.0, 1, \"Online\", \"Charlie Wilson\"),\n",
    "    (\"ORD007\", \"2024-01-16\", \"UK\", \"Books\", \"Novel\", 20.0, 10, \"Store\", \"David Lee\"),\n",
    "    (\"ORD008\", \"2024-01-16\", \"UK\", \"Electronics\", \"Phone\", 800.0, 2, \"Online\", \"Eve Davis\"),\n",
    "    (\"ORD009\", \"2024-01-17\", \"UK\", \"Clothing\", \"Jacket\", 150.0, 2, \"Store\", \"Frank Miller\"),\n",
    "    (\"ORD010\", \"2024-01-17\", \"UK\", \"Books\", \"Textbook\", 60.0, 3, \"Online\", \"Grace Lee\"),\n",
    "    \n",
    "    # Canada Sales\n",
    "    (\"ORD011\", \"2024-01-15\", \"Canada\", \"Electronics\", \"Laptop\", 1200.0, 1, \"Online\", \"Henry Taylor\"),\n",
    "    (\"ORD012\", \"2024-01-16\", \"Canada\", \"Clothing\", \"Shoes\", 120.0, 2, \"Store\", \"Ivy Anderson\"),\n",
    "    (\"ORD013\", \"2024-01-16\", \"Canada\", \"Books\", \"Magazine\", 10.0, 5, \"Online\", \"Jack Thomas\"),\n",
    "    (\"ORD014\", \"2024-01-17\", \"Canada\", \"Electronics\", \"Tablet\", 600.0, 2, \"Online\", \"Karen Jackson\"),\n",
    "    (\"ORD015\", \"2024-01-17\", \"Canada\", \"Clothing\", \"Dress\", 100.0, 1, \"Store\", \"Leo White\"),\n",
    "    \n",
    "    # More USA Sales (different dates)\n",
    "    (\"ORD016\", \"2024-01-18\", \"USA\", \"Electronics\", \"Headphones\", 200.0, 4, \"Online\", \"Mia Harris\"),\n",
    "    (\"ORD017\", \"2024-01-18\", \"USA\", \"Books\", \"Comic\", 15.0, 8, \"Store\", \"Noah Martin\"),\n",
    "    (\"ORD018\", \"2024-01-19\", \"USA\", \"Clothing\", \"Hat\", 30.0, 6, \"Online\", \"Olivia Garcia\"),\n",
    "    (\"ORD019\", \"2024-01-19\", \"USA\", \"Electronics\", \"Camera\", 1500.0, 1, \"Store\", \"Paul Martinez\"),\n",
    "    (\"ORD020\", \"2024-01-20\", \"USA\", \"Books\", \"Cookbook\", 35.0, 4, \"Online\", \"Quinn Robinson\"),\n",
    "    \n",
    "    # More UK Sales\n",
    "    (\"ORD021\", \"2024-01-18\", \"UK\", \"Electronics\", \"Mouse\", 50.0, 10, \"Online\", \"Rachel Clark\"),\n",
    "    (\"ORD022\", \"2024-01-18\", \"UK\", \"Clothing\", \"Scarf\", 40.0, 5, \"Store\", \"Sam Rodriguez\"),\n",
    "    (\"ORD023\", \"2024-01-19\", \"UK\", \"Books\", \"Biography\", 25.0, 6, \"Online\", \"Tina Lewis\"),\n",
    "    (\"ORD024\", \"2024-01-19\", \"UK\", \"Electronics\", \"Keyboard\", 100.0, 3, \"Store\", \"Uma Walker\"),\n",
    "    (\"ORD025\", \"2024-01-20\", \"UK\", \"Clothing\", \"Gloves\", 25.0, 8, \"Online\", \"Victor Hall\"),\n",
    "]\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"order_id\", StringType(), True),\n",
    "    StructField(\"order_date\", StringType(), True),\n",
    "    StructField(\"country\", StringType(), True),\n",
    "    StructField(\"category\", StringType(), True),\n",
    "    StructField(\"product\", StringType(), True),\n",
    "    StructField(\"price\", DoubleType(), True),\n",
    "    StructField(\"quantity\", IntegerType(), True),\n",
    "    StructField(\"channel\", StringType(), True),\n",
    "    StructField(\"customer_name\", StringType(), True)\n",
    "])\n",
    "\n",
    "df = spark.createDataFrame(sales_data, schema)\n",
    "\n",
    "# Add calculated columns\n",
    "df = df.withColumn(\"total_amount\", col(\"price\") * col(\"quantity\")) \\\n",
    "    .withColumn(\"order_date\", to_date(col(\"order_date\"), \"yyyy-MM-dd\")) \\\n",
    "    .withColumn(\"year\", year(col(\"order_date\"))) \\\n",
    "    .withColumn(\"month\", month(col(\"order_date\"))) \\\n",
    "    .withColumn(\"day\", dayofmonth(col(\"order_date\")))\n",
    "\n",
    "print(\"ðŸ“Š SALES DATASET:\")\n",
    "df.show(25, truncate=False)\n",
    "print(f\"\\nTotal rows: {df.count()}\")\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸ“ˆ **2. BASIC AGGREGATIONS**\n",
    "\n",
    "CÃ¡c aggregation functions cÆ¡ báº£n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¹ Single aggregations:\n",
      "Total orders: 25\n",
      "Total revenue: $16,250.00\n",
      "Average order value: $650.00\n",
      "Min order: $50.00\n",
      "Max order: $2,400.00\n",
      "\n",
      "ðŸ”¹ Multiple aggregations:\n",
      "+------------+-------------+---------------+---------+---------+-----------------+--------------+\n",
      "|total_orders|total_revenue|avg_order_value|min_order|max_order|     stddev_order|variance_order|\n",
      "+------------+-------------+---------------+---------+---------+-----------------+--------------+\n",
      "|          25|      16250.0|          650.0|     50.0|   2400.0|705.6025793603649|      497875.0|\n",
      "+------------+-------------+---------------+---------+---------+-----------------+--------------+\n",
      "\n",
      "\n",
      "ðŸ”¹ Count distinct:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26/01/09 15:46:37 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------+------------+-------------+\n",
      "|num_countries|num_categories|num_products|num_customers|\n",
      "+-------------+--------------+------------+-------------+\n",
      "|            3|             3|          21|           24|\n",
      "+-------------+--------------+------------+-------------+\n",
      "\n",
      "\n",
      "ðŸ”¹ Approximate count distinct:\n",
      "+----------------+---------------+\n",
      "|approx_customers|exact_customers|\n",
      "+----------------+---------------+\n",
      "|              25|             24|\n",
      "+----------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2.1 Single aggregations\n",
    "print(\"ðŸ”¹ Single aggregations:\")\n",
    "\n",
    "# Count\n",
    "total_orders = df.count()\n",
    "print(f\"Total orders: {total_orders}\")\n",
    "\n",
    "# Sum\n",
    "total_revenue = df.select(sum(\"total_amount\")).collect()[0][0]\n",
    "print(f\"Total revenue: ${total_revenue:,.2f}\")\n",
    "\n",
    "# Average\n",
    "avg_order_value = df.select(avg(\"total_amount\")).collect()[0][0]\n",
    "print(f\"Average order value: ${avg_order_value:,.2f}\")\n",
    "\n",
    "# Min/Max\n",
    "min_order = df.select(min(\"total_amount\")).collect()[0][0]\n",
    "max_order = df.select(max(\"total_amount\")).collect()[0][0]\n",
    "print(f\"Min order: ${min_order:,.2f}\")\n",
    "print(f\"Max order: ${max_order:,.2f}\")\n",
    "\n",
    "# 2.2 Multiple aggregations at once\n",
    "print(\"\\nðŸ”¹ Multiple aggregations:\")\n",
    "summary = df.select(\n",
    "    count(\"*\").alias(\"total_orders\"),\n",
    "    sum(\"total_amount\").alias(\"total_revenue\"),\n",
    "    avg(\"total_amount\").alias(\"avg_order_value\"),\n",
    "    min(\"total_amount\").alias(\"min_order\"),\n",
    "    max(\"total_amount\").alias(\"max_order\"),\n",
    "    stddev(\"total_amount\").alias(\"stddev_order\"),\n",
    "    variance(\"total_amount\").alias(\"variance_order\")\n",
    ")\n",
    "\n",
    "summary.show()\n",
    "\n",
    "# 2.3 Count distinct\n",
    "print(\"\\nðŸ”¹ Count distinct:\")\n",
    "distinct_counts = df.select(\n",
    "    countDistinct(\"country\").alias(\"num_countries\"),\n",
    "    countDistinct(\"category\").alias(\"num_categories\"),\n",
    "    countDistinct(\"product\").alias(\"num_products\"),\n",
    "    countDistinct(\"customer_name\").alias(\"num_customers\")\n",
    ")\n",
    "\n",
    "distinct_counts.show()\n",
    "\n",
    "# 2.4 Approximate count distinct (faster for large datasets)\n",
    "print(\"\\nðŸ”¹ Approximate count distinct:\")\n",
    "approx_counts = df.select(\n",
    "    approx_count_distinct(\"customer_name\").alias(\"approx_customers\"),\n",
    "    countDistinct(\"customer_name\").alias(\"exact_customers\")\n",
    ")\n",
    "\n",
    "approx_counts.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸ‘¥ **3. GROUPBY AGGREGATIONS**\n",
    "\n",
    "Group data vÃ  aggregate theo nhÃ³m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¹ Group by country:\n",
      "+-------+----------+-------------+\n",
      "|country|num_orders|total_revenue|\n",
      "+-------+----------+-------------+\n",
      "|    USA|        10|       8630.0|\n",
      "|     UK|        10|       4830.0|\n",
      "| Canada|         5|       2790.0|\n",
      "+-------+----------+-------------+\n",
      "\n",
      "\n",
      "ðŸ”¹ Group by country and category:\n",
      "+-------+-----------+----------+-------------+------------------+\n",
      "|country|   category|num_orders|total_revenue|   avg_order_value|\n",
      "+-------+-----------+----------+-------------+------------------+\n",
      "| Canada|Electronics|         2|       2400.0|            1200.0|\n",
      "| Canada|   Clothing|         2|        340.0|             170.0|\n",
      "| Canada|      Books|         1|         50.0|              50.0|\n",
      "|     UK|Electronics|         4|       3600.0|             900.0|\n",
      "|     UK|   Clothing|         3|        700.0|233.33333333333334|\n",
      "|     UK|      Books|         3|        530.0|176.66666666666666|\n",
      "|    USA|Electronics|         5|       7700.0|            1540.0|\n",
      "|    USA|   Clothing|         3|        670.0|223.33333333333334|\n",
      "|    USA|      Books|         2|        260.0|             130.0|\n",
      "+-------+-----------+----------+-------------+------------------+\n",
      "\n",
      "\n",
      "ðŸ”¹ Multiple aggregations per column:\n",
      "+-----------+----------+--------------+-------------+------------------+---------+---------+-----------------+\n",
      "|   category|num_orders|total_quantity|total_revenue|   avg_order_value|min_order|max_order|     stddev_order|\n",
      "+-----------+----------+--------------+-------------+------------------+---------+---------+-----------------+\n",
      "|Electronics|        11|            30|      13700.0|1245.4545454545455|    300.0|   2400.0| 701.945348818035|\n",
      "|   Clothing|         8|            32|       1710.0|            213.75|    100.0|    300.0|59.26634795564849|\n",
      "|      Books|         6|            36|        840.0|             140.0|     50.0|    200.0|52.53570214625479|\n",
      "+-----------+----------+--------------+-------------+------------------+---------+---------+-----------------+\n",
      "\n",
      "\n",
      "ðŸ”¹ Group by with filtering (HAVING):\n",
      "+-----------+----------+-------------+\n",
      "|   category|num_orders|total_revenue|\n",
      "+-----------+----------+-------------+\n",
      "|Electronics|        11|      13700.0|\n",
      "|   Clothing|         8|       1710.0|\n",
      "+-----------+----------+-------------+\n",
      "\n",
      "\n",
      "ðŸ”¹ Group by date:\n",
      "+----------+----------+-------------+---------------+\n",
      "|order_date|num_orders|daily_revenue|avg_order_value|\n",
      "+----------+----------+-------------+---------------+\n",
      "|2024-01-15|         4|       7200.0|         1800.0|\n",
      "|2024-01-16|         6|       2940.0|          490.0|\n",
      "|2024-01-17|         5|       2020.0|          404.0|\n",
      "|2024-01-18|         4|       1620.0|          405.0|\n",
      "|2024-01-19|         4|       2130.0|          532.5|\n",
      "|2024-01-20|         2|        340.0|          170.0|\n",
      "+----------+----------+-------------+---------------+\n",
      "\n",
      "\n",
      "ðŸ”¹ Collect list/set:\n",
      "+-----------+-------------------------------------------------------------------------------------------+------------------------------------------------------------+----------+\n",
      "|category   |all_products                                                                               |unique_products                                             |num_orders|\n",
      "+-----------+-------------------------------------------------------------------------------------------+------------------------------------------------------------+----------+\n",
      "|Electronics|[Tablet, Headphones, Camera, Mouse, Keyboard, Laptop, Phone, Tablet, Laptop, Phone, Laptop]|[Keyboard, Mouse, Laptop, Phone, Tablet, Headphones, Camera]|11        |\n",
      "|Clothing   |[Dress, Hat, Scarf, Gloves, Shirt, Pants, Jacket, Shoes]                                   |[Scarf, Shirt, Pants, Shoes, Dress, Hat, Gloves, Jacket]    |8         |\n",
      "|Books      |[Magazine, Comic, Cookbook, Biography, Novel, Textbook]                                    |[Magazine, Cookbook, Textbook, Biography, Novel, Comic]     |6         |\n",
      "+-----------+-------------------------------------------------------------------------------------------+------------------------------------------------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3.1 Simple groupBy\n",
    "print(\"ðŸ”¹ Group by country:\")\n",
    "by_country = df.groupBy(\"country\") \\\n",
    "    .agg(\n",
    "        count(\"*\").alias(\"num_orders\"),\n",
    "        sum(\"total_amount\").alias(\"total_revenue\")\n",
    "    ) \\\n",
    "    .orderBy(desc(\"total_revenue\"))\n",
    "\n",
    "by_country.show()\n",
    "\n",
    "# 3.2 Group by multiple columns\n",
    "print(\"\\nðŸ”¹ Group by country and category:\")\n",
    "by_country_category = df.groupBy(\"country\", \"category\") \\\n",
    "    .agg(\n",
    "        count(\"*\").alias(\"num_orders\"),\n",
    "        sum(\"total_amount\").alias(\"total_revenue\"),\n",
    "        avg(\"total_amount\").alias(\"avg_order_value\")\n",
    "    ) \\\n",
    "    .orderBy(\"country\", desc(\"total_revenue\"))\n",
    "\n",
    "by_country_category.show()\n",
    "\n",
    "# 3.3 Multiple aggregations per column\n",
    "print(\"\\nðŸ”¹ Multiple aggregations per column:\")\n",
    "detailed_stats = df.groupBy(\"category\") \\\n",
    "    .agg(\n",
    "        count(\"*\").alias(\"num_orders\"),\n",
    "        sum(\"quantity\").alias(\"total_quantity\"),\n",
    "        sum(\"total_amount\").alias(\"total_revenue\"),\n",
    "        avg(\"total_amount\").alias(\"avg_order_value\"),\n",
    "        min(\"total_amount\").alias(\"min_order\"),\n",
    "        max(\"total_amount\").alias(\"max_order\"),\n",
    "        stddev(\"total_amount\").alias(\"stddev_order\")\n",
    "    ) \\\n",
    "    .orderBy(desc(\"total_revenue\"))\n",
    "\n",
    "detailed_stats.show()\n",
    "\n",
    "# 3.4 Group by with filtering\n",
    "print(\"\\nðŸ”¹ Group by with filtering (HAVING):\")\n",
    "high_value_categories = df.groupBy(\"category\") \\\n",
    "    .agg(\n",
    "        count(\"*\").alias(\"num_orders\"),\n",
    "        sum(\"total_amount\").alias(\"total_revenue\")\n",
    "    ) \\\n",
    "    .filter(col(\"total_revenue\") > 1000) \\\n",
    "    .orderBy(desc(\"total_revenue\"))\n",
    "\n",
    "high_value_categories.show()\n",
    "\n",
    "# 3.5 Group by date\n",
    "print(\"\\nðŸ”¹ Group by date:\")\n",
    "daily_sales = df.groupBy(\"order_date\") \\\n",
    "    .agg(\n",
    "        count(\"*\").alias(\"num_orders\"),\n",
    "        sum(\"total_amount\").alias(\"daily_revenue\"),\n",
    "        avg(\"total_amount\").alias(\"avg_order_value\")\n",
    "    ) \\\n",
    "    .orderBy(\"order_date\")\n",
    "\n",
    "daily_sales.show()\n",
    "\n",
    "# 3.6 Collect list/set\n",
    "print(\"\\nðŸ”¹ Collect list/set:\")\n",
    "products_by_category = df.groupBy(\"category\") \\\n",
    "    .agg(\n",
    "        collect_list(\"product\").alias(\"all_products\"),\n",
    "        collect_set(\"product\").alias(\"unique_products\"),\n",
    "        count(\"*\").alias(\"num_orders\")\n",
    "    )\n",
    "\n",
    "products_by_category.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸ”„ **4. PIVOT TABLES**\n",
    "\n",
    "Transform rows to columns (like Excel pivot tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¹ Basic pivot - Revenue by country and category:\n",
      "+-------+-----+--------+-----------+\n",
      "|country|Books|Clothing|Electronics|\n",
      "+-------+-----+--------+-----------+\n",
      "|    USA|260.0|   670.0|     7700.0|\n",
      "|     UK|530.0|   700.0|     3600.0|\n",
      "| Canada| 50.0|   340.0|     2400.0|\n",
      "+-------+-----+--------+-----------+\n",
      "\n",
      "\n",
      "ðŸ”¹ Pivot with multiple aggregations:\n",
      "+-------+-------------+------------+----------------+---------------+-------------------+------------------+\n",
      "|country|Books_revenue|Books_orders|Clothing_revenue|Clothing_orders|Electronics_revenue|Electronics_orders|\n",
      "+-------+-------------+------------+----------------+---------------+-------------------+------------------+\n",
      "|    USA|        260.0|           2|           670.0|              3|             7700.0|                 5|\n",
      "|     UK|        530.0|           3|           700.0|              3|             3600.0|                 4|\n",
      "| Canada|         50.0|           1|           340.0|              2|             2400.0|                 2|\n",
      "+-------+-------------+------------+----------------+---------------+-------------------+------------------+\n",
      "\n",
      "\n",
      "ðŸ”¹ Pivot with specific values:\n",
      "+-------+-----------+--------+-----+\n",
      "|country|Electronics|Clothing|Books|\n",
      "+-------+-----------+--------+-----+\n",
      "|    USA|     7700.0|   670.0|260.0|\n",
      "|     UK|     3600.0|   700.0|530.0|\n",
      "| Canada|     2400.0|   340.0| 50.0|\n",
      "+-------+-----------+--------+-----+\n",
      "\n",
      "\n",
      "ðŸ”¹ Pivot by date - Daily revenue by country:\n",
      "+----------+------+------+------+\n",
      "|order_date|Canada|    UK|   USA|\n",
      "+----------+------+------+------+\n",
      "|2024-01-15|1200.0|1200.0|4800.0|\n",
      "|2024-01-16| 290.0|1800.0| 850.0|\n",
      "|2024-01-17|1300.0| 480.0| 240.0|\n",
      "|2024-01-18|  NULL| 700.0| 920.0|\n",
      "|2024-01-19|  NULL| 450.0|1680.0|\n",
      "|2024-01-20|  NULL| 200.0| 140.0|\n",
      "+----------+------+------+------+\n",
      "\n",
      "\n",
      "ðŸ”¹ Pivot with null handling:\n",
      "+-------+-----+--------+-----------+\n",
      "|country|Books|Clothing|Electronics|\n",
      "+-------+-----+--------+-----------+\n",
      "|    USA|260.0|   670.0|     7700.0|\n",
      "|     UK|530.0|   700.0|     3600.0|\n",
      "| Canada| 50.0|   340.0|     2400.0|\n",
      "+-------+-----+--------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4.1 Basic pivot\n",
    "print(\"ðŸ”¹ Basic pivot - Revenue by country and category:\")\n",
    "pivot_basic = df.groupBy(\"country\") \\\n",
    "    .pivot(\"category\") \\\n",
    "    .sum(\"total_amount\")\n",
    "\n",
    "pivot_basic.show()\n",
    "\n",
    "# 4.2 Pivot with multiple aggregations\n",
    "print(\"\\nðŸ”¹ Pivot with multiple aggregations:\")\n",
    "pivot_multi = df.groupBy(\"country\") \\\n",
    "    .pivot(\"category\") \\\n",
    "    .agg(\n",
    "        sum(\"total_amount\").alias(\"revenue\"),\n",
    "        count(\"*\").alias(\"orders\")\n",
    "    )\n",
    "\n",
    "pivot_multi.show()\n",
    "\n",
    "# 4.3 Pivot with specific values (performance optimization)\n",
    "print(\"\\nðŸ”¹ Pivot with specific values:\")\n",
    "categories = [\"Electronics\", \"Clothing\", \"Books\"]\n",
    "pivot_optimized = df.groupBy(\"country\") \\\n",
    "    .pivot(\"category\", categories) \\\n",
    "    .sum(\"total_amount\")\n",
    "\n",
    "pivot_optimized.show()\n",
    "\n",
    "# 4.4 Pivot by date\n",
    "print(\"\\nðŸ”¹ Pivot by date - Daily revenue by country:\")\n",
    "pivot_date = df.groupBy(\"order_date\") \\\n",
    "    .pivot(\"country\") \\\n",
    "    .sum(\"total_amount\") \\\n",
    "    .orderBy(\"order_date\")\n",
    "\n",
    "pivot_date.show()\n",
    "\n",
    "# 4.5 Fill null values in pivot\n",
    "print(\"\\nðŸ”¹ Pivot with null handling:\")\n",
    "pivot_filled = df.groupBy(\"country\") \\\n",
    "    .pivot(\"category\") \\\n",
    "    .sum(\"total_amount\") \\\n",
    "    .fillna(0)\n",
    "\n",
    "pivot_filled.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸ“Š **5. ROLLUP - HIERARCHICAL AGGREGATIONS**\n",
    "\n",
    "Táº¡o subtotals vÃ  grand totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¹ Rollup - Country and Category:\n",
      "+-------+-----------+----------+-------------+\n",
      "|country|   category|num_orders|total_revenue|\n",
      "+-------+-----------+----------+-------------+\n",
      "|   NULL|       NULL|        25|      16250.0|\n",
      "| Canada|       NULL|         5|       2790.0|\n",
      "| Canada|      Books|         1|         50.0|\n",
      "| Canada|   Clothing|         2|        340.0|\n",
      "| Canada|Electronics|         2|       2400.0|\n",
      "|     UK|       NULL|        10|       4830.0|\n",
      "|     UK|      Books|         3|        530.0|\n",
      "|     UK|   Clothing|         3|        700.0|\n",
      "|     UK|Electronics|         4|       3600.0|\n",
      "|    USA|       NULL|        10|       8630.0|\n",
      "|    USA|      Books|         2|        260.0|\n",
      "|    USA|   Clothing|         3|        670.0|\n",
      "|    USA|Electronics|         5|       7700.0|\n",
      "+-------+-----------+----------+-------------+\n",
      "\n",
      "\n",
      "ðŸ“ ROLLUP EXPLANATION:\n",
      "- Rows with both country AND category: Detail level\n",
      "- Rows with country but NULL category: Country subtotal\n",
      "- Row with NULL country and NULL category: Grand total\n",
      "\n",
      "\n",
      "ðŸ”¹ Rollup - Country, Category, Channel:\n",
      "+-------+-----------+-------+----------+-------------+\n",
      "|country|   category|channel|num_orders|total_revenue|\n",
      "+-------+-----------+-------+----------+-------------+\n",
      "|   NULL|       NULL|   NULL|        25|      16250.0|\n",
      "| Canada|       NULL|   NULL|         5|       2790.0|\n",
      "| Canada|      Books|   NULL|         1|         50.0|\n",
      "| Canada|      Books| Online|         1|         50.0|\n",
      "| Canada|   Clothing|   NULL|         2|        340.0|\n",
      "| Canada|   Clothing|  Store|         2|        340.0|\n",
      "| Canada|Electronics|   NULL|         2|       2400.0|\n",
      "| Canada|Electronics| Online|         2|       2400.0|\n",
      "|     UK|       NULL|   NULL|        10|       4830.0|\n",
      "|     UK|      Books|   NULL|         3|        530.0|\n",
      "|     UK|      Books| Online|         2|        330.0|\n",
      "|     UK|      Books|  Store|         1|        200.0|\n",
      "|     UK|   Clothing|   NULL|         3|        700.0|\n",
      "|     UK|   Clothing| Online|         1|        200.0|\n",
      "|     UK|   Clothing|  Store|         2|        500.0|\n",
      "|     UK|Electronics|   NULL|         4|       3600.0|\n",
      "|     UK|Electronics| Online|         3|       3300.0|\n",
      "|     UK|Electronics|  Store|         1|        300.0|\n",
      "|    USA|       NULL|   NULL|        10|       8630.0|\n",
      "|    USA|      Books|   NULL|         2|        260.0|\n",
      "|    USA|      Books| Online|         1|        140.0|\n",
      "|    USA|      Books|  Store|         1|        120.0|\n",
      "|    USA|   Clothing|   NULL|         3|        670.0|\n",
      "|    USA|   Clothing| Online|         2|        430.0|\n",
      "|    USA|   Clothing|  Store|         1|        240.0|\n",
      "|    USA|Electronics|   NULL|         5|       7700.0|\n",
      "|    USA|Electronics| Online|         3|       3800.0|\n",
      "|    USA|Electronics|  Store|         2|       3900.0|\n",
      "+-------+-----------+-------+----------+-------------+\n",
      "\n",
      "\n",
      "ðŸ”¹ Rollup with level identification:\n",
      "+-------+-----------+----------+-------------+----------------+\n",
      "|country|   category|num_orders|total_revenue|           level|\n",
      "+-------+-----------+----------+-------------+----------------+\n",
      "|   NULL|       NULL|        25|      16250.0|     Grand Total|\n",
      "| Canada|       NULL|         5|       2790.0|Country Subtotal|\n",
      "| Canada|      Books|         1|         50.0|          Detail|\n",
      "| Canada|   Clothing|         2|        340.0|          Detail|\n",
      "| Canada|Electronics|         2|       2400.0|          Detail|\n",
      "|     UK|       NULL|        10|       4830.0|Country Subtotal|\n",
      "|     UK|      Books|         3|        530.0|          Detail|\n",
      "|     UK|   Clothing|         3|        700.0|          Detail|\n",
      "|     UK|Electronics|         4|       3600.0|          Detail|\n",
      "|    USA|       NULL|        10|       8630.0|Country Subtotal|\n",
      "|    USA|      Books|         2|        260.0|          Detail|\n",
      "|    USA|   Clothing|         3|        670.0|          Detail|\n",
      "|    USA|Electronics|         5|       7700.0|          Detail|\n",
      "+-------+-----------+----------+-------------+----------------+\n",
      "\n",
      "\n",
      "ðŸ”¹ Show only subtotals:\n",
      "+-------+--------+----------+-------------+----------------+\n",
      "|country|category|num_orders|total_revenue|           level|\n",
      "+-------+--------+----------+-------------+----------------+\n",
      "|   NULL|    NULL|        25|      16250.0|     Grand Total|\n",
      "| Canada|    NULL|         5|       2790.0|Country Subtotal|\n",
      "|     UK|    NULL|        10|       4830.0|Country Subtotal|\n",
      "|    USA|    NULL|        10|       8630.0|Country Subtotal|\n",
      "+-------+--------+----------+-------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5.1 Basic rollup\n",
    "print(\"ðŸ”¹ Rollup - Country and Category:\")\n",
    "rollup_basic = df.rollup(\"country\", \"category\") \\\n",
    "    .agg(\n",
    "        count(\"*\").alias(\"num_orders\"),\n",
    "        sum(\"total_amount\").alias(\"total_revenue\")\n",
    "    ) \\\n",
    "    .orderBy(\"country\", \"category\")\n",
    "\n",
    "rollup_basic.show(30)\n",
    "\n",
    "print(\"\"\"\n",
    "ðŸ“ ROLLUP EXPLANATION:\n",
    "- Rows with both country AND category: Detail level\n",
    "- Rows with country but NULL category: Country subtotal\n",
    "- Row with NULL country and NULL category: Grand total\n",
    "\"\"\")\n",
    "\n",
    "# 5.2 Rollup with 3 levels\n",
    "print(\"\\nðŸ”¹ Rollup - Country, Category, Channel:\")\n",
    "rollup_3level = df.rollup(\"country\", \"category\", \"channel\") \\\n",
    "    .agg(\n",
    "        count(\"*\").alias(\"num_orders\"),\n",
    "        sum(\"total_amount\").alias(\"total_revenue\")\n",
    "    ) \\\n",
    "    .orderBy(\"country\", \"category\", \"channel\")\n",
    "\n",
    "rollup_3level.show(50)\n",
    "\n",
    "# 5.3 Identify aggregation levels\n",
    "print(\"\\nðŸ”¹ Rollup with level identification:\")\n",
    "rollup_labeled = df.rollup(\"country\", \"category\") \\\n",
    "    .agg(\n",
    "        count(\"*\").alias(\"num_orders\"),\n",
    "        sum(\"total_amount\").alias(\"total_revenue\")\n",
    "    ) \\\n",
    "    .withColumn(\n",
    "        \"level\",\n",
    "        when(col(\"country\").isNull(), \"Grand Total\")\n",
    "        .when(col(\"category\").isNull(), \"Country Subtotal\")\n",
    "        .otherwise(\"Detail\")\n",
    "    ) \\\n",
    "    .orderBy(\"country\", \"category\")\n",
    "\n",
    "rollup_labeled.show(30)\n",
    "\n",
    "# 5.4 Filter rollup results\n",
    "print(\"\\nðŸ”¹ Show only subtotals:\")\n",
    "subtotals_only = rollup_labeled.filter(\n",
    "    (col(\"level\") == \"Country Subtotal\") | (col(\"level\") == \"Grand Total\")\n",
    ")\n",
    "\n",
    "subtotals_only.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸŽ² **6. CUBE - MULTI-DIMENSIONAL AGGREGATIONS**\n",
    "\n",
    "Táº¡o táº¥t cáº£ combinations cá»§a group by columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¹ Cube - Country and Category:\n",
      "+-------+-----------+----------+-------------+\n",
      "|country|   category|num_orders|total_revenue|\n",
      "+-------+-----------+----------+-------------+\n",
      "|   NULL|       NULL|        25|      16250.0|\n",
      "|   NULL|      Books|         6|        840.0|\n",
      "|   NULL|   Clothing|         8|       1710.0|\n",
      "|   NULL|Electronics|        11|      13700.0|\n",
      "| Canada|       NULL|         5|       2790.0|\n",
      "| Canada|      Books|         1|         50.0|\n",
      "| Canada|   Clothing|         2|        340.0|\n",
      "| Canada|Electronics|         2|       2400.0|\n",
      "|     UK|       NULL|        10|       4830.0|\n",
      "|     UK|      Books|         3|        530.0|\n",
      "|     UK|   Clothing|         3|        700.0|\n",
      "|     UK|Electronics|         4|       3600.0|\n",
      "|    USA|       NULL|        10|       8630.0|\n",
      "|    USA|      Books|         2|        260.0|\n",
      "|    USA|   Clothing|         3|        670.0|\n",
      "|    USA|Electronics|         5|       7700.0|\n",
      "+-------+-----------+----------+-------------+\n",
      "\n",
      "\n",
      "ðŸ“ CUBE EXPLANATION:\n",
      "- Rows with both country AND category: Detail level\n",
      "- Rows with country but NULL category: Country subtotal\n",
      "- Rows with NULL country but has category: Category subtotal (across all countries)\n",
      "- Row with NULL country and NULL category: Grand total\n",
      "\n",
      "\n",
      "ðŸ”¹ Cube with level identification:\n",
      "+-------+-----------+----------+-------------+--------------+\n",
      "|country|   category|num_orders|total_revenue|         level|\n",
      "+-------+-----------+----------+-------------+--------------+\n",
      "|   NULL|      Books|         6|        840.0|Category Total|\n",
      "|   NULL|   Clothing|         8|       1710.0|Category Total|\n",
      "|   NULL|Electronics|        11|      13700.0|Category Total|\n",
      "| Canada|       NULL|         5|       2790.0| Country Total|\n",
      "|     UK|       NULL|        10|       4830.0| Country Total|\n",
      "|    USA|       NULL|        10|       8630.0| Country Total|\n",
      "| Canada|      Books|         1|         50.0|        Detail|\n",
      "| Canada|   Clothing|         2|        340.0|        Detail|\n",
      "| Canada|Electronics|         2|       2400.0|        Detail|\n",
      "|     UK|      Books|         3|        530.0|        Detail|\n",
      "|     UK|   Clothing|         3|        700.0|        Detail|\n",
      "|     UK|Electronics|         4|       3600.0|        Detail|\n",
      "|    USA|      Books|         2|        260.0|        Detail|\n",
      "|    USA|   Clothing|         3|        670.0|        Detail|\n",
      "|    USA|Electronics|         5|       7700.0|        Detail|\n",
      "|   NULL|       NULL|        25|      16250.0|   Grand Total|\n",
      "+-------+-----------+----------+-------------+--------------+\n",
      "\n",
      "\n",
      "ðŸ”¹ Cube - Country, Category, Channel:\n",
      "Total combinations: 45\n",
      "+-------+-----------+-------+----------+-------------+\n",
      "|country|   category|channel|num_orders|total_revenue|\n",
      "+-------+-----------+-------+----------+-------------+\n",
      "|   NULL|       NULL|   NULL|        25|      16250.0|\n",
      "|   NULL|       NULL| Online|        15|      10650.0|\n",
      "|   NULL|       NULL|  Store|        10|       5600.0|\n",
      "|   NULL|      Books|   NULL|         6|        840.0|\n",
      "|   NULL|      Books| Online|         4|        520.0|\n",
      "|   NULL|      Books|  Store|         2|        320.0|\n",
      "|   NULL|   Clothing|   NULL|         8|       1710.0|\n",
      "|   NULL|   Clothing| Online|         3|        630.0|\n",
      "|   NULL|   Clothing|  Store|         5|       1080.0|\n",
      "|   NULL|Electronics|   NULL|        11|      13700.0|\n",
      "|   NULL|Electronics| Online|         8|       9500.0|\n",
      "|   NULL|Electronics|  Store|         3|       4200.0|\n",
      "| Canada|       NULL|   NULL|         5|       2790.0|\n",
      "| Canada|       NULL| Online|         3|       2450.0|\n",
      "| Canada|       NULL|  Store|         2|        340.0|\n",
      "| Canada|      Books|   NULL|         1|         50.0|\n",
      "| Canada|      Books| Online|         1|         50.0|\n",
      "| Canada|   Clothing|   NULL|         2|        340.0|\n",
      "| Canada|   Clothing|  Store|         2|        340.0|\n",
      "| Canada|Electronics|   NULL|         2|       2400.0|\n",
      "| Canada|Electronics| Online|         2|       2400.0|\n",
      "|     UK|       NULL|   NULL|        10|       4830.0|\n",
      "|     UK|       NULL| Online|         6|       3830.0|\n",
      "|     UK|       NULL|  Store|         4|       1000.0|\n",
      "|     UK|      Books|   NULL|         3|        530.0|\n",
      "|     UK|      Books| Online|         2|        330.0|\n",
      "|     UK|      Books|  Store|         1|        200.0|\n",
      "|     UK|   Clothing|   NULL|         3|        700.0|\n",
      "|     UK|   Clothing| Online|         1|        200.0|\n",
      "|     UK|   Clothing|  Store|         2|        500.0|\n",
      "|     UK|Electronics|   NULL|         4|       3600.0|\n",
      "|     UK|Electronics| Online|         3|       3300.0|\n",
      "|     UK|Electronics|  Store|         1|        300.0|\n",
      "|    USA|       NULL|   NULL|        10|       8630.0|\n",
      "|    USA|       NULL| Online|         6|       4370.0|\n",
      "|    USA|       NULL|  Store|         4|       4260.0|\n",
      "|    USA|      Books|   NULL|         2|        260.0|\n",
      "|    USA|      Books| Online|         1|        140.0|\n",
      "|    USA|      Books|  Store|         1|        120.0|\n",
      "|    USA|   Clothing|   NULL|         3|        670.0|\n",
      "|    USA|   Clothing| Online|         2|        430.0|\n",
      "|    USA|   Clothing|  Store|         1|        240.0|\n",
      "|    USA|Electronics|   NULL|         5|       7700.0|\n",
      "|    USA|Electronics| Online|         3|       3800.0|\n",
      "|    USA|Electronics|  Store|         2|       3900.0|\n",
      "+-------+-----------+-------+----------+-------------+\n",
      "\n",
      "\n",
      "ðŸ”¹ Comparison - Rollup vs Cube:\n",
      "Rollup combinations: 13\n",
      "Cube combinations: 16\n",
      "\n",
      "Rollup: Hierarchical (country -> category -> total)\n",
      "Cube: All combinations (country, category, country+category, total)\n"
     ]
    }
   ],
   "source": [
    "# 6.1 Basic cube\n",
    "print(\"ðŸ”¹ Cube - Country and Category:\")\n",
    "cube_basic = df.cube(\"country\", \"category\") \\\n",
    "    .agg(\n",
    "        count(\"*\").alias(\"num_orders\"),\n",
    "        sum(\"total_amount\").alias(\"total_revenue\")\n",
    "    ) \\\n",
    "    .orderBy(\"country\", \"category\")\n",
    "\n",
    "cube_basic.show(30)\n",
    "\n",
    "print(\"\"\"\n",
    "ðŸ“ CUBE EXPLANATION:\n",
    "- Rows with both country AND category: Detail level\n",
    "- Rows with country but NULL category: Country subtotal\n",
    "- Rows with NULL country but has category: Category subtotal (across all countries)\n",
    "- Row with NULL country and NULL category: Grand total\n",
    "\"\"\")\n",
    "\n",
    "# 6.2 Cube with level identification\n",
    "print(\"\\nðŸ”¹ Cube with level identification:\")\n",
    "cube_labeled = df.cube(\"country\", \"category\") \\\n",
    "    .agg(\n",
    "        count(\"*\").alias(\"num_orders\"),\n",
    "        sum(\"total_amount\").alias(\"total_revenue\")\n",
    "    ) \\\n",
    "    .withColumn(\n",
    "        \"level\",\n",
    "        when(col(\"country\").isNull() & col(\"category\").isNull(), \"Grand Total\")\n",
    "        .when(col(\"country\").isNull(), \"Category Total\")\n",
    "        .when(col(\"category\").isNull(), \"Country Total\")\n",
    "        .otherwise(\"Detail\")\n",
    "    ) \\\n",
    "    .orderBy(\"level\", \"country\", \"category\")\n",
    "\n",
    "cube_labeled.show(30)\n",
    "\n",
    "# 6.3 Cube with 3 dimensions\n",
    "print(\"\\nðŸ”¹ Cube - Country, Category, Channel:\")\n",
    "cube_3d = df.cube(\"country\", \"category\", \"channel\") \\\n",
    "    .agg(\n",
    "        count(\"*\").alias(\"num_orders\"),\n",
    "        sum(\"total_amount\").alias(\"total_revenue\")\n",
    "    ) \\\n",
    "    .orderBy(\"country\", \"category\", \"channel\")\n",
    "\n",
    "print(f\"Total combinations: {cube_3d.count()}\")\n",
    "cube_3d.show(50)\n",
    "\n",
    "# 6.4 Compare Rollup vs Cube\n",
    "print(\"\\nðŸ”¹ Comparison - Rollup vs Cube:\")\n",
    "rollup_count = df.rollup(\"country\", \"category\").count().count()\n",
    "cube_count = df.cube(\"country\", \"category\").count().count()\n",
    "\n",
    "print(f\"Rollup combinations: {rollup_count}\")\n",
    "print(f\"Cube combinations: {cube_count}\")\n",
    "print(f\"\\nRollup: Hierarchical (country -> category -> total)\")\n",
    "print(f\"Cube: All combinations (country, category, country+category, total)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸªŸ **7. WINDOW AGGREGATIONS**\n",
    "\n",
    "Aggregations over a window of rows (preview for next lesson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¹ Running total by country:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-------+------------+-------------+\n",
      "|order_id|order_date|country|total_amount|running_total|\n",
      "+--------+----------+-------+------------+-------------+\n",
      "|  ORD011|2024-01-15| Canada|      1200.0|       1200.0|\n",
      "|  ORD013|2024-01-16| Canada|        50.0|       1490.0|\n",
      "|  ORD012|2024-01-16| Canada|       240.0|       1490.0|\n",
      "|  ORD014|2024-01-17| Canada|      1200.0|       2790.0|\n",
      "|  ORD015|2024-01-17| Canada|       100.0|       2790.0|\n",
      "|  ORD006|2024-01-15|     UK|      1200.0|       1200.0|\n",
      "|  ORD007|2024-01-16|     UK|       200.0|       3000.0|\n",
      "|  ORD008|2024-01-16|     UK|      1600.0|       3000.0|\n",
      "|  ORD009|2024-01-17|     UK|       300.0|       3480.0|\n",
      "|  ORD010|2024-01-17|     UK|       180.0|       3480.0|\n",
      "|  ORD021|2024-01-18|     UK|       500.0|       4180.0|\n",
      "|  ORD022|2024-01-18|     UK|       200.0|       4180.0|\n",
      "|  ORD023|2024-01-19|     UK|       150.0|       4630.0|\n",
      "|  ORD024|2024-01-19|     UK|       300.0|       4630.0|\n",
      "|  ORD025|2024-01-20|     UK|       200.0|       4830.0|\n",
      "|  ORD001|2024-01-15|    USA|      2400.0|       4800.0|\n",
      "|  ORD002|2024-01-15|    USA|      2400.0|       4800.0|\n",
      "|  ORD003|2024-01-16|    USA|       250.0|       5650.0|\n",
      "|  ORD004|2024-01-16|    USA|       600.0|       5650.0|\n",
      "|  ORD005|2024-01-17|    USA|       240.0|       5890.0|\n",
      "+--------+----------+-------+------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "\n",
      "ðŸ”¹ Moving average (3-day window):\n",
      "+--------+----------+-------+------------+------------------+\n",
      "|order_id|order_date|country|total_amount|   moving_avg_3day|\n",
      "+--------+----------+-------+------------+------------------+\n",
      "|  ORD011|2024-01-15| Canada|      1200.0|            1200.0|\n",
      "|  ORD012|2024-01-16| Canada|       240.0|             720.0|\n",
      "|  ORD013|2024-01-16| Canada|        50.0| 496.6666666666667|\n",
      "|  ORD014|2024-01-17| Canada|      1200.0| 496.6666666666667|\n",
      "|  ORD015|2024-01-17| Canada|       100.0|             450.0|\n",
      "|  ORD006|2024-01-15|     UK|      1200.0|            1200.0|\n",
      "|  ORD007|2024-01-16|     UK|       200.0|             700.0|\n",
      "|  ORD008|2024-01-16|     UK|      1600.0|            1000.0|\n",
      "|  ORD009|2024-01-17|     UK|       300.0|             700.0|\n",
      "|  ORD010|2024-01-17|     UK|       180.0| 693.3333333333334|\n",
      "|  ORD021|2024-01-18|     UK|       500.0| 326.6666666666667|\n",
      "|  ORD022|2024-01-18|     UK|       200.0| 293.3333333333333|\n",
      "|  ORD023|2024-01-19|     UK|       150.0| 283.3333333333333|\n",
      "|  ORD024|2024-01-19|     UK|       300.0|216.66666666666666|\n",
      "|  ORD025|2024-01-20|     UK|       200.0|216.66666666666666|\n",
      "|  ORD001|2024-01-15|    USA|      2400.0|            2400.0|\n",
      "|  ORD002|2024-01-15|    USA|      2400.0|            2400.0|\n",
      "|  ORD003|2024-01-16|    USA|       250.0|1683.3333333333333|\n",
      "|  ORD004|2024-01-16|    USA|       600.0|1083.3333333333333|\n",
      "|  ORD005|2024-01-17|    USA|       240.0| 363.3333333333333|\n",
      "+--------+----------+-------+------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "\n",
      "ðŸ”¹ Cumulative count:\n",
      "+--------+----------+-------+------------+------------+\n",
      "|order_id|order_date|country|total_amount|order_number|\n",
      "+--------+----------+-------+------------+------------+\n",
      "|  ORD011|2024-01-15| Canada|      1200.0|           1|\n",
      "|  ORD012|2024-01-16| Canada|       240.0|           3|\n",
      "|  ORD013|2024-01-16| Canada|        50.0|           3|\n",
      "|  ORD014|2024-01-17| Canada|      1200.0|           5|\n",
      "|  ORD015|2024-01-17| Canada|       100.0|           5|\n",
      "|  ORD006|2024-01-15|     UK|      1200.0|           1|\n",
      "|  ORD007|2024-01-16|     UK|       200.0|           3|\n",
      "|  ORD008|2024-01-16|     UK|      1600.0|           3|\n",
      "|  ORD009|2024-01-17|     UK|       300.0|           5|\n",
      "|  ORD010|2024-01-17|     UK|       180.0|           5|\n",
      "|  ORD021|2024-01-18|     UK|       500.0|           7|\n",
      "|  ORD022|2024-01-18|     UK|       200.0|           7|\n",
      "|  ORD023|2024-01-19|     UK|       150.0|           9|\n",
      "|  ORD024|2024-01-19|     UK|       300.0|           9|\n",
      "|  ORD025|2024-01-20|     UK|       200.0|          10|\n",
      "|  ORD001|2024-01-15|    USA|      2400.0|           2|\n",
      "|  ORD002|2024-01-15|    USA|      2400.0|           2|\n",
      "|  ORD003|2024-01-16|    USA|       250.0|           4|\n",
      "|  ORD004|2024-01-16|    USA|       600.0|           4|\n",
      "|  ORD005|2024-01-17|    USA|       240.0|           5|\n",
      "+--------+----------+-------+------------+------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "\n",
      "ðŸ’¡ More window functions in next lesson (03_window_functions.ipynb)!\n"
     ]
    }
   ],
   "source": [
    "# 7.1 Running total\n",
    "print(\"ðŸ”¹ Running total by country:\")\n",
    "windowSpec = Window.partitionBy(\"country\").orderBy(\"order_date\")\n",
    "\n",
    "running_total = df.withColumn(\n",
    "    \"running_total\",\n",
    "    sum(\"total_amount\").over(windowSpec)\n",
    ").select(\n",
    "    \"order_id\",\n",
    "    \"order_date\",\n",
    "    \"country\",\n",
    "    \"total_amount\",\n",
    "    \"running_total\"\n",
    ").orderBy(\"country\", \"order_date\")\n",
    "\n",
    "running_total.show(20)\n",
    "\n",
    "# 7.2 Moving average\n",
    "print(\"\\nðŸ”¹ Moving average (3-day window):\")\n",
    "windowSpec3 = Window.partitionBy(\"country\") \\\n",
    "    .orderBy(\"order_date\") \\\n",
    "    .rowsBetween(-2, 0)  # Current row and 2 rows before\n",
    "\n",
    "moving_avg = df.withColumn(\n",
    "    \"moving_avg_3day\",\n",
    "    avg(\"total_amount\").over(windowSpec3)\n",
    ").select(\n",
    "    \"order_id\",\n",
    "    \"order_date\",\n",
    "    \"country\",\n",
    "    \"total_amount\",\n",
    "    \"moving_avg_3day\"\n",
    ").orderBy(\"country\", \"order_date\")\n",
    "\n",
    "moving_avg.show(20)\n",
    "\n",
    "# 7.3 Cumulative count\n",
    "print(\"\\nðŸ”¹ Cumulative count:\")\n",
    "cumulative = df.withColumn(\n",
    "    \"order_number\",\n",
    "    count(\"*\").over(windowSpec)\n",
    ").select(\n",
    "    \"order_id\",\n",
    "    \"order_date\",\n",
    "    \"country\",\n",
    "    \"total_amount\",\n",
    "    \"order_number\"\n",
    ").orderBy(\"country\", \"order_date\")\n",
    "\n",
    "cumulative.show(20)\n",
    "\n",
    "print(\"\\nðŸ’¡ More window functions in next lesson (03_window_functions.ipynb)!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸŽ¯ **8. ADVANCED AGGREGATION PATTERNS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¹ Percentiles:\n",
      "+-----+----------+------+------+\n",
      "|  p25|p50_median|   p75|   p95|\n",
      "+-----+----------+------+------+\n",
      "|180.0|     250.0|1200.0|2400.0|\n",
      "+-----+----------+------+------+\n",
      "\n",
      "\n",
      "ðŸ”¹ Percentiles by category:\n",
      "+-----------+------+------+\n",
      "|   category|median|   p95|\n",
      "+-----------+------+------+\n",
      "|Electronics|1200.0|2400.0|\n",
      "|   Clothing| 200.0| 300.0|\n",
      "|      Books| 140.0| 200.0|\n",
      "+-----------+------+------+\n",
      "\n",
      "\n",
      "ðŸ”¹ First and last orders by country:\n",
      "+-------+----------------+---------------+------------------+-----------------+\n",
      "|country|first_order_date|last_order_date|first_order_amount|last_order_amount|\n",
      "+-------+----------------+---------------+------------------+-----------------+\n",
      "|    USA|      2024-01-18|     2024-01-17|             800.0|            240.0|\n",
      "|     UK|      2024-01-18|     2024-01-17|             500.0|            180.0|\n",
      "| Canada|      2024-01-16|     2024-01-16|              50.0|            240.0|\n",
      "+-------+----------------+---------------+------------------+-----------------+\n",
      "\n",
      "\n",
      "ðŸ”¹ Conditional aggregations:\n",
      "+-------+------------+-------------+------------+--------------+-------------+\n",
      "|country|total_orders|online_orders|store_orders|online_revenue|store_revenue|\n",
      "+-------+------------+-------------+------------+--------------+-------------+\n",
      "|    USA|          10|            6|           4|        4370.0|       4260.0|\n",
      "|     UK|          10|            6|           4|        3830.0|       1000.0|\n",
      "| Canada|           5|            3|           2|        2450.0|        340.0|\n",
      "+-------+------------+-------------+------------+--------------+-------------+\n",
      "\n",
      "\n",
      "ðŸ”¹ Weighted average (price weighted by quantity):\n",
      "+-----------+------------------+\n",
      "|   category|weighted_avg_price|\n",
      "+-----------+------------------+\n",
      "|Electronics| 456.6666666666667|\n",
      "|   Clothing|           53.4375|\n",
      "|      Books|23.333333333333332|\n",
      "+-----------+------------------+\n",
      "\n",
      "\n",
      "ðŸ”¹ Most popular product by category:\n",
      "+-----------+--------------------+----------+\n",
      "|   category|most_popular_product|num_orders|\n",
      "+-----------+--------------------+----------+\n",
      "|      Books|           Biography|         1|\n",
      "|   Clothing|               Scarf|         1|\n",
      "|Electronics|              Laptop|         3|\n",
      "+-----------+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 8.1 Percentiles and quantiles\n",
    "print(\"ðŸ”¹ Percentiles:\")\n",
    "percentiles = df.select(\n",
    "    expr(\"percentile_approx(total_amount, 0.25)\").alias(\"p25\"),\n",
    "    expr(\"percentile_approx(total_amount, 0.50)\").alias(\"p50_median\"),\n",
    "    expr(\"percentile_approx(total_amount, 0.75)\").alias(\"p75\"),\n",
    "    expr(\"percentile_approx(total_amount, 0.95)\").alias(\"p95\")\n",
    ")\n",
    "\n",
    "percentiles.show()\n",
    "\n",
    "# 8.2 Percentiles by group\n",
    "print(\"\\nðŸ”¹ Percentiles by category:\")\n",
    "percentiles_by_category = df.groupBy(\"category\").agg(\n",
    "    expr(\"percentile_approx(total_amount, 0.50)\").alias(\"median\"),\n",
    "    expr(\"percentile_approx(total_amount, 0.95)\").alias(\"p95\")\n",
    ")\n",
    "\n",
    "percentiles_by_category.show()\n",
    "\n",
    "# 8.3 First/Last values\n",
    "print(\"\\nðŸ”¹ First and last orders by country:\")\n",
    "first_last = df.groupBy(\"country\").agg(\n",
    "    first(\"order_date\").alias(\"first_order_date\"),\n",
    "    last(\"order_date\").alias(\"last_order_date\"),\n",
    "    first(\"total_amount\").alias(\"first_order_amount\"),\n",
    "    last(\"total_amount\").alias(\"last_order_amount\")\n",
    ")\n",
    "\n",
    "first_last.show()\n",
    "\n",
    "# 8.4 Conditional aggregations\n",
    "print(\"\\nðŸ”¹ Conditional aggregations:\")\n",
    "conditional_agg = df.groupBy(\"country\").agg(\n",
    "    count(\"*\").alias(\"total_orders\"),\n",
    "    sum(when(col(\"channel\") == \"Online\", 1).otherwise(0)).alias(\"online_orders\"),\n",
    "    sum(when(col(\"channel\") == \"Store\", 1).otherwise(0)).alias(\"store_orders\"),\n",
    "    sum(when(col(\"channel\") == \"Online\", col(\"total_amount\")).otherwise(0)).alias(\"online_revenue\"),\n",
    "    sum(when(col(\"channel\") == \"Store\", col(\"total_amount\")).otherwise(0)).alias(\"store_revenue\")\n",
    ")\n",
    "\n",
    "conditional_agg.show()\n",
    "\n",
    "# 8.5 Weighted average\n",
    "print(\"\\nðŸ”¹ Weighted average (price weighted by quantity):\")\n",
    "weighted_avg = df.groupBy(\"category\").agg(\n",
    "    sum(col(\"price\") * col(\"quantity\")).alias(\"weighted_sum\"),\n",
    "    sum(\"quantity\").alias(\"total_quantity\")\n",
    ").withColumn(\n",
    "    \"weighted_avg_price\",\n",
    "    col(\"weighted_sum\") / col(\"total_quantity\")\n",
    ").select(\"category\", \"weighted_avg_price\")\n",
    "\n",
    "weighted_avg.show()\n",
    "\n",
    "# 8.6 Mode (most frequent value)\n",
    "print(\"\\nðŸ”¹ Most popular product by category:\")\n",
    "mode_product = df.groupBy(\"category\", \"product\").count() \\\n",
    "    .withColumn(\n",
    "        \"rank\",\n",
    "        row_number().over(Window.partitionBy(\"category\").orderBy(desc(\"count\")))\n",
    "    ) \\\n",
    "    .filter(col(\"rank\") == 1) \\\n",
    "    .select(\"category\", \"product\", \"count\") \\\n",
    "    .withColumnRenamed(\"product\", \"most_popular_product\") \\\n",
    "    .withColumnRenamed(\"count\", \"num_orders\")\n",
    "\n",
    "mode_product.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸ“Š **9. COMPREHENSIVE SALES REPORT**\n",
    "\n",
    "Táº¡o bÃ¡o cÃ¡o tá»•ng há»£p hoÃ n chá»‰nh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ðŸ“Š EXECUTIVE SUMMARY\n",
      "================================================================================\n",
      "+------------+----------------+-------------+---------------+----------------+\n",
      "|total_orders|unique_customers|total_revenue|avg_order_value|total_items_sold|\n",
      "+------------+----------------+-------------+---------------+----------------+\n",
      "|          25|              24|      16250.0|          650.0|              98|\n",
      "+------------+----------------+-------------+---------------+----------------+\n",
      "\n",
      "\n",
      "ðŸ“ REVENUE BY COUNTRY:\n",
      "+-------+------+-------+---------------+----------+-----------+\n",
      "|country|orders|revenue|avg_order_value|items_sold|revenue_pct|\n",
      "+-------+------+-------+---------------+----------+-----------+\n",
      "|    USA|    10| 8630.0|          863.0|        37|      53.11|\n",
      "|     UK|    10| 4830.0|          483.0|        50|      29.72|\n",
      "| Canada|     5| 2790.0|          558.0|        11|      17.17|\n",
      "+-------+------+-------+---------------+----------+-----------+\n",
      "\n",
      "\n",
      "ðŸ“¦ CATEGORY PERFORMANCE:\n",
      "+-----------+------+-------+------------------+------------+\n",
      "|   category|orders|revenue|   avg_order_value|num_products|\n",
      "+-----------+------+-------+------------------+------------+\n",
      "|Electronics|    11|13700.0|1245.4545454545455|           7|\n",
      "|   Clothing|     8| 1710.0|            213.75|           8|\n",
      "|      Books|     6|  840.0|             140.0|           6|\n",
      "+-----------+------+-------+------------------+------------+\n",
      "\n",
      "\n",
      "ðŸ›’ CHANNEL PERFORMANCE:\n",
      "+-------+------+-------+---------------+-----------+\n",
      "|channel|orders|revenue|avg_order_value|revenue_pct|\n",
      "+-------+------+-------+---------------+-----------+\n",
      "| Online|    15|10650.0|          710.0|      65.54|\n",
      "|  Store|    10| 5600.0|          560.0|      34.46|\n",
      "+-------+------+-------+---------------+-----------+\n",
      "\n",
      "\n",
      "ðŸ“ˆ DAILY TREND:\n",
      "+----------+------+-------+---------------+\n",
      "|order_date|orders|revenue|avg_order_value|\n",
      "+----------+------+-------+---------------+\n",
      "|2024-01-15|     4| 7200.0|         1800.0|\n",
      "|2024-01-16|     6| 2940.0|          490.0|\n",
      "|2024-01-17|     5| 2020.0|          404.0|\n",
      "|2024-01-18|     4| 1620.0|          405.0|\n",
      "|2024-01-19|     4| 2130.0|          532.5|\n",
      "|2024-01-20|     2|  340.0|          170.0|\n",
      "+----------+------+-------+---------------+\n",
      "\n",
      "\n",
      "ðŸ† TOP 10 PRODUCTS:\n",
      "+----------+-----------+------+-------------+-------+\n",
      "|product   |category   |orders|quantity_sold|revenue|\n",
      "+----------+-----------+------+-------------+-------+\n",
      "|Laptop    |Electronics|3     |4            |4800.0 |\n",
      "|Phone     |Electronics|2     |5            |4000.0 |\n",
      "|Tablet    |Electronics|2     |3            |1800.0 |\n",
      "|Camera    |Electronics|1     |1            |1500.0 |\n",
      "|Headphones|Electronics|1     |4            |800.0  |\n",
      "|Mouse     |Electronics|1     |10           |500.0  |\n",
      "|Keyboard  |Electronics|1     |3            |300.0  |\n",
      "|Jacket    |Clothing   |1     |2            |300.0  |\n",
      "|Shirt     |Clothing   |1     |5            |250.0  |\n",
      "|Pants     |Clothing   |1     |3            |240.0  |\n",
      "+----------+-----------+------+-------------+-------+\n",
      "\n",
      "\n",
      "ðŸ‘¥ TOP 10 CUSTOMERS:\n",
      "+--------------+------+-----------+---------------+\n",
      "|customer_name |orders|total_spent|avg_order_value|\n",
      "+--------------+------+-----------+---------------+\n",
      "|John Doe      |2     |3000.0     |1500.0         |\n",
      "|Jane Smith    |1     |2400.0     |2400.0         |\n",
      "|Eve Davis     |1     |1600.0     |1600.0         |\n",
      "|Paul Martinez |1     |1500.0     |1500.0         |\n",
      "|Henry Taylor  |1     |1200.0     |1200.0         |\n",
      "|Charlie Wilson|1     |1200.0     |1200.0         |\n",
      "|Karen Jackson |1     |1200.0     |1200.0         |\n",
      "|Mia Harris    |1     |800.0      |800.0          |\n",
      "|Rachel Clark  |1     |500.0      |500.0          |\n",
      "|Frank Miller  |1     |300.0      |300.0          |\n",
      "+--------------+------+-----------+---------------+\n",
      "\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# 9.1 Executive Summary\n",
    "print(\"=\"*80)\n",
    "print(\"ðŸ“Š EXECUTIVE SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "exec_summary = df.select(\n",
    "    count(\"*\").alias(\"total_orders\"),\n",
    "    countDistinct(\"customer_name\").alias(\"unique_customers\"),\n",
    "    sum(\"total_amount\").alias(\"total_revenue\"),\n",
    "    avg(\"total_amount\").alias(\"avg_order_value\"),\n",
    "    sum(\"quantity\").alias(\"total_items_sold\")\n",
    ")\n",
    "\n",
    "exec_summary.show()\n",
    "\n",
    "# Láº¥y total revenue Ä‘á»ƒ tÃ­nh pháº§n trÄƒm\n",
    "total_revenue = exec_summary.select(\"total_revenue\").collect()[0][\"total_revenue\"]\n",
    "\n",
    "# 9.2 Revenue by Country - FIXED\n",
    "print(\"\\nðŸ“ REVENUE BY COUNTRY:\")\n",
    "country_report = df.groupBy(\"country\").agg(\n",
    "    count(\"*\").alias(\"orders\"),\n",
    "    sum(\"total_amount\").alias(\"revenue\"),\n",
    "    avg(\"total_amount\").alias(\"avg_order_value\"),\n",
    "    sum(\"quantity\").alias(\"items_sold\")\n",
    ").withColumn(\n",
    "    \"revenue_pct\",\n",
    "    round((col(\"revenue\") / lit(total_revenue)) * 100, 2)\n",
    ").orderBy(desc(\"revenue\"))\n",
    "\n",
    "country_report.show()\n",
    "\n",
    "# 9.3 Category Performance\n",
    "print(\"\\nðŸ“¦ CATEGORY PERFORMANCE:\")\n",
    "category_report = df.groupBy(\"category\").agg(\n",
    "    count(\"*\").alias(\"orders\"),\n",
    "    sum(\"total_amount\").alias(\"revenue\"),\n",
    "    avg(\"total_amount\").alias(\"avg_order_value\"),\n",
    "    countDistinct(\"product\").alias(\"num_products\")\n",
    ").orderBy(desc(\"revenue\"))\n",
    "\n",
    "category_report.show()\n",
    "\n",
    "# 9.4 Channel Performance - FIXED\n",
    "print(\"\\nðŸ›’ CHANNEL PERFORMANCE:\")\n",
    "channel_report = df.groupBy(\"channel\").agg(\n",
    "    count(\"*\").alias(\"orders\"),\n",
    "    sum(\"total_amount\").alias(\"revenue\"),\n",
    "    avg(\"total_amount\").alias(\"avg_order_value\")\n",
    ").withColumn(\n",
    "    \"revenue_pct\",\n",
    "    round((col(\"revenue\") / lit(total_revenue)) * 100, 2)\n",
    ").orderBy(desc(\"revenue\"))\n",
    "\n",
    "channel_report.show()\n",
    "\n",
    "# 9.5 Daily Trend\n",
    "print(\"\\nðŸ“ˆ DAILY TREND:\")\n",
    "daily_trend = df.groupBy(\"order_date\").agg(\n",
    "    count(\"*\").alias(\"orders\"),\n",
    "    sum(\"total_amount\").alias(\"revenue\"),\n",
    "    avg(\"total_amount\").alias(\"avg_order_value\")\n",
    ").orderBy(\"order_date\")\n",
    "\n",
    "daily_trend.show()\n",
    "\n",
    "# 9.6 Top Products\n",
    "print(\"\\nðŸ† TOP 10 PRODUCTS:\")\n",
    "top_products = df.groupBy(\"product\", \"category\").agg(\n",
    "    count(\"*\").alias(\"orders\"),\n",
    "    sum(\"quantity\").alias(\"quantity_sold\"),\n",
    "    sum(\"total_amount\").alias(\"revenue\")\n",
    ").orderBy(desc(\"revenue\")).limit(10)\n",
    "\n",
    "top_products.show(truncate=False)\n",
    "\n",
    "# 9.7 Top Customers\n",
    "print(\"\\nðŸ‘¥ TOP 10 CUSTOMERS:\")\n",
    "top_customers = df.groupBy(\"customer_name\").agg(\n",
    "    count(\"*\").alias(\"orders\"),\n",
    "    sum(\"total_amount\").alias(\"total_spent\"),\n",
    "    avg(\"total_amount\").alias(\"avg_order_value\")\n",
    ").orderBy(desc(\"total_spent\")).limit(10)\n",
    "\n",
    "top_customers.show(truncate=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸ’¾ **10. SAVE AGGREGATED DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save aggregated reports to MinIO\n",
    "base_path = \"s3a://warehouse/aggregated_reports/\"\n",
    "\n",
    "# Save country report\n",
    "country_report.write.mode(\"overwrite\").parquet(f\"{base_path}country_report/\")\n",
    "print(f\"âœ… Country report saved to: {base_path}country_report/\")\n",
    "\n",
    "# Save category report\n",
    "category_report.write.mode(\"overwrite\").parquet(f\"{base_path}category_report/\")\n",
    "print(f\"âœ… Category report saved to: {base_path}category_report/\")\n",
    "\n",
    "# Save daily trend\n",
    "daily_trend.write.mode(\"overwrite\").partitionBy(\"order_date\").parquet(f\"{base_path}daily_trend/\")\n",
    "print(f\"âœ… Daily trend saved to: {base_path}daily_trend/\")\n",
    "\n",
    "# Save pivot table\n",
    "pivot_filled.write.mode(\"overwrite\").parquet(f\"{base_path}pivot_country_category/\")\n",
    "print(f\"âœ… Pivot table saved to: {base_path}pivot_country_category/\")\n",
    "\n",
    "# Verify\n",
    "print(\"\\nâœ… VERIFICATION:\")\n",
    "df_verify = spark.read.parquet(f\"{base_path}country_report/\")\n",
    "print(f\"Country report rows: {df_verify.count()}\")\n",
    "df_verify.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸŽ“ **KEY TAKEAWAYS**\n",
    "\n",
    "### **âœ… What You Learned:**\n",
    "\n",
    "1. **Basic Aggregations** - count, sum, avg, min, max, stddev\n",
    "2. **GroupBy** - Single and multiple columns, filtering\n",
    "3. **Multiple Aggregations** - agg() with multiple functions\n",
    "4. **Pivot Tables** - Transform rows to columns\n",
    "5. **Rollup** - Hierarchical subtotals (country â†’ category â†’ total)\n",
    "6. **Cube** - All combinations of dimensions\n",
    "7. **Window Aggregations** - Running totals, moving averages\n",
    "8. **Advanced Patterns** - Percentiles, conditional agg, weighted avg\n",
    "\n",
    "### **ðŸ“Š Aggregation Comparison:**\n",
    "\n",
    "| Type | Use Case | Example |\n",
    "|------|----------|----------|\n",
    "| **GroupBy** | Standard grouping | Sales by country |\n",
    "| **Pivot** | Cross-tabulation | Country vs Category matrix |\n",
    "| **Rollup** | Hierarchical totals | Country â†’ Category â†’ Total |\n",
    "| **Cube** | All combinations | All possible groupings |\n",
    "| **Window** | Running calculations | Cumulative sum, moving avg |\n",
    "\n",
    "### **âš¡ Performance Tips:**\n",
    "\n",
    "1. **Use approx_count_distinct** for large datasets (faster)\n",
    "2. **Specify pivot values** explicitly (better performance)\n",
    "3. **Filter before aggregating** (reduce data size)\n",
    "4. **Use broadcast joins** for small lookup tables\n",
    "5. **Cache intermediate results** if reused\n",
    "6. **Avoid collect()** on large aggregated data\n",
    "\n",
    "### **ðŸš€ Next Steps:**\n",
    "- **Day 3 - Lesson 3:** Window Functions (ranking, lag/lead, percentiles)\n",
    "- **Day 3 - Lesson 4:** Joins (inner, outer, broadcast, optimization)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "spark.stop()\n",
    "print(\"âœ… Spark session stopped\")\n",
    "print(\"\\nðŸŽ‰ DAY 3 - LESSON 2 COMPLETED!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
