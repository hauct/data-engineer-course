{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ ADVANCED TRANSFORMATIONS WITH PYSPARK\n",
    "\n",
    "---\n",
    "\n",
    "## üìã **DAY 3 - LESSON 1: ADVANCED TRANSFORMATIONS**\n",
    "\n",
    "### **üéØ OBJECTIVES:**\n",
    "\n",
    "1. **Complex Transformations** - withColumn, select, expr\n",
    "2. **Conditional Logic** - when/otherwise, case statements\n",
    "3. **String Operations** - concat, split, regex, substring\n",
    "4. **Date/Time Operations** - date_add, date_diff, date_format\n",
    "5. **Array Operations** - explode, array functions\n",
    "6. **Struct Operations** - nested data handling\n",
    "7. **User Defined Functions (UDFs)** - Python UDFs, Pandas UDFs\n",
    "8. **Performance Best Practices** - Avoid UDFs when possible\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß **SETUP SPARK SESSION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "26/01/08 15:53:27 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Spark Session Created\n",
      "Spark Version: 3.5.1\n",
      "Master: spark://spark-master:7077\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"AdvancedTransformations\") \\\n",
    "    .master(\"spark://spark-master:7077\") \\\n",
    "    .config(\"spark.executor.memory\", \"2g\") \\\n",
    "    .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
    "    .config(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.endpoint\", \"http://minio:9000\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.access.key\", \"minioadmin\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.secret.key\", \"minioadmin123\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"‚úÖ Spark Session Created\")\n",
    "print(f\"Spark Version: {spark.version}\")\n",
    "print(f\"Master: {spark.sparkContext.master}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìä **1. CREATE SAMPLE DATASET**\n",
    "\n",
    "T·∫°o dataset ph·ª©c t·∫°p ƒë·ªÉ th·ª±c h√†nh transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä SAMPLE DATASET:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+--------------+------------------------+--------------------------------------------+----------------------------+-------------------+-------+---------+\n",
      "|order_id|customer_id|customer_name |email                   |products                                    |prices                      |order_timestamp    |country|status   |\n",
      "+--------+-----------+--------------+------------------------+--------------------------------------------+----------------------------+-------------------+-------+---------+\n",
      "|ORD001  |CUST001    |John Doe      |john.doe@email.com      |[Product A, Product B]                      |[100.0, 200.0]              |2024-01-15 10:30:00|USA    |completed|\n",
      "|ORD002  |CUST002    |Jane Smith    |jane.smith@email.com    |[Product C]                                 |[150.0]                     |2024-01-16 14:20:00|UK     |pending  |\n",
      "|ORD003  |CUST003    |Bob Johnson   |bob.johnson@email.com   |[Product A, Product C, Product D]           |[100.0, 150.0, 250.0]       |2024-01-17 09:15:00|Canada |completed|\n",
      "|ORD004  |CUST001    |John Doe      |john.doe@email.com      |[Product B, Product D]                      |[200.0, 250.0]              |2024-01-18 16:45:00|USA    |cancelled|\n",
      "|ORD005  |CUST004    |Alice Brown   |alice.brown@email.com   |[Product A]                                 |[100.0]                     |2024-01-19 11:00:00|USA    |completed|\n",
      "|ORD006  |CUST005    |Charlie Wilson|charlie.wilson@email.com|[Product B, Product C]                      |[200.0, 150.0]              |2024-01-20 13:30:00|UK     |completed|\n",
      "|ORD007  |CUST002    |Jane Smith    |jane.smith@email.com    |[Product D]                                 |[250.0]                     |2024-01-21 15:20:00|UK     |pending  |\n",
      "|ORD008  |CUST006    |David Lee     |david.lee@email.com     |[Product A, Product B, Product C, Product D]|[100.0, 200.0, 150.0, 250.0]|2024-01-22 10:10:00|Canada |completed|\n",
      "+--------+-----------+--------------+------------------------+--------------------------------------------+----------------------------+-------------------+-------+---------+\n",
      "\n",
      "\n",
      "Total rows: 8\n",
      "root\n",
      " |-- order_id: string (nullable = true)\n",
      " |-- customer_id: string (nullable = true)\n",
      " |-- customer_name: string (nullable = true)\n",
      " |-- email: string (nullable = true)\n",
      " |-- products: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- prices: array (nullable = true)\n",
      " |    |-- element: double (containsNull = true)\n",
      " |-- order_timestamp: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create complex sample data\n",
    "data = [\n",
    "    (\"ORD001\", \"CUST001\", \"John Doe\", \"john.doe@email.com\", \n",
    "     [\"Product A\", \"Product B\"], [100.0, 200.0], \"2024-01-15 10:30:00\", \"USA\", \"completed\"),\n",
    "    \n",
    "    (\"ORD002\", \"CUST002\", \"Jane Smith\", \"jane.smith@email.com\", \n",
    "     [\"Product C\"], [150.0], \"2024-01-16 14:20:00\", \"UK\", \"pending\"),\n",
    "    \n",
    "    (\"ORD003\", \"CUST003\", \"Bob Johnson\", \"bob.johnson@email.com\", \n",
    "     [\"Product A\", \"Product C\", \"Product D\"], [100.0, 150.0, 250.0], \"2024-01-17 09:15:00\", \"Canada\", \"completed\"),\n",
    "    \n",
    "    (\"ORD004\", \"CUST001\", \"John Doe\", \"john.doe@email.com\", \n",
    "     [\"Product B\", \"Product D\"], [200.0, 250.0], \"2024-01-18 16:45:00\", \"USA\", \"cancelled\"),\n",
    "    \n",
    "    (\"ORD005\", \"CUST004\", \"Alice Brown\", \"alice.brown@email.com\", \n",
    "     [\"Product A\"], [100.0], \"2024-01-19 11:00:00\", \"USA\", \"completed\"),\n",
    "    \n",
    "    (\"ORD006\", \"CUST005\", \"Charlie Wilson\", \"charlie.wilson@email.com\", \n",
    "     [\"Product B\", \"Product C\"], [200.0, 150.0], \"2024-01-20 13:30:00\", \"UK\", \"completed\"),\n",
    "    \n",
    "    (\"ORD007\", \"CUST002\", \"Jane Smith\", \"jane.smith@email.com\", \n",
    "     [\"Product D\"], [250.0], \"2024-01-21 15:20:00\", \"UK\", \"pending\"),\n",
    "    \n",
    "    (\"ORD008\", \"CUST006\", \"David Lee\", \"david.lee@email.com\", \n",
    "     [\"Product A\", \"Product B\", \"Product C\", \"Product D\"], [100.0, 200.0, 150.0, 250.0], \n",
    "     \"2024-01-22 10:10:00\", \"Canada\", \"completed\"),\n",
    "]\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"order_id\", StringType(), True),\n",
    "    StructField(\"customer_id\", StringType(), True),\n",
    "    StructField(\"customer_name\", StringType(), True),\n",
    "    StructField(\"email\", StringType(), True),\n",
    "    StructField(\"products\", ArrayType(StringType()), True),\n",
    "    StructField(\"prices\", ArrayType(DoubleType()), True),\n",
    "    StructField(\"order_timestamp\", StringType(), True),\n",
    "    StructField(\"country\", StringType(), True),\n",
    "    StructField(\"status\", StringType(), True)\n",
    "])\n",
    "\n",
    "df = spark.createDataFrame(data, schema)\n",
    "\n",
    "print(\"üìä SAMPLE DATASET:\")\n",
    "df.show(truncate=False)\n",
    "print(f\"\\nTotal rows: {df.count()}\")\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üîÑ **2. BASIC TRANSFORMATIONS REVIEW**\n",
    "\n",
    "√în t·∫≠p c√°c transformations c∆° b·∫£n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ withColumn - Add new column:\n",
      "+--------+----------+\n",
      "|order_id|order_year|\n",
      "+--------+----------+\n",
      "|  ORD001|      2024|\n",
      "|  ORD002|      2024|\n",
      "|  ORD003|      2024|\n",
      "|  ORD004|      2024|\n",
      "|  ORD005|      2024|\n",
      "+--------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "\n",
      "üîπ select - Select columns:\n",
      "+--------+-------------+-------+\n",
      "|order_id|customer_name|country|\n",
      "+--------+-------------+-------+\n",
      "|  ORD001|     John Doe|    USA|\n",
      "|  ORD002|   Jane Smith|     UK|\n",
      "|  ORD003|  Bob Johnson| Canada|\n",
      "|  ORD004|     John Doe|    USA|\n",
      "|  ORD005|  Alice Brown|    USA|\n",
      "+--------+-------------+-------+\n",
      "only showing top 5 rows\n",
      "\n",
      "\n",
      "üîπ selectExpr - SQL expressions:\n",
      "+--------+-------------+-------------+\n",
      "|order_id|customer_name|country_upper|\n",
      "+--------+-------------+-------------+\n",
      "|  ORD001|     John Doe|          USA|\n",
      "|  ORD002|   Jane Smith|           UK|\n",
      "|  ORD003|  Bob Johnson|       CANADA|\n",
      "|  ORD004|     John Doe|          USA|\n",
      "|  ORD005|  Alice Brown|          USA|\n",
      "+--------+-------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "\n",
      "üîπ drop - Remove columns:\n",
      "Columns before: ['order_id', 'customer_id', 'customer_name', 'email', 'products', 'prices', 'order_timestamp', 'country', 'status']\n",
      "Columns after: ['order_id', 'customer_id', 'customer_name', 'products', 'prices', 'order_timestamp', 'country', 'status']\n",
      "\n",
      "üîπ withColumnRenamed - Rename column:\n",
      "+--------+-----------+\n",
      "|order_id|  full_name|\n",
      "+--------+-----------+\n",
      "|  ORD001|   John Doe|\n",
      "|  ORD002| Jane Smith|\n",
      "|  ORD003|Bob Johnson|\n",
      "|  ORD004|   John Doe|\n",
      "|  ORD005|Alice Brown|\n",
      "+--------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2.1 withColumn - Add/modify columns\n",
    "print(\"üîπ withColumn - Add new column:\")\n",
    "df_with_col = df.withColumn(\"order_year\", lit(2024))\n",
    "df_with_col.select(\"order_id\", \"order_year\").show(5)\n",
    "\n",
    "# 2.2 select - Select specific columns\n",
    "print(\"\\nüîπ select - Select columns:\")\n",
    "df.select(\"order_id\", \"customer_name\", \"country\").show(5)\n",
    "\n",
    "# 2.3 selectExpr - Select with SQL expressions\n",
    "print(\"\\nüîπ selectExpr - SQL expressions:\")\n",
    "df.selectExpr(\n",
    "    \"order_id\",\n",
    "    \"customer_name\",\n",
    "    \"upper(country) as country_upper\"\n",
    ").show(5)\n",
    "\n",
    "# 2.4 drop - Remove columns\n",
    "print(\"\\nüîπ drop - Remove columns:\")\n",
    "df_dropped = df.drop(\"email\")\n",
    "print(f\"Columns before: {df.columns}\")\n",
    "print(f\"Columns after: {df_dropped.columns}\")\n",
    "\n",
    "# 2.5 withColumnRenamed - Rename columns\n",
    "print(\"\\nüîπ withColumnRenamed - Rename column:\")\n",
    "df_renamed = df.withColumnRenamed(\"customer_name\", \"full_name\")\n",
    "df_renamed.select(\"order_id\", \"full_name\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéØ **3. CONDITIONAL LOGIC - WHEN/OTHERWISE**\n",
    "\n",
    "X·ª≠ l√Ω logic ƒëi·ªÅu ki·ªán ph·ª©c t·∫°p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ Simple when/otherwise:\n",
      "+--------+---------+------------+\n",
      "|order_id|   status|status_label|\n",
      "+--------+---------+------------+\n",
      "|  ORD001|completed| ‚úÖ Completed|\n",
      "|  ORD002|  pending|   ‚è≥ Pending|\n",
      "|  ORD003|completed| ‚úÖ Completed|\n",
      "|  ORD004|cancelled| ‚ùå Cancelled|\n",
      "|  ORD005|completed| ‚úÖ Completed|\n",
      "|  ORD006|completed| ‚úÖ Completed|\n",
      "|  ORD007|  pending|   ‚è≥ Pending|\n",
      "|  ORD008|completed| ‚úÖ Completed|\n",
      "+--------+---------+------------+\n",
      "\n",
      "\n",
      "üîπ Multiple conditions:\n",
      "+--------+---------+-------+--------+\n",
      "|order_id|   status|country|priority|\n",
      "+--------+---------+-------+--------+\n",
      "|  ORD001|completed|    USA|    High|\n",
      "|  ORD002|  pending|     UK|  Medium|\n",
      "|  ORD003|completed| Canada|     Low|\n",
      "|  ORD004|cancelled|    USA|  Medium|\n",
      "|  ORD005|completed|    USA|    High|\n",
      "|  ORD006|completed|     UK|     Low|\n",
      "|  ORD007|  pending|     UK|  Medium|\n",
      "|  ORD008|completed| Canada|     Low|\n",
      "+--------+---------+-------+--------+\n",
      "\n",
      "\n",
      "üîπ Nested conditions:\n",
      "+--------+-------+---------+-----------------+\n",
      "|order_id|country|   status|customer_category|\n",
      "+--------+-------+---------+-----------------+\n",
      "|  ORD001|    USA|completed|       US-Premium|\n",
      "|  ORD002|     UK|  pending|      UK-Standard|\n",
      "|  ORD003| Canada|completed|    International|\n",
      "|  ORD004|    USA|cancelled|      US-Standard|\n",
      "|  ORD005|    USA|completed|       US-Premium|\n",
      "|  ORD006|     UK|completed|       UK-Premium|\n",
      "|  ORD007|     UK|  pending|      UK-Standard|\n",
      "|  ORD008| Canada|completed|    International|\n",
      "+--------+-------+---------+-----------------+\n",
      "\n",
      "\n",
      "üîπ Using expr:\n",
      "+--------+---------+-------+--------+\n",
      "|order_id|   status|country|discount|\n",
      "+--------+---------+-------+--------+\n",
      "|  ORD001|completed|    USA|    0.15|\n",
      "|  ORD002|  pending|     UK|    0.05|\n",
      "|  ORD003|completed| Canada|    0.10|\n",
      "|  ORD004|cancelled|    USA|    0.00|\n",
      "|  ORD005|completed|    USA|    0.15|\n",
      "|  ORD006|completed|     UK|    0.10|\n",
      "|  ORD007|  pending|     UK|    0.05|\n",
      "|  ORD008|completed| Canada|    0.10|\n",
      "+--------+---------+-------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3.1 Simple when/otherwise\n",
    "print(\"üîπ Simple when/otherwise:\")\n",
    "df_status = df.withColumn(\n",
    "    \"status_label\",\n",
    "    when(col(\"status\") == \"completed\", \"‚úÖ Completed\")\n",
    "    .when(col(\"status\") == \"pending\", \"‚è≥ Pending\")\n",
    "    .when(col(\"status\") == \"cancelled\", \"‚ùå Cancelled\")\n",
    "    .otherwise(\"‚ùì Unknown\")\n",
    ")\n",
    "\n",
    "df_status.select(\"order_id\", \"status\", \"status_label\").show()\n",
    "\n",
    "# 3.2 Multiple conditions with AND/OR\n",
    "print(\"\\nüîπ Multiple conditions:\")\n",
    "df_priority = df.withColumn(\n",
    "    \"priority\",\n",
    "    when(\n",
    "        (col(\"status\") == \"completed\") & (col(\"country\") == \"USA\"),\n",
    "        \"High\"\n",
    "    ).when(\n",
    "        (col(\"status\") == \"pending\") | (col(\"status\") == \"cancelled\"),\n",
    "        \"Medium\"\n",
    "    ).otherwise(\"Low\")\n",
    ")\n",
    "\n",
    "df_priority.select(\"order_id\", \"status\", \"country\", \"priority\").show()\n",
    "\n",
    "# 3.3 Nested when/otherwise\n",
    "print(\"\\nüîπ Nested conditions:\")\n",
    "df_category = df.withColumn(\n",
    "    \"customer_category\",\n",
    "    when(col(\"country\") == \"USA\",\n",
    "        when(col(\"status\") == \"completed\", \"US-Premium\")\n",
    "        .otherwise(\"US-Standard\")\n",
    "    ).when(col(\"country\") == \"UK\",\n",
    "        when(col(\"status\") == \"completed\", \"UK-Premium\")\n",
    "        .otherwise(\"UK-Standard\")\n",
    "    ).otherwise(\"International\")\n",
    ")\n",
    "\n",
    "df_category.select(\"order_id\", \"country\", \"status\", \"customer_category\").show()\n",
    "\n",
    "# 3.4 Using expr for complex logic\n",
    "print(\"\\nüîπ Using expr:\")\n",
    "df_expr = df.withColumn(\n",
    "    \"discount\",\n",
    "    expr(\"\"\"\n",
    "        CASE \n",
    "            WHEN status = 'completed' AND country = 'USA' THEN 0.15\n",
    "            WHEN status = 'completed' THEN 0.10\n",
    "            WHEN status = 'pending' THEN 0.05\n",
    "            ELSE 0.0\n",
    "        END\n",
    "    \"\"\")\n",
    ")\n",
    "\n",
    "df_expr.select(\"order_id\", \"status\", \"country\", \"discount\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìù **4. STRING OPERATIONS**\n",
    "\n",
    "X·ª≠ l√Ω chu·ªói k√Ω t·ª± n√¢ng cao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ Basic string functions:\n",
      "+--------+--------------+--------------+--------------+--------------+-----------+\n",
      "|order_id|customer_name |name_upper    |name_lower    |name_initcap  |name_length|\n",
      "+--------+--------------+--------------+--------------+--------------+-----------+\n",
      "|ORD001  |John Doe      |JOHN DOE      |john doe      |John Doe      |8          |\n",
      "|ORD002  |Jane Smith    |JANE SMITH    |jane smith    |Jane Smith    |10         |\n",
      "|ORD003  |Bob Johnson   |BOB JOHNSON   |bob johnson   |Bob Johnson   |11         |\n",
      "|ORD004  |John Doe      |JOHN DOE      |john doe      |John Doe      |8          |\n",
      "|ORD005  |Alice Brown   |ALICE BROWN   |alice brown   |Alice Brown   |11         |\n",
      "|ORD006  |Charlie Wilson|CHARLIE WILSON|charlie wilson|Charlie Wilson|14         |\n",
      "|ORD007  |Jane Smith    |JANE SMITH    |jane smith    |Jane Smith    |10         |\n",
      "|ORD008  |David Lee     |DAVID LEE     |david lee     |David Lee     |9          |\n",
      "+--------+--------------+--------------+--------------+--------------+-----------+\n",
      "\n",
      "\n",
      "üîπ String concatenation:\n",
      "+--------+--------------+-------+--------------------+--------------------+-----------------------+\n",
      "|order_id|customer_name |country|name_country_1      |name_country_2      |name_country_3         |\n",
      "+--------+--------------+-------+--------------------+--------------------+-----------------------+\n",
      "|ORD001  |John Doe      |USA    |John Doe - USA      |John Doe | USA      |John Doe from USA      |\n",
      "|ORD002  |Jane Smith    |UK     |Jane Smith - UK     |Jane Smith | UK     |Jane Smith from UK     |\n",
      "|ORD003  |Bob Johnson   |Canada |Bob Johnson - Canada|Bob Johnson | Canada|Bob Johnson from Canada|\n",
      "|ORD004  |John Doe      |USA    |John Doe - USA      |John Doe | USA      |John Doe from USA      |\n",
      "|ORD005  |Alice Brown   |USA    |Alice Brown - USA   |Alice Brown | USA   |Alice Brown from USA   |\n",
      "|ORD006  |Charlie Wilson|UK     |Charlie Wilson - UK |Charlie Wilson | UK |Charlie Wilson from UK |\n",
      "|ORD007  |Jane Smith    |UK     |Jane Smith - UK     |Jane Smith | UK     |Jane Smith from UK     |\n",
      "|ORD008  |David Lee     |Canada |David Lee - Canada  |David Lee | Canada  |David Lee from Canada  |\n",
      "+--------+--------------+-------+--------------------+--------------------+-----------------------+\n",
      "\n",
      "\n",
      "üîπ Substring and split:\n",
      "+--------+--------------+-------------+-----------------+----------+---------+\n",
      "|order_id|customer_name |first_4_chars|name_parts       |first_name|last_name|\n",
      "+--------+--------------+-------------+-----------------+----------+---------+\n",
      "|ORD001  |John Doe      |John         |[John, Doe]      |John      |Doe      |\n",
      "|ORD002  |Jane Smith    |Jane         |[Jane, Smith]    |Jane      |Smith    |\n",
      "|ORD003  |Bob Johnson   |Bob          |[Bob, Johnson]   |Bob       |Johnson  |\n",
      "|ORD004  |John Doe      |John         |[John, Doe]      |John      |Doe      |\n",
      "|ORD005  |Alice Brown   |Alic         |[Alice, Brown]   |Alice     |Brown    |\n",
      "|ORD006  |Charlie Wilson|Char         |[Charlie, Wilson]|Charlie   |Wilson   |\n",
      "|ORD007  |Jane Smith    |Jane         |[Jane, Smith]    |Jane      |Smith    |\n",
      "|ORD008  |David Lee     |Davi         |[David, Lee]     |David     |Lee      |\n",
      "+--------+--------------+-------------+-----------------+----------+---------+\n",
      "\n",
      "\n",
      "üîπ Regex operations:\n",
      "+--------+------------------------+------------+--------------------------+--------------+\n",
      "|order_id|email                   |email_domain|email_masked              |is_valid_email|\n",
      "+--------+------------------------+------------+--------------------------+--------------+\n",
      "|ORD001  |john.doe@email.com      |email.com   |john.doe@company.com      |true          |\n",
      "|ORD002  |jane.smith@email.com    |email.com   |jane.smith@company.com    |true          |\n",
      "|ORD003  |bob.johnson@email.com   |email.com   |bob.johnson@company.com   |true          |\n",
      "|ORD004  |john.doe@email.com      |email.com   |john.doe@company.com      |true          |\n",
      "|ORD005  |alice.brown@email.com   |email.com   |alice.brown@company.com   |true          |\n",
      "|ORD006  |charlie.wilson@email.com|email.com   |charlie.wilson@company.com|true          |\n",
      "|ORD007  |jane.smith@email.com    |email.com   |jane.smith@company.com    |true          |\n",
      "|ORD008  |david.lee@email.com     |email.com   |david.lee@company.com     |true          |\n",
      "+--------+------------------------+------------+--------------------------+--------------+\n",
      "\n",
      "\n",
      "üîπ Trim and pad:\n",
      "+--------+---------------+--------------------+--------------+--------------+--------------+\n",
      "|order_id|order_id_padded|name_padded         |name_trimmed  |name_ltrimmed |name_rtrimmed |\n",
      "+--------+---------------+--------------------+--------------+--------------+--------------+\n",
      "|ORD001  |0000ORD001     |John Doe            |John Doe      |John Doe      |John Doe      |\n",
      "|ORD002  |0000ORD002     |Jane Smith          |Jane Smith    |Jane Smith    |Jane Smith    |\n",
      "|ORD003  |0000ORD003     |Bob Johnson         |Bob Johnson   |Bob Johnson   |Bob Johnson   |\n",
      "|ORD004  |0000ORD004     |John Doe            |John Doe      |John Doe      |John Doe      |\n",
      "|ORD005  |0000ORD005     |Alice Brown         |Alice Brown   |Alice Brown   |Alice Brown   |\n",
      "|ORD006  |0000ORD006     |Charlie Wilson      |Charlie Wilson|Charlie Wilson|Charlie Wilson|\n",
      "|ORD007  |0000ORD007     |Jane Smith          |Jane Smith    |Jane Smith    |Jane Smith    |\n",
      "|ORD008  |0000ORD008     |David Lee           |David Lee     |David Lee     |David Lee     |\n",
      "+--------+---------------+--------------------+--------------+--------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4.1 Basic string functions\n",
    "print(\"üîπ Basic string functions:\")\n",
    "df_string = df.select(\n",
    "    \"order_id\",\n",
    "    \"customer_name\",\n",
    "    upper(col(\"customer_name\")).alias(\"name_upper\"),\n",
    "    lower(col(\"customer_name\")).alias(\"name_lower\"),\n",
    "    initcap(col(\"customer_name\")).alias(\"name_initcap\"),\n",
    "    length(col(\"customer_name\")).alias(\"name_length\")\n",
    ")\n",
    "\n",
    "df_string.show(truncate=False)\n",
    "\n",
    "# 4.2 Concatenation\n",
    "print(\"\\nüîπ String concatenation:\")\n",
    "df_concat = df.select(\n",
    "    \"order_id\",\n",
    "    \"customer_name\",\n",
    "    \"country\",\n",
    "    # Method 1: concat\n",
    "    concat(col(\"customer_name\"), lit(\" - \"), col(\"country\")).alias(\"name_country_1\"),\n",
    "    # Method 2: concat_ws (with separator)\n",
    "    concat_ws(\" | \", col(\"customer_name\"), col(\"country\")).alias(\"name_country_2\"),\n",
    "    # Method 3: format_string\n",
    "    format_string(\"%s from %s\", col(\"customer_name\"), col(\"country\")).alias(\"name_country_3\")\n",
    ")\n",
    "\n",
    "df_concat.show(truncate=False)\n",
    "\n",
    "# 4.3 Substring and split\n",
    "print(\"\\nüîπ Substring and split:\")\n",
    "df_substr = df.select(\n",
    "    \"order_id\",\n",
    "    \"customer_name\",\n",
    "    # Substring (start from position 1, length 4)\n",
    "    substring(col(\"customer_name\"), 1, 4).alias(\"first_4_chars\"),\n",
    "    # Split by space\n",
    "    split(col(\"customer_name\"), \" \").alias(\"name_parts\"),\n",
    "    # Get first name (first element of split)\n",
    "    split(col(\"customer_name\"), \" \").getItem(0).alias(\"first_name\"),\n",
    "    # Get last name (last element of split)\n",
    "    split(col(\"customer_name\"), \" \").getItem(1).alias(\"last_name\")\n",
    ")\n",
    "\n",
    "df_substr.show(truncate=False)\n",
    "\n",
    "# 4.4 Regex operations\n",
    "print(\"\\nüîπ Regex operations:\")\n",
    "df_regex = df.select(\n",
    "    \"order_id\",\n",
    "    \"email\",\n",
    "    # Extract domain from email\n",
    "    regexp_extract(col(\"email\"), r\"@(.+)\", 1).alias(\"email_domain\"),\n",
    "    # Replace\n",
    "    regexp_replace(col(\"email\"), r\"@.+\", \"@company.com\").alias(\"email_masked\"),\n",
    "    # Check if matches pattern\n",
    "    col(\"email\").rlike(r\"^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$\").alias(\"is_valid_email\")\n",
    ")\n",
    "\n",
    "df_regex.show(truncate=False)\n",
    "\n",
    "# 4.5 Trim and pad\n",
    "print(\"\\nüîπ Trim and pad:\")\n",
    "df_trim = df.select(\n",
    "    \"order_id\",\n",
    "    # Left pad with zeros (total length 10)\n",
    "    lpad(col(\"order_id\"), 10, \"0\").alias(\"order_id_padded\"),\n",
    "    # Right pad with spaces\n",
    "    rpad(col(\"customer_name\"), 20, \" \").alias(\"name_padded\"),\n",
    "    # Trim\n",
    "    trim(col(\"customer_name\")).alias(\"name_trimmed\"),\n",
    "    ltrim(col(\"customer_name\")).alias(\"name_ltrimmed\"),\n",
    "    rtrim(col(\"customer_name\")).alias(\"name_rtrimmed\")\n",
    ")\n",
    "\n",
    "df_trim.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìÖ **5. DATE/TIME OPERATIONS**\n",
    "\n",
    "X·ª≠ l√Ω ng√†y th√°ng v√† th·ªùi gian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ Parse timestamp:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-------------------+----------+\n",
      "|order_id|    order_timestamp|     order_datetime|order_date|\n",
      "+--------+-------------------+-------------------+----------+\n",
      "|  ORD001|2024-01-15 10:30:00|2024-01-15 10:30:00|2024-01-15|\n",
      "|  ORD002|2024-01-16 14:20:00|2024-01-16 14:20:00|2024-01-16|\n",
      "|  ORD003|2024-01-17 09:15:00|2024-01-17 09:15:00|2024-01-17|\n",
      "|  ORD004|2024-01-18 16:45:00|2024-01-18 16:45:00|2024-01-18|\n",
      "|  ORD005|2024-01-19 11:00:00|2024-01-19 11:00:00|2024-01-19|\n",
      "|  ORD006|2024-01-20 13:30:00|2024-01-20 13:30:00|2024-01-20|\n",
      "|  ORD007|2024-01-21 15:20:00|2024-01-21 15:20:00|2024-01-21|\n",
      "|  ORD008|2024-01-22 10:10:00|2024-01-22 10:10:00|2024-01-22|\n",
      "+--------+-------------------+-------------------+----------+\n",
      "\n",
      "\n",
      "üîπ Extract date parts:\n",
      "+--------+-------------------+----+-----+---+-----------+-----------+------------+-------+----+------+------+\n",
      "|order_id|     order_datetime|year|month|day|day_of_week|day_of_year|week_of_year|quarter|hour|minute|second|\n",
      "+--------+-------------------+----+-----+---+-----------+-----------+------------+-------+----+------+------+\n",
      "|  ORD001|2024-01-15 10:30:00|2024|    1| 15|          2|         15|           3|      1|  10|    30|     0|\n",
      "|  ORD002|2024-01-16 14:20:00|2024|    1| 16|          3|         16|           3|      1|  14|    20|     0|\n",
      "|  ORD003|2024-01-17 09:15:00|2024|    1| 17|          4|         17|           3|      1|   9|    15|     0|\n",
      "|  ORD004|2024-01-18 16:45:00|2024|    1| 18|          5|         18|           3|      1|  16|    45|     0|\n",
      "|  ORD005|2024-01-19 11:00:00|2024|    1| 19|          6|         19|           3|      1|  11|     0|     0|\n",
      "|  ORD006|2024-01-20 13:30:00|2024|    1| 20|          7|         20|           3|      1|  13|    30|     0|\n",
      "|  ORD007|2024-01-21 15:20:00|2024|    1| 21|          1|         21|           3|      1|  15|    20|     0|\n",
      "|  ORD008|2024-01-22 10:10:00|2024|    1| 22|          2|         22|           4|      1|  10|    10|     0|\n",
      "+--------+-------------------+----+-----+---+-----------+-----------+------------+-------+----+------+------+\n",
      "\n",
      "\n",
      "üîπ Date arithmetic:\n",
      "+--------+----------+-------------+----------------+----------+----------------+------------------+\n",
      "|order_id|order_date|delivery_date|preparation_date|next_month|days_since_order|months_since_order|\n",
      "+--------+----------+-------------+----------------+----------+----------------+------------------+\n",
      "|  ORD001|2024-01-15|   2024-01-22|      2024-01-12|2024-02-15|             724|       23.77419355|\n",
      "|  ORD002|2024-01-16|   2024-01-23|      2024-01-13|2024-02-16|             723|       23.74193548|\n",
      "|  ORD003|2024-01-17|   2024-01-24|      2024-01-14|2024-02-17|             722|       23.70967742|\n",
      "|  ORD004|2024-01-18|   2024-01-25|      2024-01-15|2024-02-18|             721|       23.67741935|\n",
      "|  ORD005|2024-01-19|   2024-01-26|      2024-01-16|2024-02-19|             720|       23.64516129|\n",
      "|  ORD006|2024-01-20|   2024-01-27|      2024-01-17|2024-02-20|             719|       23.61290323|\n",
      "|  ORD007|2024-01-21|   2024-01-28|      2024-01-18|2024-02-21|             718|       23.58064516|\n",
      "|  ORD008|2024-01-22|   2024-01-29|      2024-01-19|2024-02-22|             717|        23.5483871|\n",
      "+--------+----------+-------------+----------------+----------+----------------+------------------+\n",
      "\n",
      "\n",
      "üîπ Date formatting:\n",
      "+--------+-------------------+----------+----------+----------+---------------------------+---------+-------------------+\n",
      "|order_id|order_datetime     |date_iso  |date_eu   |date_us   |date_full                  |time_only|datetime_full      |\n",
      "+--------+-------------------+----------+----------+----------+---------------------------+---------+-------------------+\n",
      "|ORD001  |2024-01-15 10:30:00|2024-01-15|15/01/2024|01/15/2024|Monday, January 15, 2024   |10:30:00 |2024-01-15 10:30:00|\n",
      "|ORD002  |2024-01-16 14:20:00|2024-01-16|16/01/2024|01/16/2024|Tuesday, January 16, 2024  |14:20:00 |2024-01-16 14:20:00|\n",
      "|ORD003  |2024-01-17 09:15:00|2024-01-17|17/01/2024|01/17/2024|Wednesday, January 17, 2024|09:15:00 |2024-01-17 09:15:00|\n",
      "|ORD004  |2024-01-18 16:45:00|2024-01-18|18/01/2024|01/18/2024|Thursday, January 18, 2024 |16:45:00 |2024-01-18 16:45:00|\n",
      "|ORD005  |2024-01-19 11:00:00|2024-01-19|19/01/2024|01/19/2024|Friday, January 19, 2024   |11:00:00 |2024-01-19 11:00:00|\n",
      "|ORD006  |2024-01-20 13:30:00|2024-01-20|20/01/2024|01/20/2024|Saturday, January 20, 2024 |13:30:00 |2024-01-20 13:30:00|\n",
      "|ORD007  |2024-01-21 15:20:00|2024-01-21|21/01/2024|01/21/2024|Sunday, January 21, 2024   |15:20:00 |2024-01-21 15:20:00|\n",
      "|ORD008  |2024-01-22 10:10:00|2024-01-22|22/01/2024|01/22/2024|Monday, January 22, 2024   |10:10:00 |2024-01-22 10:10:00|\n",
      "+--------+-------------------+----------+----------+----------+---------------------------+---------+-------------------+\n",
      "\n",
      "\n",
      "üîπ Current date/time:\n",
      "+--------+----------+--------------------------+--------------+-------------------+\n",
      "|order_id|today     |now                       |unix_timestamp|from_unix          |\n",
      "+--------+----------+--------------------------+--------------+-------------------+\n",
      "|ORD001  |2026-01-08|2026-01-08 16:00:36.637792|1767888036    |2026-01-08 16:00:36|\n",
      "|ORD002  |2026-01-08|2026-01-08 16:00:36.637792|1767888036    |2026-01-08 16:00:36|\n",
      "|ORD003  |2026-01-08|2026-01-08 16:00:36.637792|1767888036    |2026-01-08 16:00:36|\n",
      "|ORD004  |2026-01-08|2026-01-08 16:00:36.637792|1767888036    |2026-01-08 16:00:36|\n",
      "|ORD005  |2026-01-08|2026-01-08 16:00:36.637792|1767888036    |2026-01-08 16:00:36|\n",
      "|ORD006  |2026-01-08|2026-01-08 16:00:36.637792|1767888036    |2026-01-08 16:00:36|\n",
      "|ORD007  |2026-01-08|2026-01-08 16:00:36.637792|1767888036    |2026-01-08 16:00:36|\n",
      "|ORD008  |2026-01-08|2026-01-08 16:00:36.637792|1767888036    |2026-01-08 16:00:36|\n",
      "+--------+----------+--------------------------+--------------+-------------------+\n",
      "\n",
      "\n",
      "üîπ Truncate date:\n",
      "+--------+-------------------+-------------------+-------------------+-------------------+-------------------+-------------------+\n",
      "|order_id|order_datetime     |year_start         |month_start        |week_start         |day_start          |hour_start         |\n",
      "+--------+-------------------+-------------------+-------------------+-------------------+-------------------+-------------------+\n",
      "|ORD001  |2024-01-15 10:30:00|2024-01-01 00:00:00|2024-01-01 00:00:00|2024-01-15 00:00:00|2024-01-15 00:00:00|2024-01-15 10:00:00|\n",
      "|ORD002  |2024-01-16 14:20:00|2024-01-01 00:00:00|2024-01-01 00:00:00|2024-01-15 00:00:00|2024-01-16 00:00:00|2024-01-16 14:00:00|\n",
      "|ORD003  |2024-01-17 09:15:00|2024-01-01 00:00:00|2024-01-01 00:00:00|2024-01-15 00:00:00|2024-01-17 00:00:00|2024-01-17 09:00:00|\n",
      "|ORD004  |2024-01-18 16:45:00|2024-01-01 00:00:00|2024-01-01 00:00:00|2024-01-15 00:00:00|2024-01-18 00:00:00|2024-01-18 16:00:00|\n",
      "|ORD005  |2024-01-19 11:00:00|2024-01-01 00:00:00|2024-01-01 00:00:00|2024-01-15 00:00:00|2024-01-19 00:00:00|2024-01-19 11:00:00|\n",
      "|ORD006  |2024-01-20 13:30:00|2024-01-01 00:00:00|2024-01-01 00:00:00|2024-01-15 00:00:00|2024-01-20 00:00:00|2024-01-20 13:00:00|\n",
      "|ORD007  |2024-01-21 15:20:00|2024-01-01 00:00:00|2024-01-01 00:00:00|2024-01-15 00:00:00|2024-01-21 00:00:00|2024-01-21 15:00:00|\n",
      "|ORD008  |2024-01-22 10:10:00|2024-01-01 00:00:00|2024-01-01 00:00:00|2024-01-22 00:00:00|2024-01-22 00:00:00|2024-01-22 10:00:00|\n",
      "+--------+-------------------+-------------------+-------------------+-------------------+-------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.conf.set(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\")\n",
    "\n",
    "# 5.1 Parse timestamp\n",
    "print(\"üîπ Parse timestamp:\")\n",
    "df_date = df.withColumn(\n",
    "    \"order_datetime\",\n",
    "    to_timestamp(col(\"order_timestamp\"), \"yyyy-MM-dd HH:mm:ss\")\n",
    ").withColumn(\n",
    "    \"order_date\",\n",
    "    to_date(col(\"order_timestamp\"), \"yyyy-MM-dd\")\n",
    ")\n",
    "\n",
    "df_date.select(\"order_id\", \"order_timestamp\", \"order_datetime\", \"order_date\").show()\n",
    "\n",
    "# 5.2 Extract date parts\n",
    "print(\"\\nüîπ Extract date parts:\")\n",
    "df_parts = df_date.select(\n",
    "    \"order_id\",\n",
    "    \"order_datetime\",\n",
    "    year(col(\"order_datetime\")).alias(\"year\"),\n",
    "    month(col(\"order_datetime\")).alias(\"month\"),\n",
    "    dayofmonth(col(\"order_datetime\")).alias(\"day\"),\n",
    "    dayofweek(col(\"order_datetime\")).alias(\"day_of_week\"),  # 1=Sunday, 7=Saturday\n",
    "    dayofyear(col(\"order_datetime\")).alias(\"day_of_year\"),\n",
    "    weekofyear(col(\"order_datetime\")).alias(\"week_of_year\"),\n",
    "    quarter(col(\"order_datetime\")).alias(\"quarter\"),\n",
    "    hour(col(\"order_datetime\")).alias(\"hour\"),\n",
    "    minute(col(\"order_datetime\")).alias(\"minute\"),\n",
    "    second(col(\"order_datetime\")).alias(\"second\")\n",
    ")\n",
    "\n",
    "df_parts.show()\n",
    "\n",
    "# 5.3 Date arithmetic\n",
    "print(\"\\nüîπ Date arithmetic:\")\n",
    "df_calc = df_date.select(\n",
    "    \"order_id\",\n",
    "    \"order_date\",\n",
    "    # Add days\n",
    "    date_add(col(\"order_date\"), 7).alias(\"delivery_date\"),\n",
    "    # Subtract days\n",
    "    date_sub(col(\"order_date\"), 3).alias(\"preparation_date\"),\n",
    "    # Add months\n",
    "    add_months(col(\"order_date\"), 1).alias(\"next_month\"),\n",
    "    # Days between dates\n",
    "    datediff(current_date(), col(\"order_date\")).alias(\"days_since_order\"),\n",
    "    # Months between dates\n",
    "    months_between(current_date(), col(\"order_date\")).alias(\"months_since_order\")\n",
    ")\n",
    "\n",
    "df_calc.show()\n",
    "\n",
    "# 5.4 Date formatting\n",
    "print(\"\\nüîπ Date formatting:\")\n",
    "df_format = df_date.select(\n",
    "    \"order_id\",\n",
    "    \"order_datetime\",\n",
    "    # Format date\n",
    "    date_format(col(\"order_datetime\"), \"yyyy-MM-dd\").alias(\"date_iso\"),\n",
    "    date_format(col(\"order_datetime\"), \"dd/MM/yyyy\").alias(\"date_eu\"),\n",
    "    date_format(col(\"order_datetime\"), \"MM/dd/yyyy\").alias(\"date_us\"),\n",
    "    date_format(col(\"order_datetime\"), \"EEEE, MMMM dd, yyyy\").alias(\"date_full\"),\n",
    "    date_format(col(\"order_datetime\"), \"HH:mm:ss\").alias(\"time_only\"),\n",
    "    date_format(col(\"order_datetime\"), \"yyyy-MM-dd HH:mm:ss\").alias(\"datetime_full\")\n",
    ")\n",
    "\n",
    "df_format.show(truncate=False)\n",
    "\n",
    "# 5.5 Current date/time functions\n",
    "print(\"\\nüîπ Current date/time:\")\n",
    "df_current = df.select(\n",
    "    \"order_id\",\n",
    "    current_date().alias(\"today\"),\n",
    "    current_timestamp().alias(\"now\"),\n",
    "    unix_timestamp().alias(\"unix_timestamp\"),\n",
    "    from_unixtime(unix_timestamp()).alias(\"from_unix\")\n",
    ")\n",
    "\n",
    "df_current.show(truncate=False)\n",
    "\n",
    "# 5.6 Truncate date\n",
    "print(\"\\nüîπ Truncate date:\")\n",
    "df_trunc = df_date.select(\n",
    "    \"order_id\",\n",
    "    \"order_datetime\",\n",
    "    date_trunc(\"year\", col(\"order_datetime\")).alias(\"year_start\"),\n",
    "    date_trunc(\"month\", col(\"order_datetime\")).alias(\"month_start\"),\n",
    "    date_trunc(\"week\", col(\"order_datetime\")).alias(\"week_start\"),\n",
    "    date_trunc(\"day\", col(\"order_datetime\")).alias(\"day_start\"),\n",
    "    date_trunc(\"hour\", col(\"order_datetime\")).alias(\"hour_start\")\n",
    ")\n",
    "\n",
    "df_trunc.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üî¢ **6. NUMERIC OPERATIONS**\n",
    "\n",
    "X·ª≠ l√Ω s·ªë h·ªçc v√† to√°n h·ªçc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ Calculating total amount from prices array:\n",
      "üîπ Basic math operations:\n",
      "+--------+------------+--------------+---------------+------------------+-----------+--------------+\n",
      "|order_id|total_amount|amount_plus_10|amount_minus_10|   amount_with_tax|amount_half|amount_mod_100|\n",
      "+--------+------------+--------------+---------------+------------------+-----------+--------------+\n",
      "|  ORD001|       300.0|         310.0|          290.0|             330.0|      150.0|           0.0|\n",
      "|  ORD003|       500.0|         510.0|          490.0|             550.0|      250.0|           0.0|\n",
      "|  ORD002|       150.0|         160.0|          140.0|             165.0|       75.0|          50.0|\n",
      "|  ORD004|       450.0|         460.0|          440.0|495.00000000000006|      225.0|          50.0|\n",
      "|  ORD008|       700.0|         710.0|          690.0| 770.0000000000001|      350.0|           0.0|\n",
      "|  ORD005|       100.0|         110.0|           90.0|110.00000000000001|       50.0|           0.0|\n",
      "|  ORD006|       350.0|         360.0|          340.0|385.00000000000006|      175.0|          50.0|\n",
      "|  ORD007|       250.0|         260.0|          240.0|             275.0|      125.0|          50.0|\n",
      "+--------+------------+--------------+---------------+------------------+-----------+--------------+\n",
      "\n",
      "\n",
      "üîπ Rounding functions:\n",
      "+--------+------------+-------+-----------+-------+-----+--------------+\n",
      "|order_id|total_amount|rounded|rounded_2dp|ceiling|floor|banker_rounded|\n",
      "+--------+------------+-------+-----------+-------+-----+--------------+\n",
      "|  ORD001|       300.0|  300.0|      300.0|    300|  300|         300.0|\n",
      "|  ORD003|       500.0|  500.0|      500.0|    500|  500|         500.0|\n",
      "|  ORD002|       150.0|  150.0|      150.0|    150|  150|         150.0|\n",
      "|  ORD004|       450.0|  450.0|      450.0|    450|  450|         450.0|\n",
      "|  ORD008|       700.0|  700.0|      700.0|    700|  700|         700.0|\n",
      "|  ORD005|       100.0|  100.0|      100.0|    100|  100|         100.0|\n",
      "|  ORD006|       350.0|  350.0|      350.0|    350|  350|         350.0|\n",
      "|  ORD007|       250.0|  250.0|      250.0|    250|  250|         250.0|\n",
      "+--------+------------+-------+-----------+-------+-----+--------------+\n",
      "\n",
      "\n",
      "üîπ Mathematical functions:\n",
      "+--------+------------+--------+------------------+--------+------------------+------------------+------------------+\n",
      "|order_id|total_amount|absolute|       square_root| squared|       natural_log|       log_base_10|       exponential|\n",
      "+--------+------------+--------+------------------+--------+------------------+------------------+------------------+\n",
      "|  ORD008|       700.0|   700.0|26.457513110645905|490000.0| 6.551080335043404| 2.845098040014257|2.7182818284590455|\n",
      "|  ORD005|       100.0|   100.0|              10.0| 10000.0| 4.605170185988092|               2.0|2.7182818284590455|\n",
      "|  ORD006|       350.0|   350.0|18.708286933869708|122500.0| 5.857933154483459|2.5440680443502757|2.7182818284590455|\n",
      "|  ORD007|       250.0|   250.0|15.811388300841896| 62500.0| 5.521460917862246|2.3979400086720375|2.7182818284590455|\n",
      "|  ORD001|       300.0|   300.0|17.320508075688775| 90000.0| 5.703782474656201|2.4771212547196626|2.7182818284590455|\n",
      "|  ORD003|       500.0|   500.0|22.360679774997898|250000.0| 6.214608098422191|2.6989700043360187|2.7182818284590455|\n",
      "|  ORD002|       150.0|   150.0| 12.24744871391589| 22500.0|5.0106352940962555|2.1760912590556813|2.7182818284590455|\n",
      "|  ORD004|       450.0|   450.0|21.213203435596427|202500.0|6.1092475827643655|2.6532125137753435|2.7182818284590455|\n",
      "+--------+------------+--------+------------------+--------+------------------+------------------+------------------+\n",
      "\n",
      "\n",
      "üîπ Statistical functions:\n",
      "+--------+------------+------------+------------+\n",
      "|order_id|total_amount|max_with_200|min_with_400|\n",
      "+--------+------------+------------+------------+\n",
      "|  ORD001|       300.0|       300.0|       300.0|\n",
      "|  ORD003|       500.0|       500.0|       400.0|\n",
      "|  ORD002|       150.0|       200.0|       150.0|\n",
      "|  ORD004|       450.0|       450.0|       400.0|\n",
      "|  ORD008|       700.0|       700.0|       400.0|\n",
      "|  ORD005|       100.0|       200.0|       100.0|\n",
      "|  ORD006|       350.0|       350.0|       350.0|\n",
      "|  ORD007|       250.0|       250.0|       250.0|\n",
      "+--------+------------+------------+------------+\n",
      "\n",
      "\n",
      "üîπ Null handling:\n",
      "+--------+------------+--------------+----------+-----------+\n",
      "|order_id|total_amount|amount_or_zero|amount_nvl|amount_when|\n",
      "+--------+------------+--------------+----------+-----------+\n",
      "|  ORD001|       300.0|         300.0|     300.0|      300.0|\n",
      "|  ORD003|       500.0|         500.0|     500.0|      500.0|\n",
      "|  ORD002|       150.0|         150.0|     150.0|      150.0|\n",
      "|  ORD004|       450.0|         450.0|     450.0|      450.0|\n",
      "|  ORD008|       700.0|         700.0|     700.0|      700.0|\n",
      "|  ORD005|       100.0|         100.0|     100.0|      100.0|\n",
      "|  ORD006|       350.0|         350.0|     350.0|      350.0|\n",
      "|  ORD007|       250.0|         250.0|     250.0|      250.0|\n",
      "+--------+------------+--------------+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# First, calculate total amount from prices array - FIXED\n",
    "print(\"üîπ Calculating total amount from prices array:\")\n",
    "# C√°ch 1: S·ª≠ d·ª•ng explode v√† sum (d·ªÖ hi·ªÉu h∆°n)\n",
    "df_numeric = df.withColumn(\n",
    "    \"price_element\",\n",
    "    expr(\"explode(prices)\")\n",
    ").groupBy(\"order_id\").agg(\n",
    "    expr(\"sum(price_element)\").alias(\"total_amount\")\n",
    ")\n",
    "\n",
    "# Join l·∫°i v·ªõi DataFrame g·ªëc ƒë·ªÉ c√≥ c√°c c·ªôt kh√°c\n",
    "df_numeric = df.join(df_numeric, on=\"order_id\")\n",
    "\n",
    "# 6.1 Basic math operations\n",
    "print(\"üîπ Basic math operations:\")\n",
    "df_math = df_numeric.select(\n",
    "    \"order_id\",\n",
    "    \"total_amount\",\n",
    "    # Arithmetic\n",
    "    (col(\"total_amount\") + 10).alias(\"amount_plus_10\"),\n",
    "    (col(\"total_amount\") - 10).alias(\"amount_minus_10\"),\n",
    "    (col(\"total_amount\") * 1.1).alias(\"amount_with_tax\"),\n",
    "    (col(\"total_amount\") / 2).alias(\"amount_half\"),\n",
    "    (col(\"total_amount\") % 100).alias(\"amount_mod_100\")\n",
    ")\n",
    "\n",
    "df_math.show()\n",
    "\n",
    "# 6.2 Rounding functions\n",
    "print(\"\\nüîπ Rounding functions:\")\n",
    "df_round = df_numeric.select(\n",
    "    \"order_id\",\n",
    "    \"total_amount\",\n",
    "    round(col(\"total_amount\"), 0).alias(\"rounded\"),\n",
    "    round(col(\"total_amount\"), 2).alias(\"rounded_2dp\"),\n",
    "    ceil(col(\"total_amount\")).alias(\"ceiling\"),\n",
    "    floor(col(\"total_amount\")).alias(\"floor\"),\n",
    "    bround(col(\"total_amount\"), 0).alias(\"banker_rounded\")  # Banker's rounding\n",
    ")\n",
    "\n",
    "df_round.show()\n",
    "\n",
    "# 6.3 Mathematical functions\n",
    "print(\"\\nüîπ Mathematical functions:\")\n",
    "df_math_func = df_numeric.select(\n",
    "    \"order_id\",\n",
    "    \"total_amount\",\n",
    "    abs(col(\"total_amount\")).alias(\"absolute\"),\n",
    "    sqrt(col(\"total_amount\")).alias(\"square_root\"),\n",
    "    pow(col(\"total_amount\"), 2).alias(\"squared\"),\n",
    "    log(col(\"total_amount\")).alias(\"natural_log\"),\n",
    "    log10(col(\"total_amount\")).alias(\"log_base_10\"),\n",
    "    exp(lit(1)).alias(\"exponential\")\n",
    ")\n",
    "\n",
    "df_math_func.show()\n",
    "\n",
    "# 6.4 Statistical functions\n",
    "print(\"\\nüîπ Statistical functions:\")\n",
    "df_stats = df_numeric.select(\n",
    "    \"order_id\",\n",
    "    \"total_amount\",\n",
    "    # Min/Max with literal\n",
    "    greatest(col(\"total_amount\"), lit(200)).alias(\"max_with_200\"),\n",
    "    least(col(\"total_amount\"), lit(400)).alias(\"min_with_400\")\n",
    ")\n",
    "\n",
    "df_stats.show()\n",
    "\n",
    "# 6.5 Null handling in numeric operations\n",
    "print(\"\\nüîπ Null handling:\")\n",
    "df_null = df_numeric.select(\n",
    "    \"order_id\",\n",
    "    \"total_amount\",\n",
    "    coalesce(col(\"total_amount\"), lit(0)).alias(\"amount_or_zero\"),\n",
    "    nvl(col(\"total_amount\"), lit(0)).alias(\"amount_nvl\"),\n",
    "    when(col(\"total_amount\").isNull(), 0).otherwise(col(\"total_amount\")).alias(\"amount_when\")\n",
    ")\n",
    "\n",
    "df_null.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ Calculating total amount from prices array:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+------------+\n",
      "|order_id|              prices|total_amount|\n",
      "+--------+--------------------+------------+\n",
      "|  ORD008|[100.0, 200.0, 15...|       700.0|\n",
      "|  ORD005|             [100.0]|       100.0|\n",
      "|  ORD006|      [200.0, 150.0]|       350.0|\n",
      "|  ORD007|             [250.0]|       250.0|\n",
      "|  ORD001|      [100.0, 200.0]|       300.0|\n",
      "|  ORD003|[100.0, 150.0, 25...|       500.0|\n",
      "|  ORD002|             [150.0]|       150.0|\n",
      "|  ORD004|      [200.0, 250.0]|       450.0|\n",
      "+--------+--------------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+--------------+--------------------+--------------------+--------------------+-------------------+-------+---------+------------+\n",
      "|order_id|customer_id| customer_name|               email|            products|              prices|    order_timestamp|country|   status|total_amount|\n",
      "+--------+-----------+--------------+--------------------+--------------------+--------------------+-------------------+-------+---------+------------+\n",
      "|  ORD001|    CUST001|      John Doe|  john.doe@email.com|[Product A, Produ...|      [100.0, 200.0]|2024-01-15 10:30:00|    USA|completed|       300.0|\n",
      "|  ORD003|    CUST003|   Bob Johnson|bob.johnson@email...|[Product A, Produ...|[100.0, 150.0, 25...|2024-01-17 09:15:00| Canada|completed|       500.0|\n",
      "|  ORD002|    CUST002|    Jane Smith|jane.smith@email.com|         [Product C]|             [150.0]|2024-01-16 14:20:00|     UK|  pending|       150.0|\n",
      "|  ORD004|    CUST001|      John Doe|  john.doe@email.com|[Product B, Produ...|      [200.0, 250.0]|2024-01-18 16:45:00|    USA|cancelled|       450.0|\n",
      "|  ORD008|    CUST006|     David Lee| david.lee@email.com|[Product A, Produ...|[100.0, 200.0, 15...|2024-01-22 10:10:00| Canada|completed|       700.0|\n",
      "|  ORD005|    CUST004|   Alice Brown|alice.brown@email...|         [Product A]|             [100.0]|2024-01-19 11:00:00|    USA|completed|       100.0|\n",
      "|  ORD006|    CUST005|Charlie Wilson|charlie.wilson@em...|[Product B, Produ...|      [200.0, 150.0]|2024-01-20 13:30:00|     UK|completed|       350.0|\n",
      "|  ORD007|    CUST002|    Jane Smith|jane.smith@email.com|         [Product D]|             [250.0]|2024-01-21 15:20:00|     UK|  pending|       250.0|\n",
      "+--------+-----------+--------------+--------------------+--------------------+--------------------+-------------------+-------+---------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_numeric.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üì¶ **7. ARRAY OPERATIONS**\n",
    "\n",
    "X·ª≠ l√Ω m·∫£ng (arrays) - R·∫§T QUAN TR·ªåNG!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ Basic array functions:\n",
      "+--------+--------------------------------------------+----------------------------+------------+-------------+-----------+-------------+\n",
      "|order_id|products                                    |prices                      |num_products|first_product|first_price|has_product_a|\n",
      "+--------+--------------------------------------------+----------------------------+------------+-------------+-----------+-------------+\n",
      "|ORD001  |[Product A, Product B]                      |[100.0, 200.0]              |2           |Product A    |100.0      |true         |\n",
      "|ORD002  |[Product C]                                 |[150.0]                     |1           |Product C    |150.0      |false        |\n",
      "|ORD003  |[Product A, Product C, Product D]           |[100.0, 150.0, 250.0]       |3           |Product A    |100.0      |true         |\n",
      "|ORD004  |[Product B, Product D]                      |[200.0, 250.0]              |2           |Product B    |200.0      |false        |\n",
      "|ORD005  |[Product A]                                 |[100.0]                     |1           |Product A    |100.0      |true         |\n",
      "|ORD006  |[Product B, Product C]                      |[200.0, 150.0]              |2           |Product B    |200.0      |false        |\n",
      "|ORD007  |[Product D]                                 |[250.0]                     |1           |Product D    |250.0      |false        |\n",
      "|ORD008  |[Product A, Product B, Product C, Product D]|[100.0, 200.0, 150.0, 250.0]|4           |Product A    |100.0      |true         |\n",
      "+--------+--------------------------------------------+----------------------------+------------+-------------+-----------+-------------+\n",
      "\n",
      "\n",
      "üîπ Explode array to rows:\n",
      "+--------+--------------+---------+\n",
      "|order_id|customer_name |product  |\n",
      "+--------+--------------+---------+\n",
      "|ORD001  |John Doe      |Product A|\n",
      "|ORD001  |John Doe      |Product B|\n",
      "|ORD002  |Jane Smith    |Product C|\n",
      "|ORD003  |Bob Johnson   |Product A|\n",
      "|ORD003  |Bob Johnson   |Product C|\n",
      "|ORD003  |Bob Johnson   |Product D|\n",
      "|ORD004  |John Doe      |Product B|\n",
      "|ORD004  |John Doe      |Product D|\n",
      "|ORD005  |Alice Brown   |Product A|\n",
      "|ORD006  |Charlie Wilson|Product B|\n",
      "|ORD006  |Charlie Wilson|Product C|\n",
      "|ORD007  |Jane Smith    |Product D|\n",
      "|ORD008  |David Lee     |Product A|\n",
      "|ORD008  |David Lee     |Product B|\n",
      "|ORD008  |David Lee     |Product C|\n",
      "|ORD008  |David Lee     |Product D|\n",
      "+--------+--------------+---------+\n",
      "\n",
      "Original rows: 8, After explode: 16\n",
      "\n",
      "üîπ Explode with position:\n",
      "+--------+--------+---------+\n",
      "|order_id|position|product  |\n",
      "+--------+--------+---------+\n",
      "|ORD001  |0       |Product A|\n",
      "|ORD001  |1       |Product B|\n",
      "|ORD002  |0       |Product C|\n",
      "|ORD003  |0       |Product A|\n",
      "|ORD003  |1       |Product C|\n",
      "|ORD003  |2       |Product D|\n",
      "|ORD004  |0       |Product B|\n",
      "|ORD004  |1       |Product D|\n",
      "|ORD005  |0       |Product A|\n",
      "|ORD006  |0       |Product B|\n",
      "|ORD006  |1       |Product C|\n",
      "|ORD007  |0       |Product D|\n",
      "|ORD008  |0       |Product A|\n",
      "|ORD008  |1       |Product B|\n",
      "|ORD008  |2       |Product C|\n",
      "|ORD008  |3       |Product D|\n",
      "+--------+--------+---------+\n",
      "\n",
      "\n",
      "üîπ Explode multiple arrays (zip):\n",
      "+--------+--------------+---------+-----+\n",
      "|order_id|customer_name |product  |price|\n",
      "+--------+--------------+---------+-----+\n",
      "|ORD001  |John Doe      |Product A|100.0|\n",
      "|ORD001  |John Doe      |Product B|200.0|\n",
      "|ORD002  |Jane Smith    |Product C|150.0|\n",
      "|ORD003  |Bob Johnson   |Product A|100.0|\n",
      "|ORD003  |Bob Johnson   |Product C|150.0|\n",
      "|ORD003  |Bob Johnson   |Product D|250.0|\n",
      "|ORD004  |John Doe      |Product B|200.0|\n",
      "|ORD004  |John Doe      |Product D|250.0|\n",
      "|ORD005  |Alice Brown   |Product A|100.0|\n",
      "|ORD006  |Charlie Wilson|Product B|200.0|\n",
      "|ORD006  |Charlie Wilson|Product C|150.0|\n",
      "|ORD007  |Jane Smith    |Product D|250.0|\n",
      "|ORD008  |David Lee     |Product A|100.0|\n",
      "|ORD008  |David Lee     |Product B|200.0|\n",
      "|ORD008  |David Lee     |Product C|150.0|\n",
      "|ORD008  |David Lee     |Product D|250.0|\n",
      "+--------+--------------+---------+-----+\n",
      "\n",
      "\n",
      "üîπ Array aggregations:\n",
      "+--------+--------------------------------------------+----------------------------+------------+------------------+---------+---------+\n",
      "|order_id|products                                    |prices                      |total_amount|avg_price         |min_price|max_price|\n",
      "+--------+--------------------------------------------+----------------------------+------------+------------------+---------+---------+\n",
      "|ORD001  |[Product A, Product B]                      |[100.0, 200.0]              |300.0       |150.0             |100.0    |200.0    |\n",
      "|ORD002  |[Product C]                                 |[150.0]                     |150.0       |150.0             |150.0    |150.0    |\n",
      "|ORD003  |[Product A, Product C, Product D]           |[100.0, 150.0, 250.0]       |500.0       |166.66666666666666|100.0    |250.0    |\n",
      "|ORD004  |[Product B, Product D]                      |[200.0, 250.0]              |450.0       |225.0             |200.0    |250.0    |\n",
      "|ORD005  |[Product A]                                 |[100.0]                     |100.0       |100.0             |100.0    |100.0    |\n",
      "|ORD006  |[Product B, Product C]                      |[200.0, 150.0]              |350.0       |175.0             |150.0    |200.0    |\n",
      "|ORD007  |[Product D]                                 |[250.0]                     |250.0       |250.0             |250.0    |250.0    |\n",
      "|ORD008  |[Product A, Product B, Product C, Product D]|[100.0, 200.0, 150.0, 250.0]|700.0       |175.0             |100.0    |250.0    |\n",
      "+--------+--------------------------------------------+----------------------------+------------+------------------+---------+---------+\n",
      "\n",
      "\n",
      "üîπ Array transformations:\n",
      "+--------+--------------------------------------------+----------------------------+------------------------------------------------------+---------------+------------------+------------+\n",
      "|order_id|products                                    |prices                      |prices_with_tax                                       |expensive_items|has_expensive_item|all_positive|\n",
      "+--------+--------------------------------------------+----------------------------+------------------------------------------------------+---------------+------------------+------------+\n",
      "|ORD001  |[Product A, Product B]                      |[100.0, 200.0]              |[110.00000000000001, 220.00000000000003]              |[200.0]        |false             |true        |\n",
      "|ORD002  |[Product C]                                 |[150.0]                     |[165.0]                                               |[]             |false             |true        |\n",
      "|ORD003  |[Product A, Product C, Product D]           |[100.0, 150.0, 250.0]       |[110.00000000000001, 165.0, 275.0]                    |[250.0]        |true              |true        |\n",
      "|ORD004  |[Product B, Product D]                      |[200.0, 250.0]              |[220.00000000000003, 275.0]                           |[200.0, 250.0] |true              |true        |\n",
      "|ORD005  |[Product A]                                 |[100.0]                     |[110.00000000000001]                                  |[]             |false             |true        |\n",
      "|ORD006  |[Product B, Product C]                      |[200.0, 150.0]              |[220.00000000000003, 165.0]                           |[200.0]        |false             |true        |\n",
      "|ORD007  |[Product D]                                 |[250.0]                     |[275.0]                                               |[250.0]        |true              |true        |\n",
      "|ORD008  |[Product A, Product B, Product C, Product D]|[100.0, 200.0, 150.0, 250.0]|[110.00000000000001, 220.00000000000003, 165.0, 275.0]|[200.0, 250.0] |true              |true        |\n",
      "+--------+--------------------------------------------+----------------------------+------------------------------------------------------+---------------+------------------+------------+\n",
      "\n",
      "\n",
      "üîπ Array sorting and distinct:\n",
      "+--------+--------------------------------------------+----------------------------+--------------------------------------------+----------------------------+--------------------------------------------+--------------------------------------------+\n",
      "|order_id|products                                    |prices                      |products_sorted                             |prices_sorted               |products_unique                             |products_reversed                           |\n",
      "+--------+--------------------------------------------+----------------------------+--------------------------------------------+----------------------------+--------------------------------------------+--------------------------------------------+\n",
      "|ORD001  |[Product A, Product B]                      |[100.0, 200.0]              |[Product A, Product B]                      |[100.0, 200.0]              |[Product A, Product B]                      |[Product B, Product A]                      |\n",
      "|ORD002  |[Product C]                                 |[150.0]                     |[Product C]                                 |[150.0]                     |[Product C]                                 |[Product C]                                 |\n",
      "|ORD003  |[Product A, Product C, Product D]           |[100.0, 150.0, 250.0]       |[Product A, Product C, Product D]           |[100.0, 150.0, 250.0]       |[Product A, Product C, Product D]           |[Product D, Product C, Product A]           |\n",
      "|ORD004  |[Product B, Product D]                      |[200.0, 250.0]              |[Product B, Product D]                      |[200.0, 250.0]              |[Product B, Product D]                      |[Product D, Product B]                      |\n",
      "|ORD005  |[Product A]                                 |[100.0]                     |[Product A]                                 |[100.0]                     |[Product A]                                 |[Product A]                                 |\n",
      "|ORD006  |[Product B, Product C]                      |[200.0, 150.0]              |[Product B, Product C]                      |[150.0, 200.0]              |[Product B, Product C]                      |[Product C, Product B]                      |\n",
      "|ORD007  |[Product D]                                 |[250.0]                     |[Product D]                                 |[250.0]                     |[Product D]                                 |[Product D]                                 |\n",
      "|ORD008  |[Product A, Product B, Product C, Product D]|[100.0, 200.0, 150.0, 250.0]|[Product A, Product B, Product C, Product D]|[100.0, 150.0, 200.0, 250.0]|[Product A, Product B, Product C, Product D]|[Product D, Product C, Product B, Product A]|\n",
      "+--------+--------------------------------------------+----------------------------+--------------------------------------------+----------------------------+--------------------------------------------+--------------------------------------------+\n",
      "\n",
      "\n",
      "üîπ Array set operations:\n",
      "+--------+---------+---------+------------+---------+------+\n",
      "|order_id|array1   |array2   |union       |intersect|except|\n",
      "+--------+---------+---------+------------+---------+------+\n",
      "|ORD001  |[A, B, C]|[B, C, D]|[A, B, C, D]|[B, C]   |[A]   |\n",
      "|ORD002  |[X, Y]   |[Y, Z]   |[X, Y, Z]   |[Y]      |[X]   |\n",
      "+--------+---------+---------+------------+---------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 7.1 Basic array functions\n",
    "print(\"üîπ Basic array functions:\")\n",
    "df_array = df.select(\n",
    "    \"order_id\",\n",
    "    \"products\",\n",
    "    \"prices\",\n",
    "    # Array size\n",
    "    size(col(\"products\")).alias(\"num_products\"),\n",
    "    # Get element by index (0-based)\n",
    "    col(\"products\").getItem(0).alias(\"first_product\"),\n",
    "    col(\"prices\").getItem(0).alias(\"first_price\"),\n",
    "    # Check if array contains element\n",
    "    array_contains(col(\"products\"), \"Product A\").alias(\"has_product_a\")\n",
    ")\n",
    "\n",
    "df_array.show(truncate=False)\n",
    "\n",
    "# 7.2 Explode - Convert array to rows\n",
    "print(\"\\nüîπ Explode array to rows:\")\n",
    "df_exploded = df.select(\n",
    "    \"order_id\",\n",
    "    \"customer_name\",\n",
    "    explode(col(\"products\")).alias(\"product\")\n",
    ")\n",
    "\n",
    "df_exploded.show(truncate=False)\n",
    "print(f\"Original rows: {df.count()}, After explode: {df_exploded.count()}\")\n",
    "\n",
    "# 7.3 Explode with position\n",
    "print(\"\\nüîπ Explode with position:\")\n",
    "df_exploded_pos = df.select(\n",
    "    \"order_id\",\n",
    "    posexplode(col(\"products\")).alias(\"position\", \"product\")\n",
    ")\n",
    "\n",
    "df_exploded_pos.show(truncate=False)\n",
    "\n",
    "# 7.4 Explode multiple arrays together\n",
    "print(\"\\nüîπ Explode multiple arrays (zip):\")\n",
    "df_zipped = df.select(\n",
    "    \"order_id\",\n",
    "    \"customer_name\",\n",
    "    explode(arrays_zip(col(\"products\"), col(\"prices\"))).alias(\"item\")\n",
    ").select(\n",
    "    \"order_id\",\n",
    "    \"customer_name\",\n",
    "    col(\"item.products\").alias(\"product\"),\n",
    "    col(\"item.prices\").alias(\"price\")\n",
    ")\n",
    "\n",
    "df_zipped.show(truncate=False)\n",
    "\n",
    "# 7.5 Array aggregations\n",
    "print(\"\\nüîπ Array aggregations:\")\n",
    "df_agg = df.select(\n",
    "    \"order_id\",\n",
    "    \"products\",\n",
    "    \"prices\",\n",
    "    # Sum of array elements\n",
    "    expr(\"aggregate(prices, CAST(0 AS DOUBLE), (acc, x) -> acc + x)\").alias(\"total_amount\"),\n",
    "    # Average\n",
    "   (expr(\"aggregate(prices, CAST(0 AS DOUBLE), (acc, x) -> acc + x)\") / size(col(\"prices\"))).alias(\"avg_price\"),\n",
    "    # Min/Max\n",
    "    array_min(col(\"prices\")).alias(\"min_price\"),\n",
    "    array_max(col(\"prices\")).alias(\"max_price\")\n",
    ")\n",
    "\n",
    "df_agg.show(truncate=False)\n",
    "\n",
    "# 7.6 Array transformations\n",
    "print(\"\\nüîπ Array transformations:\")\n",
    "df_transform = df.select(\n",
    "    \"order_id\",\n",
    "    \"products\",\n",
    "    \"prices\",\n",
    "    # Transform each element (add 10% tax)\n",
    "    expr(\"transform(prices, x -> x * 1.1)\").alias(\"prices_with_tax\"),\n",
    "    # Filter array elements\n",
    "    expr(\"filter(prices, x -> x > 150)\").alias(\"expensive_items\"),\n",
    "    # Check if any element matches condition\n",
    "    expr(\"exists(prices, x -> x > 200)\").alias(\"has_expensive_item\"),\n",
    "    # Check if all elements match condition\n",
    "    expr(\"forall(prices, x -> x > 0)\").alias(\"all_positive\")\n",
    ")\n",
    "\n",
    "df_transform.show(truncate=False)\n",
    "\n",
    "# 7.7 Array sorting and distinct\n",
    "print(\"\\nüîπ Array sorting and distinct:\")\n",
    "df_sort = df.select(\n",
    "    \"order_id\",\n",
    "    \"products\",\n",
    "    \"prices\",\n",
    "    # Sort array\n",
    "    array_sort(col(\"products\")).alias(\"products_sorted\"),\n",
    "    array_sort(col(\"prices\")).alias(\"prices_sorted\"),\n",
    "    # Remove duplicates\n",
    "    array_distinct(col(\"products\")).alias(\"products_unique\"),\n",
    "    # Reverse array\n",
    "    reverse(col(\"products\")).alias(\"products_reversed\")\n",
    ")\n",
    "\n",
    "df_sort.show(truncate=False)\n",
    "\n",
    "# 7.8 Array union, intersect, except\n",
    "print(\"\\nüîπ Array set operations:\")\n",
    "# Create sample data for set operations\n",
    "df_sets = spark.createDataFrame([\n",
    "    (\"ORD001\", [\"A\", \"B\", \"C\"], [\"B\", \"C\", \"D\"]),\n",
    "    (\"ORD002\", [\"X\", \"Y\"], [\"Y\", \"Z\"])\n",
    "], [\"order_id\", \"array1\", \"array2\"])\n",
    "\n",
    "df_set_ops = df_sets.select(\n",
    "    \"order_id\",\n",
    "    \"array1\",\n",
    "    \"array2\",\n",
    "    # Union (combine arrays)\n",
    "    array_union(col(\"array1\"), col(\"array2\")).alias(\"union\"),\n",
    "    # Intersect (common elements)\n",
    "    array_intersect(col(\"array1\"), col(\"array2\")).alias(\"intersect\"),\n",
    "    # Except (elements in array1 but not in array2)\n",
    "    array_except(col(\"array1\"), col(\"array2\")).alias(\"except\")\n",
    ")\n",
    "\n",
    "df_set_ops.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üèóÔ∏è **8. STRUCT OPERATIONS**\n",
    "\n",
    "X·ª≠ l√Ω d·ªØ li·ªáu nested (struct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ Create struct:\n",
      "+--------+---------------------------------------------------+----------------------------------------------------------------------------+\n",
      "|order_id|customer_info                                      |order_details                                                               |\n",
      "+--------+---------------------------------------------------+----------------------------------------------------------------------------+\n",
      "|ORD001  |{CUST001, John Doe, john.doe@email.com}            |{[Product A, Product B], [100.0, 200.0]}                                    |\n",
      "|ORD002  |{CUST002, Jane Smith, jane.smith@email.com}        |{[Product C], [150.0]}                                                      |\n",
      "|ORD003  |{CUST003, Bob Johnson, bob.johnson@email.com}      |{[Product A, Product C, Product D], [100.0, 150.0, 250.0]}                  |\n",
      "|ORD004  |{CUST001, John Doe, john.doe@email.com}            |{[Product B, Product D], [200.0, 250.0]}                                    |\n",
      "|ORD005  |{CUST004, Alice Brown, alice.brown@email.com}      |{[Product A], [100.0]}                                                      |\n",
      "|ORD006  |{CUST005, Charlie Wilson, charlie.wilson@email.com}|{[Product B, Product C], [200.0, 150.0]}                                    |\n",
      "|ORD007  |{CUST002, Jane Smith, jane.smith@email.com}        |{[Product D], [250.0]}                                                      |\n",
      "|ORD008  |{CUST006, David Lee, david.lee@email.com}          |{[Product A, Product B, Product C, Product D], [100.0, 200.0, 150.0, 250.0]}|\n",
      "+--------+---------------------------------------------------+----------------------------------------------------------------------------+\n",
      "\n",
      "root\n",
      " |-- order_id: string (nullable = true)\n",
      " |-- customer_info: struct (nullable = false)\n",
      " |    |-- customer_id: string (nullable = true)\n",
      " |    |-- customer_name: string (nullable = true)\n",
      " |    |-- email: string (nullable = true)\n",
      " |-- order_details: struct (nullable = false)\n",
      " |    |-- items: array (nullable = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      " |    |-- amounts: array (nullable = true)\n",
      " |    |    |-- element: double (containsNull = true)\n",
      "\n",
      "\n",
      "üîπ Access struct fields:\n",
      "+--------+--------------+------------------------+--------------------------------------------+\n",
      "|order_id|name_1        |email_1                 |products                                    |\n",
      "+--------+--------------+------------------------+--------------------------------------------+\n",
      "|ORD001  |John Doe      |john.doe@email.com      |[Product A, Product B]                      |\n",
      "|ORD002  |Jane Smith    |jane.smith@email.com    |[Product C]                                 |\n",
      "|ORD003  |Bob Johnson   |bob.johnson@email.com   |[Product A, Product C, Product D]           |\n",
      "|ORD004  |John Doe      |john.doe@email.com      |[Product B, Product D]                      |\n",
      "|ORD005  |Alice Brown   |alice.brown@email.com   |[Product A]                                 |\n",
      "|ORD006  |Charlie Wilson|charlie.wilson@email.com|[Product B, Product C]                      |\n",
      "|ORD007  |Jane Smith    |jane.smith@email.com    |[Product D]                                 |\n",
      "|ORD008  |David Lee     |david.lee@email.com     |[Product A, Product B, Product C, Product D]|\n",
      "+--------+--------------+------------------------+--------------------------------------------+\n",
      "\n",
      "\n",
      "üîπ Flatten struct:\n",
      "+--------+-----------+--------------+------------------------+--------------------------------------------+----------------------------+\n",
      "|order_id|customer_id|customer_name |email                   |items                                       |amounts                     |\n",
      "+--------+-----------+--------------+------------------------+--------------------------------------------+----------------------------+\n",
      "|ORD001  |CUST001    |John Doe      |john.doe@email.com      |[Product A, Product B]                      |[100.0, 200.0]              |\n",
      "|ORD002  |CUST002    |Jane Smith    |jane.smith@email.com    |[Product C]                                 |[150.0]                     |\n",
      "|ORD003  |CUST003    |Bob Johnson   |bob.johnson@email.com   |[Product A, Product C, Product D]           |[100.0, 150.0, 250.0]       |\n",
      "|ORD004  |CUST001    |John Doe      |john.doe@email.com      |[Product B, Product D]                      |[200.0, 250.0]              |\n",
      "|ORD005  |CUST004    |Alice Brown   |alice.brown@email.com   |[Product A]                                 |[100.0]                     |\n",
      "|ORD006  |CUST005    |Charlie Wilson|charlie.wilson@email.com|[Product B, Product C]                      |[200.0, 150.0]              |\n",
      "|ORD007  |CUST002    |Jane Smith    |jane.smith@email.com    |[Product D]                                 |[250.0]                     |\n",
      "|ORD008  |CUST006    |David Lee     |david.lee@email.com     |[Product A, Product B, Product C, Product D]|[100.0, 200.0, 150.0, 250.0]|\n",
      "+--------+-----------+--------------+------------------------+--------------------------------------------+----------------------------+\n",
      "\n",
      "\n",
      "üîπ Complex nested structure:\n",
      "+--------+---------------------------------------------------------+---------------------------------------------------------------------------------------+\n",
      "|order_id|customer                                                 |order                                                                                  |\n",
      "+--------+---------------------------------------------------------+---------------------------------------------------------------------------------------+\n",
      "|ORD001  |{CUST001, John Doe, {john.doe@email.com, USA}}           |{[Product A, Product B], [100.0, 200.0], completed}                                    |\n",
      "|ORD002  |{CUST002, Jane Smith, {jane.smith@email.com, UK}}        |{[Product C], [150.0], pending}                                                        |\n",
      "|ORD003  |{CUST003, Bob Johnson, {bob.johnson@email.com, Canada}}  |{[Product A, Product C, Product D], [100.0, 150.0, 250.0], completed}                  |\n",
      "|ORD004  |{CUST001, John Doe, {john.doe@email.com, USA}}           |{[Product B, Product D], [200.0, 250.0], cancelled}                                    |\n",
      "|ORD005  |{CUST004, Alice Brown, {alice.brown@email.com, USA}}     |{[Product A], [100.0], completed}                                                      |\n",
      "|ORD006  |{CUST005, Charlie Wilson, {charlie.wilson@email.com, UK}}|{[Product B, Product C], [200.0, 150.0], completed}                                    |\n",
      "|ORD007  |{CUST002, Jane Smith, {jane.smith@email.com, UK}}        |{[Product D], [250.0], pending}                                                        |\n",
      "|ORD008  |{CUST006, David Lee, {david.lee@email.com, Canada}}      |{[Product A, Product B, Product C, Product D], [100.0, 200.0, 150.0, 250.0], completed}|\n",
      "+--------+---------------------------------------------------------+---------------------------------------------------------------------------------------+\n",
      "\n",
      "root\n",
      " |-- order_id: string (nullable = true)\n",
      " |-- customer: struct (nullable = false)\n",
      " |    |-- customer_id: string (nullable = true)\n",
      " |    |-- customer_name: string (nullable = true)\n",
      " |    |-- contact: struct (nullable = false)\n",
      " |    |    |-- email: string (nullable = true)\n",
      " |    |    |-- country: string (nullable = true)\n",
      " |-- order: struct (nullable = false)\n",
      " |    |-- products: array (nullable = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      " |    |-- prices: array (nullable = true)\n",
      " |    |    |-- element: double (containsNull = true)\n",
      " |    |-- status: string (nullable = true)\n",
      "\n",
      "\n",
      "üîπ Access deeply nested fields:\n",
      "+--------+--------------+------------------------+-------+---------+\n",
      "|order_id|name          |email                   |country|status   |\n",
      "+--------+--------------+------------------------+-------+---------+\n",
      "|ORD001  |John Doe      |john.doe@email.com      |USA    |completed|\n",
      "|ORD002  |Jane Smith    |jane.smith@email.com    |UK     |pending  |\n",
      "|ORD003  |Bob Johnson   |bob.johnson@email.com   |Canada |completed|\n",
      "|ORD004  |John Doe      |john.doe@email.com      |USA    |cancelled|\n",
      "|ORD005  |Alice Brown   |alice.brown@email.com   |USA    |completed|\n",
      "|ORD006  |Charlie Wilson|charlie.wilson@email.com|UK     |completed|\n",
      "|ORD007  |Jane Smith    |jane.smith@email.com    |UK     |pending  |\n",
      "|ORD008  |David Lee     |david.lee@email.com     |Canada |completed|\n",
      "+--------+--------------+------------------------+-------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 8.1 Create struct\n",
    "print(\"üîπ Create struct:\")\n",
    "df_struct = df.select(\n",
    "    \"order_id\",\n",
    "    # Create struct from columns\n",
    "    struct(\n",
    "        col(\"customer_id\"),\n",
    "        col(\"customer_name\"),\n",
    "        col(\"email\")\n",
    "    ).alias(\"customer_info\"),\n",
    "    # Create struct with named fields\n",
    "    struct(\n",
    "        col(\"products\").alias(\"items\"),\n",
    "        col(\"prices\").alias(\"amounts\")\n",
    "    ).alias(\"order_details\")\n",
    ")\n",
    "\n",
    "df_struct.show(truncate=False)\n",
    "df_struct.printSchema()\n",
    "\n",
    "# 8.2 Access struct fields\n",
    "print(\"\\nüîπ Access struct fields:\")\n",
    "df_access = df_struct.select(\n",
    "    \"order_id\",\n",
    "    # Method 1: Dot notation\n",
    "    col(\"customer_info.customer_name\").alias(\"name_1\"),\n",
    "    # Method 2: getField\n",
    "    col(\"customer_info\").getField(\"email\").alias(\"email_1\"),\n",
    "    # Access nested array in struct\n",
    "    col(\"order_details.items\").alias(\"products\")\n",
    ")\n",
    "\n",
    "df_access.show(truncate=False)\n",
    "\n",
    "# 8.3 Flatten struct\n",
    "print(\"\\nüîπ Flatten struct:\")\n",
    "df_flatten = df_struct.select(\n",
    "    \"order_id\",\n",
    "    \"customer_info.*\",  # Flatten all fields\n",
    "    \"order_details.*\"\n",
    ")\n",
    "\n",
    "df_flatten.show(truncate=False)\n",
    "\n",
    "# 8.4 Complex nested structure\n",
    "print(\"\\nüîπ Complex nested structure:\")\n",
    "df_complex = df.select(\n",
    "    \"order_id\",\n",
    "    struct(\n",
    "        col(\"customer_id\"),\n",
    "        col(\"customer_name\"),\n",
    "        struct(\n",
    "            col(\"email\"),\n",
    "            col(\"country\")\n",
    "        ).alias(\"contact\")\n",
    "    ).alias(\"customer\"),\n",
    "    struct(\n",
    "        col(\"products\"),\n",
    "        col(\"prices\"),\n",
    "        col(\"status\")\n",
    "    ).alias(\"order\")\n",
    ")\n",
    "\n",
    "df_complex.show(truncate=False)\n",
    "df_complex.printSchema()\n",
    "\n",
    "# Access deeply nested fields\n",
    "print(\"\\nüîπ Access deeply nested fields:\")\n",
    "df_deep = df_complex.select(\n",
    "    \"order_id\",\n",
    "    col(\"customer.customer_name\").alias(\"name\"),\n",
    "    col(\"customer.contact.email\").alias(\"email\"),\n",
    "    col(\"customer.contact.country\").alias(\"country\"),\n",
    "    col(\"order.status\").alias(\"status\")\n",
    ")\n",
    "\n",
    "df_deep.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üé® **9. USER DEFINED FUNCTIONS (UDFs)**\n",
    "\n",
    "‚ö†Ô∏è **WARNING:** UDFs are SLOW! Use built-in functions when possible!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ Simple Python UDF:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+---------------+\n",
      "|order_id|total_amount|amount_category|\n",
      "+--------+------------+---------------+\n",
      "|  ORD001|       300.0|         Medium|\n",
      "|  ORD002|       150.0|            Low|\n",
      "|  ORD003|       500.0|           High|\n",
      "|  ORD004|       450.0|           High|\n",
      "|  ORD005|       100.0|            Low|\n",
      "|  ORD006|       350.0|         Medium|\n",
      "|  ORD007|       250.0|         Medium|\n",
      "|  ORD008|       700.0|           High|\n",
      "+--------+------------+---------------+\n",
      "\n",
      "\n",
      "üîπ UDF with multiple inputs:\n",
      "+--------+------------+-------+---------+---------------+\n",
      "|order_id|total_amount|country|   status|discount_amount|\n",
      "+--------+------------+-------+---------+---------------+\n",
      "|  ORD001|       300.0|    USA|completed|           45.0|\n",
      "|  ORD002|       150.0|     UK|  pending|            0.0|\n",
      "|  ORD003|       500.0| Canada|completed|           25.0|\n",
      "|  ORD004|       450.0|    USA|cancelled|            0.0|\n",
      "|  ORD005|       100.0|    USA|completed|           15.0|\n",
      "|  ORD006|       350.0|     UK|completed|           35.0|\n",
      "|  ORD007|       250.0|     UK|  pending|            0.0|\n",
      "|  ORD008|       700.0| Canada|completed|           35.0|\n",
      "+--------+------------+-------+---------+---------------+\n",
      "\n",
      "\n",
      "üîπ UDF with complex return type:\n",
      "+--------+------------------------+--------------+---------+\n",
      "|order_id|email                   |username      |domain   |\n",
      "+--------+------------------------+--------------+---------+\n",
      "|ORD001  |john.doe@email.com      |john.doe      |email.com|\n",
      "|ORD002  |jane.smith@email.com    |jane.smith    |email.com|\n",
      "|ORD003  |bob.johnson@email.com   |bob.johnson   |email.com|\n",
      "|ORD004  |john.doe@email.com      |john.doe      |email.com|\n",
      "|ORD005  |alice.brown@email.com   |alice.brown   |email.com|\n",
      "|ORD006  |charlie.wilson@email.com|charlie.wilson|email.com|\n",
      "|ORD007  |jane.smith@email.com    |jane.smith    |email.com|\n",
      "|ORD008  |david.lee@email.com     |david.lee     |email.com|\n",
      "+--------+------------------------+--------------+---------+\n",
      "\n",
      "\n",
      "üîπ Register UDF for SQL:\n",
      "+--------+------------+--------+\n",
      "|order_id|total_amount|category|\n",
      "+--------+------------+--------+\n",
      "|  ORD001|       300.0|  Medium|\n",
      "|  ORD002|       150.0|     Low|\n",
      "|  ORD003|       500.0|    High|\n",
      "|  ORD004|       450.0|    High|\n",
      "|  ORD005|       100.0|     Low|\n",
      "|  ORD006|       350.0|  Medium|\n",
      "|  ORD007|       250.0|  Medium|\n",
      "|  ORD008|       700.0|    High|\n",
      "+--------+------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 9.1 Simple Python UDF\n",
    "print(\"üîπ Simple Python UDF:\")\n",
    "\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "# Define Python function\n",
    "def categorize_amount(amount):\n",
    "    if amount < 200:\n",
    "        return \"Low\"\n",
    "    elif amount < 400:\n",
    "        return \"Medium\"\n",
    "    else:\n",
    "        return \"High\"\n",
    "\n",
    "# Register as UDF\n",
    "categorize_udf = udf(categorize_amount, StringType())\n",
    "\n",
    "# Use UDF\n",
    "df_with_amount = df.withColumn(\n",
    "    \"total_amount\",\n",
    "    expr(\"aggregate(prices, CAST(0 AS DOUBLE), (acc, x) -> acc + x)\")\n",
    ")\n",
    "\n",
    "df_udf = df_with_amount.withColumn(\n",
    "    \"amount_category\",\n",
    "    categorize_udf(col(\"total_amount\"))\n",
    ")\n",
    "\n",
    "df_udf.select(\"order_id\", \"total_amount\", \"amount_category\").show()\n",
    "\n",
    "# 9.2 UDF with multiple inputs\n",
    "print(\"\\nüîπ UDF with multiple inputs:\")\n",
    "\n",
    "def calculate_discount(amount, country, status):\n",
    "    discount = 0.0\n",
    "    if status == \"completed\":\n",
    "        if country == \"USA\":\n",
    "            discount = 0.15\n",
    "        elif country == \"UK\":\n",
    "            discount = 0.10\n",
    "        else:\n",
    "            discount = 0.05\n",
    "    return amount * discount\n",
    "\n",
    "discount_udf = udf(calculate_discount, DoubleType())\n",
    "\n",
    "df_discount = df_with_amount.withColumn(\n",
    "    \"discount_amount\",\n",
    "    discount_udf(col(\"total_amount\"), col(\"country\"), col(\"status\"))\n",
    ")\n",
    "\n",
    "df_discount.select(\"order_id\", \"total_amount\", \"country\", \"status\", \"discount_amount\").show()\n",
    "\n",
    "# 9.3 UDF with complex return type\n",
    "print(\"\\nüîπ UDF with complex return type:\")\n",
    "\n",
    "def parse_email(email):\n",
    "    if email:\n",
    "        parts = email.split(\"@\")\n",
    "        return {\"username\": parts[0], \"domain\": parts[1] if len(parts) > 1 else None}\n",
    "    return {\"username\": None, \"domain\": None}\n",
    "\n",
    "email_schema = StructType([\n",
    "    StructField(\"username\", StringType(), True),\n",
    "    StructField(\"domain\", StringType(), True)\n",
    "])\n",
    "\n",
    "parse_email_udf = udf(parse_email, email_schema)\n",
    "\n",
    "df_email = df.withColumn(\n",
    "    \"email_parts\",\n",
    "    parse_email_udf(col(\"email\"))\n",
    ").select(\n",
    "    \"order_id\",\n",
    "    \"email\",\n",
    "    \"email_parts.*\"\n",
    ")\n",
    "\n",
    "df_email.show(truncate=False)\n",
    "\n",
    "# 9.4 Register UDF for SQL\n",
    "print(\"\\nüîπ Register UDF for SQL:\")\n",
    "\n",
    "spark.udf.register(\"categorize_amount_sql\", categorize_amount, StringType())\n",
    "\n",
    "df_with_amount.createOrReplaceTempView(\"orders\")\n",
    "\n",
    "df_sql_udf = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        order_id,\n",
    "        total_amount,\n",
    "        categorize_amount_sql(total_amount) as category\n",
    "    FROM orders\n",
    "\"\"\")\n",
    "\n",
    "df_sql_udf.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚ö° **10. PANDAS UDFs (VECTORIZED UDFs)**\n",
    "\n",
    "‚úÖ **MUCH FASTER** than regular UDFs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ Pandas UDF (Scalar):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26/01/08 17:08:10 WARN TaskSetManager: Lost task 0.0 in stage 148.0 (TID 159) (172.18.0.7 executor 0): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n",
      "  File \"/opt/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1231, in main\n",
      "    func, profiler, deserializer, serializer = read_udfs(pickleSer, infile, eval_type)\n",
      "  File \"/opt/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1067, in read_udfs\n",
      "    udfs.append(read_single_udf(pickleSer, infile, eval_type, runner_conf, udf_index=i))\n",
      "  File \"/opt/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 529, in read_single_udf\n",
      "    f, return_type = read_command(pickleSer, infile)\n",
      "  File \"/opt/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 90, in read_command\n",
      "    command = serializer._read_with_length(file)\n",
      "  File \"/opt/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 174, in _read_with_length\n",
      "    return self.loads(obj)\n",
      "  File \"/opt/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 472, in loads\n",
      "    return cloudpickle.loads(obj, encoding=encoding)\n",
      "ModuleNotFoundError: No module named 'pandas'\n",
      "\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\n",
      "\tat org.apache.spark.sql.execution.python.PythonArrowOutput$$anon$1.read(PythonArrowOutput.scala:118)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:893)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:893)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\n",
      "\tat java.base/java.lang.Thread.run(Unknown Source)\n",
      "\n",
      "26/01/08 17:08:10 ERROR TaskSetManager: Task 0 in stage 148.0 failed 4 times; aborting job\n"
     ]
    },
    {
     "ename": "PythonException",
     "evalue": "\n  An exception was thrown from the Python worker. Please see the stack trace below.\nTraceback (most recent call last):\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1231, in main\n    func, profiler, deserializer, serializer = read_udfs(pickleSer, infile, eval_type)\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1067, in read_udfs\n    udfs.append(read_single_udf(pickleSer, infile, eval_type, runner_conf, udf_index=i))\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 529, in read_single_udf\n    f, return_type = read_command(pickleSer, infile)\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 90, in read_command\n    command = serializer._read_with_length(file)\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 174, in _read_with_length\n    return self.loads(obj)\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 472, in loads\n    return cloudpickle.loads(obj, encoding=encoding)\nModuleNotFoundError: No module named 'pandas'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPythonException\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 16\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m amounts\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLow\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m200\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMedium\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m400\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHigh\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     11\u001b[0m df_pandas_udf \u001b[38;5;241m=\u001b[39m df_with_amount\u001b[38;5;241m.\u001b[39mwithColumn(\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mamount_category_pandas\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     13\u001b[0m     categorize_amount_pandas(col(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtotal_amount\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     14\u001b[0m )\n\u001b[0;32m---> 16\u001b[0m \u001b[43mdf_pandas_udf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43morder_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtotal_amount\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mamount_category_pandas\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# # 10.2 Pandas UDF with multiple columns\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# print(\"\\nüîπ Pandas UDF with multiple columns:\")\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# print(\"Pandas UDF: Processes batches using Arrow (FAST)\")\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# print(\"Speedup: 3-100x faster depending on data size!\")\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pyspark/sql/dataframe.py:945\u001b[0m, in \u001b[0;36mDataFrame.show\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    885\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mshow\u001b[39m(\u001b[38;5;28mself\u001b[39m, n: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m, truncate: Union[\u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, vertical: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    886\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Prints the first ``n`` rows to the console.\u001b[39;00m\n\u001b[1;32m    887\u001b[0m \n\u001b[1;32m    888\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    943\u001b[0m \u001b[38;5;124;03m    name | Bob\u001b[39;00m\n\u001b[1;32m    944\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 945\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_show_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvertical\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pyspark/sql/dataframe.py:963\u001b[0m, in \u001b[0;36mDataFrame._show_string\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    957\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PySparkTypeError(\n\u001b[1;32m    958\u001b[0m         error_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNOT_BOOL\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    959\u001b[0m         message_parameters\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvertical\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(vertical)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m},\n\u001b[1;32m    960\u001b[0m     )\n\u001b[1;32m    962\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(truncate, \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m truncate:\n\u001b[0;32m--> 963\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshowString\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvertical\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    965\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pyspark/errors/exceptions/captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    181\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mPythonException\u001b[0m: \n  An exception was thrown from the Python worker. Please see the stack trace below.\nTraceback (most recent call last):\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1231, in main\n    func, profiler, deserializer, serializer = read_udfs(pickleSer, infile, eval_type)\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1067, in read_udfs\n    udfs.append(read_single_udf(pickleSer, infile, eval_type, runner_conf, udf_index=i))\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 529, in read_single_udf\n    f, return_type = read_command(pickleSer, infile)\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 90, in read_command\n    command = serializer._read_with_length(file)\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 174, in _read_with_length\n    return self.loads(obj)\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 472, in loads\n    return cloudpickle.loads(obj, encoding=encoding)\nModuleNotFoundError: No module named 'pandas'\n"
     ]
    }
   ],
   "source": [
    "# 10.1 Pandas UDF (Scalar)\n",
    "print(\"üîπ Pandas UDF (Scalar):\")\n",
    "\n",
    "from pyspark.sql.functions import pandas_udf\n",
    "import pandas as pd\n",
    "\n",
    "@pandas_udf(StringType())\n",
    "def categorize_amount_pandas(amounts: pd.Series) -> pd.Series:\n",
    "    return amounts.apply(lambda x: \"Low\" if x < 200 else (\"Medium\" if x < 400 else \"High\"))\n",
    "\n",
    "df_pandas_udf = df_with_amount.withColumn(\n",
    "    \"amount_category_pandas\",\n",
    "    categorize_amount_pandas(col(\"total_amount\"))\n",
    ")\n",
    "\n",
    "df_pandas_udf.select(\"order_id\", \"total_amount\", \"amount_category_pandas\").show()\n",
    "\n",
    "# # 10.2 Pandas UDF with multiple columns\n",
    "# print(\"\\nüîπ Pandas UDF with multiple columns:\")\n",
    "\n",
    "# @pandas_udf(DoubleType())\n",
    "# def calculate_discount_pandas(amounts: pd.Series, countries: pd.Series, statuses: pd.Series) -> pd.Series:\n",
    "#     def calc(amount, country, status):\n",
    "#         if status == \"completed\":\n",
    "#             if country == \"USA\":\n",
    "#                 return amount * 0.15\n",
    "#             elif country == \"UK\":\n",
    "#                 return amount * 0.10\n",
    "#             else:\n",
    "#                 return amount * 0.05\n",
    "#         return 0.0\n",
    "    \n",
    "#     return pd.Series([calc(a, c, s) for a, c, s in zip(amounts, countries, statuses)])\n",
    "\n",
    "# df_pandas_discount = df_with_amount.withColumn(\n",
    "#     \"discount_pandas\",\n",
    "#     calculate_discount_pandas(col(\"total_amount\"), col(\"country\"), col(\"status\"))\n",
    "# )\n",
    "\n",
    "# df_pandas_discount.select(\"order_id\", \"total_amount\", \"country\", \"status\", \"discount_pandas\").show()\n",
    "\n",
    "# # 10.3 Performance comparison: Regular UDF vs Pandas UDF\n",
    "# print(\"\\n‚ö° Performance Comparison:\")\n",
    "# print(\"Regular UDF: Processes row by row (SLOW)\")\n",
    "# print(\"Pandas UDF: Processes batches using Arrow (FAST)\")\n",
    "# print(\"Speedup: 3-100x faster depending on data size!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéØ **11. BEST PRACTICES & PERFORMANCE TIPS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"üéØ TRANSFORMATION BEST PRACTICES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\"\"\n",
    "‚úÖ DO:\n",
    "1. Use built-in functions whenever possible (MUCH faster than UDFs)\n",
    "2. Use Pandas UDFs instead of regular UDFs (3-100x faster)\n",
    "3. Chain transformations efficiently (lazy evaluation)\n",
    "4. Use selectExpr for complex SQL expressions\n",
    "5. Use expr() for complex logic instead of nested when/otherwise\n",
    "6. Leverage array functions instead of explode when possible\n",
    "7. Use broadcast for small lookup tables\n",
    "8. Cache intermediate results if reused multiple times\n",
    "\n",
    "‚ùå DON'T:\n",
    "1. Use Python UDFs unless absolutely necessary (very slow!)\n",
    "2. Use collect() on large datasets (brings all data to driver)\n",
    "3. Use rdd.map() when DataFrame operations are available\n",
    "4. Create too many small partitions (overhead)\n",
    "5. Use UDFs for operations that can be done with built-in functions\n",
    "6. Explode large arrays unnecessarily (data multiplication)\n",
    "7. Use nested loops in UDFs (extremely slow)\n",
    "8. Ignore null handling (causes errors)\n",
    "\n",
    "‚ö° PERFORMANCE RANKING (Fastest to Slowest):\n",
    "1. Built-in functions (SQL expressions) ‚ö°‚ö°‚ö°‚ö°‚ö°\n",
    "2. Pandas UDFs (Vectorized) ‚ö°‚ö°‚ö°‚ö°\n",
    "3. Python UDFs ‚ö°‚ö°\n",
    "4. RDD operations ‚ö°\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üíæ **12. SAVE TRANSFORMED DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create final transformed dataset\n",
    "df_final = df.withColumn(\n",
    "    \"order_datetime\",\n",
    "    to_timestamp(col(\"order_timestamp\"), \"yyyy-MM-dd HH:mm:ss\")\n",
    ").withColumn(\n",
    "    \"total_amount\",\n",
    "    expr(\"aggregate(prices, 0.0, (acc, x) -> acc + x)\")\n",
    ").withColumn(\n",
    "    \"num_products\",\n",
    "    size(col(\"products\"))\n",
    ").withColumn(\n",
    "    \"avg_price\",\n",
    "    col(\"total_amount\") / col(\"num_products\")\n",
    ").withColumn(\n",
    "    \"order_date\",\n",
    "    to_date(col(\"order_datetime\"))\n",
    ").withColumn(\n",
    "    \"order_year\",\n",
    "    year(col(\"order_datetime\"))\n",
    ").withColumn(\n",
    "    \"order_month\",\n",
    "    month(col(\"order_datetime\"))\n",
    ").withColumn(\n",
    "    \"amount_category\",\n",
    "    when(col(\"total_amount\") < 200, \"Low\")\n",
    "    .when(col(\"total_amount\") < 400, \"Medium\")\n",
    "    .otherwise(\"High\")\n",
    ")\n",
    "\n",
    "print(\"‚úÖ FINAL TRANSFORMED DATA:\")\n",
    "df_final.show(truncate=False)\n",
    "\n",
    "# Save to MinIO\n",
    "output_path = \"s3a://warehouse/transformed_orders/\"\n",
    "\n",
    "df_final.write \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .partitionBy(\"order_year\", \"order_month\") \\\n",
    "    .parquet(output_path)\n",
    "\n",
    "print(f\"\\n‚úÖ Data saved to: {output_path}\")\n",
    "\n",
    "# Verify\n",
    "df_verify = spark.read.parquet(output_path)\n",
    "print(f\"\\n‚úÖ Verification: {df_verify.count()} rows loaded\")\n",
    "df_verify.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéì **KEY TAKEAWAYS**\n",
    "\n",
    "### **‚úÖ What You Learned:**\n",
    "\n",
    "1. **Conditional Logic** - when/otherwise, case statements\n",
    "2. **String Operations** - concat, split, regex, substring\n",
    "3. **Date/Time** - date_add, date_diff, date_format, date_trunc\n",
    "4. **Numeric Operations** - round, ceil, floor, math functions\n",
    "5. **Array Operations** - explode, array functions, transformations\n",
    "6. **Struct Operations** - nested data handling\n",
    "7. **UDFs** - Python UDFs (slow) vs Pandas UDFs (fast)\n",
    "8. **Performance** - Always prefer built-in functions!\n",
    "\n",
    "### **üöÄ Next Steps:**\n",
    "- **Day 3 - Lesson 2:** Aggregations (groupBy, pivot, rollup, cube)\n",
    "- **Day 3 - Lesson 3:** Window Functions (ranking, lag/lead, running totals)\n",
    "- **Day 3 - Lesson 4:** Joins (inner, outer, broadcast, optimization)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "spark.stop()\n",
    "print(\"‚úÖ Spark session stopped\")\n",
    "print(\"\\nüéâ DAY 3 - LESSON 1 COMPLETED!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
