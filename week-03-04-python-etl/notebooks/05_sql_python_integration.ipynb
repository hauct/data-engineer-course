{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üîó B√ÄI 5: SQL + PYTHON INTEGRATION\n",
    "\n",
    "## M·ª•c ti√™u:\n",
    "- Execute SQL from Python\n",
    "- Parameterized queries\n",
    "- Batch operations\n",
    "- Transaction management\n",
    "- Performance optimization\n",
    "- Real-world ETL pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-17 17:38:20,628 - db_connector - INFO - Database connector initialized for data_engineer@postgres\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Setup complete!\n",
      "Database: data_engineer\n"
     ]
    }
   ],
   "source": [
    "# Setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import sys\n",
    "sys.path.append('/home/jovyan/week-03-04-python-etl/scripts')\n",
    "\n",
    "from db_connector import DatabaseConnector\n",
    "from data_cleaner import DataCleaner\n",
    "from validators import DataValidator\n",
    "from etl_pipeline import ETLPipeline\n",
    "\n",
    "# Initialize database connection\n",
    "db = DatabaseConnector()\n",
    "\n",
    "print(\"‚úÖ Setup complete!\")\n",
    "print(f\"Database: {db.config['database']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üìä PART 1: Basic SQL Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/week-03-04-python-etl/scripts/db_connector.py:105: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql_query(query, conn, params=params)\n",
      "2025-12-17 17:38:26,728 - db_connector - INFO - Query executed, DataFrame shape: (10, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query returned 10 rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>customer_count</th>\n",
       "      <th>segments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ghana</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Uruguay</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bahamas</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Romania</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Portugal</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Northern Mariana Islands</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Australia</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Italy</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>New Caledonia</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Pitcairn Islands</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    country  customer_count  segments\n",
       "0                     Ghana              11         3\n",
       "1                   Uruguay              10         3\n",
       "2                   Bahamas               9         3\n",
       "3                   Romania               8         3\n",
       "4                  Portugal               8         3\n",
       "5  Northern Mariana Islands               8         3\n",
       "6                 Australia               8         3\n",
       "7                     Italy               8         3\n",
       "8             New Caledonia               8         3\n",
       "9          Pitcairn Islands               8         3"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Execute simple SELECT query\n",
    "query = \"\"\"\n",
    "    SELECT \n",
    "        country,\n",
    "        COUNT(*) as customer_count,\n",
    "        COUNT(DISTINCT customer_segment) as segments\n",
    "    FROM analytics.customers\n",
    "    GROUP BY country\n",
    "    ORDER BY customer_count DESC\n",
    "    LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "# YOUR CODE HERE\n",
    "result = db.read_sql(query)\n",
    "\n",
    "print(f\"Query returned {len(result)} rows\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/week-03-04-python-etl/scripts/db_connector.py:105: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql_query(query, conn, params=params)\n",
      "2025-12-17 17:38:27,640 - db_connector - INFO - Query executed, DataFrame shape: (27, 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last 30 days statistics:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>orders</th>\n",
       "      <th>revenue</th>\n",
       "      <th>avg_order_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-12-13</td>\n",
       "      <td>18</td>\n",
       "      <td>85558.56</td>\n",
       "      <td>4753.253333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-12-12</td>\n",
       "      <td>10</td>\n",
       "      <td>40301.36</td>\n",
       "      <td>4030.136000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-12-11</td>\n",
       "      <td>14</td>\n",
       "      <td>51609.93</td>\n",
       "      <td>3686.423571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-12-10</td>\n",
       "      <td>10</td>\n",
       "      <td>40570.81</td>\n",
       "      <td>4057.081000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-12-09</td>\n",
       "      <td>18</td>\n",
       "      <td>72533.67</td>\n",
       "      <td>4029.648333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2025-12-08</td>\n",
       "      <td>9</td>\n",
       "      <td>46702.58</td>\n",
       "      <td>5189.175556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2025-12-07</td>\n",
       "      <td>12</td>\n",
       "      <td>53885.99</td>\n",
       "      <td>4490.499167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2025-12-06</td>\n",
       "      <td>19</td>\n",
       "      <td>62177.78</td>\n",
       "      <td>3272.514737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2025-12-05</td>\n",
       "      <td>15</td>\n",
       "      <td>73639.38</td>\n",
       "      <td>4909.292000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2025-12-04</td>\n",
       "      <td>21</td>\n",
       "      <td>79963.36</td>\n",
       "      <td>3807.779048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  orders   revenue  avg_order_value\n",
       "0  2025-12-13      18  85558.56      4753.253333\n",
       "1  2025-12-12      10  40301.36      4030.136000\n",
       "2  2025-12-11      14  51609.93      3686.423571\n",
       "3  2025-12-10      10  40570.81      4057.081000\n",
       "4  2025-12-09      18  72533.67      4029.648333\n",
       "5  2025-12-08       9  46702.58      5189.175556\n",
       "6  2025-12-07      12  53885.99      4490.499167\n",
       "7  2025-12-06      19  62177.78      3272.514737\n",
       "8  2025-12-05      15  73639.38      4909.292000\n",
       "9  2025-12-04      21  79963.36      3807.779048"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Execute query with date filter\n",
    "query = \"\"\"\n",
    "    SELECT \n",
    "        DATE(order_date) as date,\n",
    "        COUNT(*) as orders,\n",
    "        SUM(total_amount) as revenue,\n",
    "        AVG(total_amount) as avg_order_value\n",
    "    FROM analytics.orders\n",
    "    WHERE order_date >= CURRENT_DATE - INTERVAL '30 days'\n",
    "    GROUP BY DATE(order_date)\n",
    "    ORDER BY date DESC\n",
    "\"\"\"\n",
    "\n",
    "# YOUR CODE HERE\n",
    "daily_stats = db.read_sql(query)\n",
    "\n",
    "print(f\"Last 30 days statistics:\")\n",
    "daily_stats.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üéØ EXERCISE 1: Parameterized Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Query with parameters (safe from SQL injection)\n",
    "def get_customers_by_country(country_name):\n",
    "    \"\"\"\n",
    "    Get customers from specific country using parameterized query\n",
    "    \"\"\"\n",
    "    query = \"\"\"\n",
    "        SELECT *\n",
    "        FROM analytics.customers\n",
    "        WHERE country = %s\n",
    "        LIMIT 100\n",
    "    \"\"\"\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    return db.read_sql(query, (country_name,))\n",
    "\n",
    "# Test\n",
    "vietnam_customers = get_customers_by_country('Vietnam')\n",
    "print(f\"Vietnam customers: {len(vietnam_customers)}\")\n",
    "vietnam_customers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Query with multiple parameters\n",
    "def get_orders_by_date_range(start_date, end_date, min_amount=0):\n",
    "    \"\"\"\n",
    "    Get orders within date range and minimum amount\n",
    "    \"\"\"\n",
    "    query = \"\"\"\n",
    "        SELECT *\n",
    "        FROM analytics.orders\n",
    "        WHERE order_date BETWEEN %s AND %s\n",
    "          AND total_amount >= %s\n",
    "        ORDER BY order_date DESC\n",
    "    \"\"\"\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    return db.read_sql(query, (start_date, end_date, min_amount))\n",
    "\n",
    "# Test\n",
    "start = datetime.now() - timedelta(days=30)\n",
    "end = datetime.now()\n",
    "orders = get_orders_by_date_range(start, end, min_amount=1000)\n",
    "\n",
    "print(f\"Found {len(orders)} orders\")\n",
    "orders.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üéØ EXERCISE 2: Write Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a summary table\n",
    "create_table_sql = \"\"\"\n",
    "    DROP TABLE IF EXISTS analytics.daily_summary;\n",
    "    \n",
    "    CREATE TABLE analytics.daily_summary (\n",
    "        summary_date DATE PRIMARY KEY,\n",
    "        total_orders INTEGER,\n",
    "        total_revenue DECIMAL(15,2),\n",
    "        avg_order_value DECIMAL(10,2),\n",
    "        unique_customers INTEGER,\n",
    "        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "    );\n",
    "\"\"\"\n",
    "\n",
    "# YOUR CODE HERE\n",
    "db.execute_query(create_table_sql, fetch=False)\n",
    "\n",
    "print(\"‚úÖ Table created successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calculate and insert daily summary\n",
    "calculate_summary_sql = \"\"\"\n",
    "    INSERT INTO analytics.daily_summary \n",
    "    (summary_date, total_orders, total_revenue, avg_order_value, unique_customers)\n",
    "    SELECT \n",
    "        DATE(order_date) as summary_date,\n",
    "        COUNT(*) as total_orders,\n",
    "        SUM(total_amount) as total_revenue,\n",
    "        AVG(total_amount) as avg_order_value,\n",
    "        COUNT(DISTINCT customer_id) as unique_customers\n",
    "    FROM analytics.orders\n",
    "    WHERE order_date >= CURRENT_DATE - INTERVAL '30 days'\n",
    "    GROUP BY DATE(order_date)\n",
    "    ON CONFLICT (summary_date) \n",
    "    DO UPDATE SET\n",
    "        total_orders = EXCLUDED.total_orders,\n",
    "        total_revenue = EXCLUDED.total_revenue,\n",
    "        avg_order_value = EXCLUDED.avg_order_value,\n",
    "        unique_customers = EXCLUDED.unique_customers,\n",
    "        created_at = CURRENT_TIMESTAMP;\n",
    "\"\"\"\n",
    "\n",
    "# YOUR CODE HERE\n",
    "db.execute_query(calculate_summary_sql, fetch=False)\n",
    "\n",
    "print(\"‚úÖ Summary calculated and inserted\")\n",
    "\n",
    "# Verify\n",
    "summary = db.read_sql(\"SELECT * FROM analytics.daily_summary ORDER BY summary_date DESC LIMIT 10\")\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üéØ EXERCISE 3: Batch Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write DataFrame to database in batches\n",
    "# Create sample data\n",
    "sample_data = pd.DataFrame({\n",
    "    'product_id': range(1, 101),\n",
    "    'product_name': [f'Product {i}' for i in range(1, 101)],\n",
    "    'category': np.random.choice(['Electronics', 'Clothing', 'Food', 'Books'], 100),\n",
    "    'price': np.random.uniform(10, 1000, 100).round(2),\n",
    "    'stock': np.random.randint(0, 100, 100)\n",
    "})\n",
    "\n",
    "print(f\"Sample data shape: {sample_data.shape}\")\n",
    "sample_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write to database\n",
    "# YOUR CODE HERE\n",
    "rows_written = db.write_dataframe(\n",
    "    sample_data,\n",
    "    table_name='products_temp',\n",
    "    schema='analytics',\n",
    "    if_exists='replace'\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Written {rows_written} rows to database\")\n",
    "\n",
    "# Verify\n",
    "verify = db.read_sql(\"SELECT * FROM analytics.products_temp LIMIT 10\")\n",
    "verify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üéØ EXERCISE 4: Transaction Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Execute multiple queries in a transaction\n",
    "def update_customer_segment():\n",
    "    \"\"\"\n",
    "    Update customer segments based on order history\n",
    "    Uses transaction to ensure all-or-nothing\n",
    "    \"\"\"\n",
    "    queries = [\n",
    "        # Reset all to 'Standard'\n",
    "        \"\"\"\n",
    "        UPDATE analytics.customers\n",
    "        SET customer_segment = 'Standard'\n",
    "        \"\"\",\n",
    "        \n",
    "        # Update to Premium (>10 orders or >$5000 total)\n",
    "        \"\"\"\n",
    "        UPDATE analytics.customers c\n",
    "        SET customer_segment = 'Premium'\n",
    "        FROM (\n",
    "            SELECT customer_id\n",
    "            FROM analytics.orders\n",
    "            GROUP BY customer_id\n",
    "            HAVING COUNT(*) > 10 OR SUM(total_amount) > 5000\n",
    "        ) o\n",
    "        WHERE c.customer_id = o.customer_id\n",
    "        \"\"\",\n",
    "        \n",
    "        # Update to VIP (>20 orders or >$10000 total)\n",
    "        \"\"\"\n",
    "        UPDATE analytics.customers c\n",
    "        SET customer_segment = 'VIP'\n",
    "        FROM (\n",
    "            SELECT customer_id\n",
    "            FROM analytics.orders\n",
    "            GROUP BY customer_id\n",
    "            HAVING COUNT(*) > 20 OR SUM(total_amount) > 10000\n",
    "        ) o\n",
    "        WHERE c.customer_id = o.customer_id\n",
    "        \"\"\"\n",
    "    ]\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    conn = db.get_connection()\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    try:\n",
    "        for query in queries:\n",
    "            cursor.execute(query)\n",
    "        \n",
    "        conn.commit()\n",
    "        print(\"‚úÖ Transaction committed successfully\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        conn.rollback()\n",
    "        print(f\"‚ùå Transaction rolled back: {e}\")\n",
    "        raise\n",
    "    \n",
    "    finally:\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "\n",
    "# Test (commented out to avoid changing data)\n",
    "# update_customer_segment()\n",
    "\n",
    "# Check current distribution\n",
    "segment_dist = db.read_sql(\"\"\"\n",
    "    SELECT customer_segment, COUNT(*) as count\n",
    "    FROM analytics.customers\n",
    "    GROUP BY customer_segment\n",
    "    ORDER BY count DESC\n",
    "\"\"\")\n",
    "\n",
    "print(\"Current segment distribution:\")\n",
    "segment_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üéØ EXERCISE 5: Complete ETL Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Build customer analytics pipeline\n",
    "def customer_analytics_pipeline():\n",
    "    \"\"\"\n",
    "    Complete ETL pipeline:\n",
    "    1. Extract customers and orders\n",
    "    2. Calculate customer metrics\n",
    "    3. Clean and validate\n",
    "    4. Load to analytics table\n",
    "    \"\"\"\n",
    "    pipeline = ETLPipeline('customer_analytics')\n",
    "    \n",
    "    try:\n",
    "        # EXTRACT\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"EXTRACT PHASE\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        customers = db.read_sql(\"SELECT * FROM analytics.customers\")\n",
    "        print(f\"‚úÖ Extracted {len(customers)} customers\")\n",
    "        \n",
    "        orders = db.read_sql(\"SELECT * FROM analytics.orders\")\n",
    "        print(f\"‚úÖ Extracted {len(orders)} orders\")\n",
    "        \n",
    "        # TRANSFORM\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"TRANSFORM PHASE\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        customer_metrics = orders.groupby('customer_id').agg({\n",
    "            'order_id': 'count',\n",
    "            'total_amount': ['sum', 'mean', 'max'],\n",
    "            'order_date': ['min', 'max']\n",
    "        }).reset_index()\n",
    "        \n",
    "        customer_metrics.columns = [\n",
    "            'customer_id', 'total_orders', 'total_spent',\n",
    "            'avg_order_value', 'max_order_value',\n",
    "            'first_order_date', 'last_order_date'\n",
    "        ]\n",
    "        \n",
    "        print(f\"‚úÖ Calculated metrics for {len(customer_metrics)} customers\")\n",
    "        \n",
    "        # Merge with customer data\n",
    "        analytics_df = customers.merge(\n",
    "            customer_metrics,\n",
    "            on='customer_id',\n",
    "            how='left'\n",
    "        )\n",
    "        \n",
    "        # Fill nulls for customers without orders\n",
    "        analytics_df['total_orders'] = analytics_df['total_orders'].fillna(0)\n",
    "        analytics_df['total_spent'] = analytics_df['total_spent'].fillna(0)\n",
    "        \n",
    "        # Add derived columns\n",
    "        analytics_df['days_since_last_order'] = (\n",
    "            pd.Timestamp.now() - pd.to_datetime(analytics_df['last_order_date'])\n",
    "        ).dt.days\n",
    "        \n",
    "        analytics_df['customer_lifetime_days'] = (\n",
    "            pd.to_datetime(analytics_df['last_order_date']) - \n",
    "            pd.to_datetime(analytics_df['first_order_date'])\n",
    "        ).dt.days\n",
    "        \n",
    "        print(f\"‚úÖ Created analytics dataset: {analytics_df.shape}\")\n",
    "        \n",
    "        # VALIDATE\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"VALIDATION PHASE\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        validator = (\n",
    "            DataValidator(analytics_df, \"customer_analytics\")\n",
    "            .check_not_null(['customer_id', 'customer_name'])\n",
    "            .check_unique(['customer_id'])\n",
    "            .check_range('total_orders', 0, float('inf'))\n",
    "            .check_range('total_spent', 0, float('inf'))\n",
    "        )\n",
    "        \n",
    "        validator.print_report()\n",
    "        \n",
    "        # LOAD\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"LOAD PHASE\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        rows = db.write_dataframe(\n",
    "            analytics_df,\n",
    "            table_name='customer_analytics',\n",
    "            schema='analytics',\n",
    "            if_exists='replace'\n",
    "        )\n",
    "        \n",
    "        print(f\"‚úÖ Loaded {rows} rows to analytics.customer_analytics\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"PIPELINE COMPLETED SUCCESSFULLY\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        return analytics_df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Pipeline failed: {e}\")\n",
    "        raise\n",
    "\n",
    "# Run pipeline\n",
    "result = customer_analytics_pipeline()\n",
    "\n",
    "print(\"\\nüìä Sample results:\")\n",
    "result.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify loaded data\n",
    "verify_query = \"\"\"\n",
    "    SELECT \n",
    "        customer_segment,\n",
    "        COUNT(*) as customers,\n",
    "        AVG(total_orders) as avg_orders,\n",
    "        AVG(total_spent) as avg_spent,\n",
    "        AVG(days_since_last_order) as avg_days_since_order\n",
    "    FROM analytics.customer_analytics\n",
    "    GROUP BY customer_segment\n",
    "    ORDER BY avg_spent DESC\n",
    "\"\"\"\n",
    "\n",
    "segment_analysis = db.read_sql(verify_query)\n",
    "print(\"\\nüìà Customer Segment Analysis:\")\n",
    "segment_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üéØ CHALLENGE: Build Your Own Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create product performance pipeline\n",
    "# Requirements:\n",
    "# 1. Extract orders and order_items\n",
    "# 2. Calculate per product:\n",
    "#    - Total quantity sold\n",
    "#    - Total revenue\n",
    "#    - Number of orders\n",
    "#    - Average price\n",
    "#    - First/last sale date\n",
    "# 3. Validate results\n",
    "# 4. Load to analytics.product_performance\n",
    "\n",
    "def product_performance_pipeline():\n",
    "    \"\"\"\n",
    "    YOUR CODE HERE\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "# Run your pipeline\n",
    "# product_performance_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üìö KEY TAKEAWAYS\n",
    "\n",
    "### SQL + Python Integration Best Practices:\n",
    "\n",
    "1. **Use Parameterized Queries** - Prevent SQL injection\n",
    "2. **Batch Operations** - Process large datasets efficiently\n",
    "3. **Transaction Management** - Ensure data consistency\n",
    "4. **Error Handling** - Rollback on failures\n",
    "5. **Connection Pooling** - Reuse connections\n",
    "6. **Validate Data** - Check before and after loading\n",
    "7. **Log Everything** - Track pipeline execution\n",
    "8. **Optimize Queries** - Use indexes, limit data transfer\n",
    "\n",
    "### When to Use SQL vs Python:\n",
    "\n",
    "**Use SQL when:**\n",
    "- Filtering large datasets\n",
    "- Joining tables\n",
    "- Aggregating data\n",
    "- Working with database-specific features\n",
    "\n",
    "**Use Python when:**\n",
    "- Complex transformations\n",
    "- Machine learning\n",
    "- API integrations\n",
    "- Custom business logic\n",
    "\n",
    "**Best approach:** Combine both!\n",
    "- SQL for heavy lifting in database\n",
    "- Python for complex logic and orchestration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üéì CONGRATULATIONS!\n",
    "\n",
    "B·∫°n ƒë√£ ho√†n th√†nh Week 3-4: Python for Data Engineering!\n",
    "\n",
    "### B·∫°n ƒë√£ h·ªçc ƒë∆∞·ª£c:\n",
    "‚úÖ Pandas for data manipulation\n",
    "‚úÖ Data cleaning techniques\n",
    "‚úÖ ETL patterns and best practices\n",
    "‚úÖ Data validation frameworks\n",
    "‚úÖ SQL + Python integration\n",
    "\n",
    "### Ti·∫øp theo:\n",
    "- Week 5-6: Apache Airflow & Workflow Orchestration\n",
    "- Week 7-8: Data Warehousing with dbt\n",
    "- Week 9-10: Real-time Data Processing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
