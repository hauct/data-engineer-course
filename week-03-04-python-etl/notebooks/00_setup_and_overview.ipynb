{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üèÅ 00. SETUP & OVERVIEW - ETL Pipeline Architecture\n",
    "\n",
    "## üéØ M·ª§C TI√äU:\n",
    "- Hi·ªÉu ki·∫øn tr√∫c 3-layer ETL (Raw ‚Üí Staging ‚Üí Production)\n",
    "- Ki·ªÉm tra m√¥i tr∆∞·ªùng v√† k·∫øt n·ªëi database\n",
    "- T·ªïng quan v·ªÅ data flow\n",
    "\n",
    "## üìö N·ªòI DUNG:\n",
    "1. Ki·∫øn tr√∫c ETL 3-layer\n",
    "2. Ki·ªÉm tra k·∫øt n·ªëi database\n",
    "3. T·ªïng quan v·ªÅ d·ªØ li·ªáu\n",
    "4. Workflow t·ªïng th·ªÉ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üèóÔ∏è KI·∫æN TR√öC ETL 3-LAYER\n",
    "\n",
    "```\n",
    "raw_data/          ‚Üí    raw schema      ‚Üí    staging schema    ‚Üí    prod schema\n",
    "(Parquet files)         (Immutable)          (Cleaned)              (Aggregated)\n",
    "\n",
    "customers/              raw.customers   ‚Üí    staging.customers ‚Üí    prod.customer_metrics\n",
    "products/               raw.products    ‚Üí    staging.products\n",
    "orders/                 raw.orders      ‚Üí    staging.orders    ‚Üí    prod.daily_sales\n",
    "order_items/            raw.order_items ‚Üí    staging.order_items    prod.monthly_sales\n",
    "                                                                     prod.daily_category_metrics\n",
    "                                                                     prod.daily_product_metrics\n",
    "```\n",
    "\n",
    "## üìã C√ÅC LAYER:\n",
    "\n",
    "### 1Ô∏è‚É£ **RAW Layer** (Bronze)\n",
    "- **M·ª•c ƒë√≠ch**: L∆∞u tr·ªØ d·ªØ li·ªáu g·ªëc, kh√¥ng thay ƒë·ªïi\n",
    "- **ƒê·∫∑c ƒëi·ªÉm**: \n",
    "  - C√≥ duplicate, null, l·ªói format\n",
    "  - C√≥ metadata columns (_ingested_at, _source_file, _partition_date)\n",
    "  - Immutable (kh√¥ng s·ª≠a, ch·ªâ append)\n",
    "\n",
    "### 2Ô∏è‚É£ **STAGING Layer** (Silver)\n",
    "- **M·ª•c ƒë√≠ch**: D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c l√†m s·∫°ch, chu·∫©n h√≥a\n",
    "- **ƒê·∫∑c ƒëi·ªÉm**:\n",
    "  - Remove duplicates\n",
    "  - Validate data (email format, ranges)\n",
    "  - Standardize text (capitalize names)\n",
    "  - Enforce referential integrity\n",
    "\n",
    "### 3Ô∏è‚É£ **PRODUCTION Layer** (Gold)\n",
    "- **M·ª•c ƒë√≠ch**: D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c t·ªïng h·ª£p, s·∫µn s√†ng cho business\n",
    "- **ƒê·∫∑c ƒëi·ªÉm**:\n",
    "  - Aggregated metrics\n",
    "  - Denormalized\n",
    "  - Optimized for reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import sys\n",
    "sys.path.append('../scripts')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "from db_connector import DatabaseConnector\n",
    "from data_cleaner import DataCleaner\n",
    "from validators import DataValidator\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. KI·ªÇM TRA K·∫æT N·ªêI DATABASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-20 08:45:35,750 - db_connector - INFO - Database connector initialized for data_engineer@postgres\n",
      "2025-12-20 08:45:35,803 - db_connector - INFO - Query executed, DataFrame shape: (1, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîå Ki·ªÉm tra k·∫øt n·ªëi database...\n",
      "\n",
      "‚úÖ K·∫øt n·ªëi th√†nh c√¥ng!\n",
      "Database: data_engineer\n",
      "User: dataengineer\n",
      "Version: PostgreSQL 15.15 on x86_64-pc-linux-musl, compiled...\n"
     ]
    }
   ],
   "source": [
    "print(\"üîå Ki·ªÉm tra k·∫øt n·ªëi database...\")\n",
    "\n",
    "db = DatabaseConnector()\n",
    "\n",
    "# Test query\n",
    "result = db.read_sql(\"SELECT current_database(), current_user, version()\")\n",
    "print(\"\\n‚úÖ K·∫øt n·ªëi th√†nh c√¥ng!\")\n",
    "print(f\"Database: {result['current_database'][0]}\")\n",
    "print(f\"User: {result['current_user'][0]}\")\n",
    "print(f\"Version: {result['version'][0][:50]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. KI·ªÇM TRA C√ÅC SCHEMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-20 08:45:40,293 - db_connector - INFO - Query executed, DataFrame shape: (3, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Ki·ªÉm tra schemas...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>schema_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>prod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>raw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>staging</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  schema_name\n",
       "0        prod\n",
       "1         raw\n",
       "2     staging"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"üìÇ Ki·ªÉm tra schemas...\")\n",
    "\n",
    "schemas_query = \"\"\"\n",
    "SELECT schema_name \n",
    "FROM information_schema.schemata \n",
    "WHERE schema_name IN ('raw', 'staging', 'prod')\n",
    "ORDER BY schema_name\n",
    "\"\"\"\n",
    "\n",
    "schemas = db.read_sql(schemas_query)\n",
    "display(schemas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. KI·ªÇM TRA TABLES TRONG M·ªñI SCHEMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-20 08:45:41,209 - db_connector - INFO - Query executed, DataFrame shape: (4, 1)\n",
      "2025-12-20 08:45:41,219 - db_connector - INFO - Query executed, DataFrame shape: (1, 1)\n",
      "2025-12-20 08:45:41,285 - db_connector - INFO - Query executed, DataFrame shape: (1, 1)\n",
      "2025-12-20 08:45:41,308 - db_connector - INFO - Query executed, DataFrame shape: (1, 1)\n",
      "2025-12-20 08:45:41,318 - db_connector - INFO - Query executed, DataFrame shape: (1, 1)\n",
      "2025-12-20 08:45:41,323 - db_connector - INFO - Query executed, DataFrame shape: (4, 1)\n",
      "2025-12-20 08:45:41,335 - db_connector - INFO - Query executed, DataFrame shape: (1, 1)\n",
      "2025-12-20 08:45:41,377 - db_connector - INFO - Query executed, DataFrame shape: (1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Ki·ªÉm tra tables...\n",
      "\n",
      "RAW Schema:\n",
      "--------------------------------------------------\n",
      "  customers.....................     11,116 rows\n",
      "  order_items...................    360,327 rows\n",
      "  orders........................    119,726 rows\n",
      "  products......................     36,500 rows\n",
      "\n",
      "STAGING Schema:\n",
      "--------------------------------------------------\n",
      "  customers.....................     10,680 rows\n",
      "  order_items...................    333,217 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-20 08:45:41,400 - db_connector - INFO - Query executed, DataFrame shape: (1, 1)\n",
      "2025-12-20 08:45:41,403 - db_connector - INFO - Query executed, DataFrame shape: (1, 1)\n",
      "2025-12-20 08:45:41,408 - db_connector - INFO - Query executed, DataFrame shape: (5, 1)\n",
      "2025-12-20 08:45:41,417 - db_connector - INFO - Query executed, DataFrame shape: (1, 1)\n",
      "2025-12-20 08:45:41,423 - db_connector - INFO - Query executed, DataFrame shape: (1, 1)\n",
      "2025-12-20 08:45:41,446 - db_connector - INFO - Query executed, DataFrame shape: (1, 1)\n",
      "2025-12-20 08:45:41,449 - db_connector - INFO - Query executed, DataFrame shape: (1, 1)\n",
      "2025-12-20 08:45:41,454 - db_connector - INFO - Query executed, DataFrame shape: (1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  orders........................    110,791 rows\n",
      "  products......................        100 rows\n",
      "\n",
      "PROD Schema:\n",
      "--------------------------------------------------\n",
      "  customer_metrics..............     10,680 rows\n",
      "  daily_category_metrics........      2,548 rows\n",
      "  daily_product_metrics.........     35,837 rows\n",
      "  daily_sales...................        364 rows\n",
      "  monthly_sales.................         12 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"üìä Ki·ªÉm tra tables...\\n\")\n",
    "\n",
    "for schema in ['raw', 'staging', 'prod']:\n",
    "    try:\n",
    "        # Get table names\n",
    "        table_names_query = f\"\"\"\n",
    "        SELECT table_name\n",
    "        FROM information_schema.tables \n",
    "        WHERE table_schema = '{schema}'\n",
    "        ORDER BY table_name\n",
    "        \"\"\"\n",
    "        tables = db.read_sql(table_names_query)\n",
    "        \n",
    "        print(f\"{schema.upper()} Schema:\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        for table_name in tables['table_name']:\n",
    "            count_query = f\"SELECT COUNT(*) as count FROM {schema}.{table_name}\"\n",
    "            count = db.read_sql(count_query)['count'][0]\n",
    "            print(f\"  {table_name:.<30} {count:>10,} rows\")\n",
    "        \n",
    "        print()\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ö†Ô∏è Error: {e}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. KI·ªÇM TRA RAW DATA FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Ki·ªÉm tra raw data files...\n",
      "\n",
      "customers:\n",
      "  Total partitions: 365\n",
      "  First: 2025-01-01\n",
      "  Last: 2025-12-31\n",
      "\n",
      "products:\n",
      "  Total partitions: 365\n",
      "  First: 2025-01-01\n",
      "  Last: 2025-12-31\n",
      "\n",
      "orders:\n",
      "  Total partitions: 364\n",
      "  First: 2025-01-02\n",
      "  Last: 2025-12-31\n",
      "\n",
      "order_items:\n",
      "  Total partitions: 364\n",
      "  First: 2025-01-02\n",
      "  Last: 2025-12-31\n"
     ]
    }
   ],
   "source": [
    "print(\"üìÅ Ki·ªÉm tra raw data files...\")\n",
    "\n",
    "raw_data_dir = Path('../raw_data')\n",
    "\n",
    "if raw_data_dir.exists():\n",
    "    for entity in ['customers', 'products', 'orders', 'order_items']:\n",
    "        entity_dir = raw_data_dir / entity\n",
    "        if entity_dir.exists():\n",
    "            partitions = sorted([d.name for d in entity_dir.iterdir() if d.is_dir()])\n",
    "            print(f\"\\n{entity}:\")\n",
    "            print(f\"  Total partitions: {len(partitions)}\")\n",
    "            if partitions:\n",
    "                print(f\"  First: {partitions[0]}\")\n",
    "                print(f\"  Last: {partitions[-1]}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Raw data directory not found!\")\n",
    "    print(\"Run: python scripts/generate_raw_data.py --test-mode\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. DATA FLOW VISUALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-20 08:45:54,584 - db_connector - INFO - Query executed, DataFrame shape: (3, 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üìä DATA FLOW SUMMARY\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layer</th>\n",
       "      <th>customers</th>\n",
       "      <th>products</th>\n",
       "      <th>orders</th>\n",
       "      <th>order_items</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RAW</td>\n",
       "      <td>11116</td>\n",
       "      <td>36500</td>\n",
       "      <td>119726</td>\n",
       "      <td>360327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>STAGING</td>\n",
       "      <td>10680</td>\n",
       "      <td>100</td>\n",
       "      <td>110791</td>\n",
       "      <td>333217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PROD</td>\n",
       "      <td>10680</td>\n",
       "      <td>0</td>\n",
       "      <td>364</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     layer  customers  products  orders  order_items\n",
       "0      RAW      11116     36500  119726       360327\n",
       "1  STAGING      10680       100  110791       333217\n",
       "2     PROD      10680         0     364            0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"üìä DATA FLOW SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "flow_query = \"\"\"\n",
    "SELECT \n",
    "    'RAW' as layer,\n",
    "    (SELECT COUNT(*) FROM raw.customers) as customers,\n",
    "    (SELECT COUNT(*) FROM raw.products) as products,\n",
    "    (SELECT COUNT(*) FROM raw.orders) as orders,\n",
    "    (SELECT COUNT(*) FROM raw.order_items) as order_items\n",
    "UNION ALL\n",
    "SELECT \n",
    "    'STAGING' as layer,\n",
    "    (SELECT COUNT(*) FROM staging.customers) as customers,\n",
    "    (SELECT COUNT(*) FROM staging.products) as products,\n",
    "    (SELECT COUNT(*) FROM staging.orders) as orders,\n",
    "    (SELECT COUNT(*) FROM staging.order_items) as order_items\n",
    "UNION ALL\n",
    "SELECT \n",
    "    'PROD' as layer,\n",
    "    (SELECT COUNT(*) FROM prod.customer_metrics) as customers,\n",
    "    0 as products,\n",
    "    (SELECT COUNT(*) FROM prod.daily_sales) as orders,\n",
    "    0 as order_items\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    flow_df = db.read_sql(flow_query)\n",
    "    display(flow_df)\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Some tables might be empty: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéØ WORKFLOW T·ªîNG TH·ªÇ\n",
    "\n",
    "## B∆∞·ªõc 1: Generate Raw Data\n",
    "```bash\n",
    "python scripts/generate_raw_data.py --test-mode\n",
    "```\n",
    "\n",
    "## B∆∞·ªõc 2: Run ETL Pipeline\n",
    "```bash\n",
    "# Option 1: Run t·ª´ng layer\n",
    "make etl-run-raw    # Raw layer\n",
    "make etl-run-stg    # Staging layer\n",
    "make etl-run-prod   # Production layer\n",
    "\n",
    "# Option 2: Run full pipeline\n",
    "make etl-run-full\n",
    "```\n",
    "\n",
    "## B∆∞·ªõc 3: Explore Data\n",
    "- Notebook 01: Raw layer exploration\n",
    "- Notebook 02: Staging transformation\n",
    "- Notebook 03: Production aggregation\n",
    "\n",
    "## B∆∞·ªõc 4: Validate Data Quality\n",
    "- Notebook 05: Data quality checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Setup complete! Ready to explore ETL pipeline.\n",
      "\n",
      "üìö Next steps:\n",
      "  1. Run: python scripts/generate_raw_data.py --test-mode\n",
      "  2. Open: 01_raw_layer_exploration.ipynb\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n‚úÖ Setup complete! Ready to explore ETL pipeline.\")\n",
    "print(\"\\nüìö Next steps:\")\n",
    "print(\"  1. Run: python scripts/generate_raw_data.py --test-mode\")\n",
    "print(\"  2. Open: 01_raw_layer_exploration.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
